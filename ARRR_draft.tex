
\documentclass[]{article}
\usepackage[]{geometry}
\usepackage[american]{babel}
\usepackage{csquotes}
\usepackage[natbib=true, style=apa]{biblatex}
\bibliography{sources.bib}
%opening
\title{Towards formal theories and computational models of evolving referents to unfamiliar targets}
\author{Veronica Boyce}


\begin{document}
	
	\maketitle
	
	
	Language is an amazing human technology that supports much of human culture by being an efficient way of conveying many concepts with precision. Humans communicate in a range of situations, using language in ways that range from scripted and stereotyped (ex. greetings) to very open ended. The extensibility of language for use in novel contexts supports the transmission of new ideas and communication with new people. 
	
	Much linguistic creativity is ephemeral, occurring at at a single time within a single conversation to fulfill a one-time communicative need.  However, some linguistic needs are recurrent, and the words used to fill these needs may eventually conventionalize and lexicalize within the community. If the communicate niche occurs across groups, the conventions can spread to larger communities.  At the long time scale, the stickiest linguistic innovations make up language evolution. 
	
	Whether descriptions are fleeting or lasting, the core observation is the same: humans are adept at using language to communicate about unfamiliar targets with each other. This success entails two skills: a) the ability to refer to a new thing (that doesn't have an established name) in a way an interlocuter can understand and b) the ability to refer to a not-quite-so-new anymore thing in a way that is sensitive to the conversation history and may eventually converge into a conventional name. 
	
	How can we explain and predict these phenomena?
	
	\section{Levels of explanation}
	One issue with developing formal models of human linguistic behavior is that the data is rich and the possibilities are vast. How can one take rich, messy interaction data and tame it into meaningful features that are tractable to model and predict? 
	
	One can define the question of interest, and thus the scope of the modeling and prediction problem, at a few different levels:
	
	1. A clear trend observed in experiments is that utterance length reduces over repeated reference to the same novel target between the same pair of interlocuters. This has a straightforward output metric (utterance length in words), and given enough data, a functional form could be fit.  Determining the relevant input predictors, and operationalizing them would be a challenge, and then there's the wide variation in reduction rate for individual dyads within an experimental condition. This level could be the target of statistical models, but not for explanatory theories. 
	
	2. Instead of predicting the entire curve of a conversation, we could instead ask: given the environment and the conversation history thus far (i.e. any previous references to the target), can we predict properties of the next description? While still a high-level model, this at least parallels the presumed generative process of people selecting utterances and actions based on what has occurred thus far. Group-to-group variation in the dynamics may be smaller and only integrate into larger differences over time. This approach can also be neatly separated into questions of how to model initial utterances and separately the dynamics of how successful utterances evolve over repetition. 
	
	3. Finally, one may wish to model the actual production and comprehension processes. We might wish to predict the incremental understanding of a new reference expression given conversation history and context. Conversely, we might want to model the unit by unit production of a referring expression. This level of analysis could be seen as the algorithmic counterpart to the computational level approach in 2. Notably addressing these fine-grained process questions would require correspondingly detailed time course data to predict. 
	
	Currently, we have formal models at none of these levels. Personally, I find the 2nd level the most promising, but ideally, we would have mutually compatible formal theories at all levels. In the rest of this introduction, I will discuss the current state of the literature and gesture at what types of work will be needed to bridge towards formal models. 
	
	I will cover approaches from four perspectives. First, the communication and reference game literature which provides descriptive characterizations of phenomena of interest. Next, I will discuss two optimization-oriented frameworks of efficiency and the Rational Speech Acts models. Each of these might be able to supply formal theory, although as we will see, there are significant challenges in lining these frameworks up with the rich, open-ended language data. Finally, I will touch on the psycholinguistic approach, which reveals some constraints that computational/optimization approaches may need to account for. 
	
%Good down to here!

\section{Communication}
The communication and conversation literature, especially with regard to referring expressions, has provided useful descriptive work, but is primarily made up of verbal theories that are vague and do not make clear-cut risky predictions. 

\subsection{Mentalizing versus Non-mentalizing approaches}

A big question that comes up with conversation, and interactions between agents more generally, is whether and how agents track other agents internal states of knowledge and how this factors into their interaction.

The ``mentalizing'' tradition treats humans as representing other humans as agents with mental states. Within this broad school, there is variation in how these representations are implemented, how information gets added or modified, what exactly is tracked, and when representations (versus heuristics) are used. 

Within this tradition, many use the term ``common ground'' to refer to knowledge that two agents share. In some cases, it is used in a pre-theoretic way to mean roughly ``things you think another person will understand and won't be surprised if you reference'' \citep{leung2023, TODO}. For instance,  \citet{hanna2003} defines common ground as the ``mutual knowledge, beliefs, and assumptions'' held by the interlocuters. This meaning is rougly comparably to ``givenness'' in other domains \citep{fay2010}. 

 However, the problem with the term ``common ground'' is that some use it in a theoretically very loaded way, originating from the privileged versus mutual versus common knowledge framework \citep{TODO}. Under this usage, ``common ground'' is defined via infinite recursion in knowing that the other person knows that the first person knows that ...; this is the usage that comes up in formal semantics where many things may be introduced to common ground via accomodation \citep{horton1996, TODO}. In practice, humans don't tend to do more than a couple layers of recursion in their pragmatic reasoning \citep{frankeReasoningReferenceGames2016}. Thus, it is generally not important to distinguish knowledge types at deeper recursion levels than mutual knowledge that both people know to be mutual. 

How to deterministically populate these presumed knowledge representations has been the subject of much ink spillage \citep{horton1996,clark1996, TODO}. For our purposes, what another person knows or can be expected to understand is something that computational models will want as an input or intermediary, so that it can be used to evaluate utterance options. However, the knowledge state can clearly be probabilistic and may be inferred from empirical data. 

The mentalizing approaches can be contrasted with ``interactive alignment theory'' which attempts to explain how people can successfully collaborate on reference tasks without reasoning about each other's mental states \citep{pickering2004, gandolfi2022}. Its proponents claim that the alignment occurs via ``priming'' and is ``resource-free and automatic'', without providing a further explanation of what this means or how this works in terms of memory and processing \citep{pickering2004}.  Given that humans reason socially about each other readily and from a young age \citep{TODO}, it's not clear that there is a reason to prefer a non-mentalizing approach. 

As an aside, the ``common ground'' tradition and the ``interactive alignment'' traditions have tended to use different types of experiments, with ``common ground'' generally using asymmetric director/matcher designs (dating back to at least \citet{krauss1966}) and the ``interactive alignment'' traditions using symmetric designs such as the `maze' task. Thus it is possible the two approaches are build around trying to explain differing sets of experimental results. 

\subsection{Partner specificity, audience design, and sharing effort}

One key phenomenon from iterated reference games to unfamiliar images is that different pairs converge to different descriptions, which leads to claims of ``partner specificity''. This term is used both when one person talks with multiple others, possibly using different terms with each \citep{TODO}, and in the absence of any partner switching to signal that different pairs develop different names for the targets \citep{TODO}. 

Empirical evidence from experiments where one director talks with multiple partners suggests that people do ``partial pooling'' over their partners \citep{hawkins2021, yoon2014}. That is, a speaker A will show some variation in their expressions when talking to partner B versus partner C, but there will be some generalization between partners as well, so that A talking with B is more like A talking with C than D talking to E. When coupled with a tendency for descriptions to shorten within a pair, this leads to a jagged pattern of reference length: when switching to a new partner, speakers use longer utterances, but not as long as their initial utterance with their first partner \citep{yoon2019a}.  

A related term is ``audience design'', the idea that speakers seem to be sensitive to the knowledge state of their listener and say things that are easy for the listeners to comprehend. Confusingly, ``audience design'' sometimes implies intention on the part of the speaker \citep{horton2002a, horton2005}, and sometimes is used when utterances are constructed based on what's easy for the speaker, and listener ease is a side effect \cite{horton1996, rogers2013, macdonald2013}.

  Intention versus side-effect are difficult to distinguish between because speakers and listeners often share recent context, find the same things salient, and linguistically what is easier to produce is often easier to process. Thus, disentangling speaker and listener ease may require careful experimental designs where ease of production and ease of comprehension are separated \citep{ferreira2004}. 
  
Questions around audience design are issue of how interlocuters split the communicative burden with one another. Depending on the task and the communication modality, there may be many options for how to balance the communicative load  \citep{clark1996, fay2010, foxtree2013, TODO}. For instance, a listener could describe what options they see or otherwise prompt the speaker. We might expect the load splitting to vary based on the capacities of the interlocuters (ex. a speaker might craft their utterances more when talking to a child versus an adult) and the capacities of the channels (ex. speakers may use different approaches if listeners can interrupt). 

Multi-way conversations complicate the verbal theories of audience design and partner specificity by introducing a larger audience of more partners. Two main questions are whether ``aim low'' or ``aim high'' in balancing the needs of the listeners and whether speakers track individual listeners or an aggregate \cite{yoon2014}. Empirical results indicate that speakers are sensitive to the knowledge states of listeners in a gradient way \citep{yoon2014, yoon2018, yoon2019}. At least in small groups, speakers can track the correspondence between individual listener identity to histories and knowledge states, and can incorporate contextual factors that modulate task difficulty into their considerations \citep{yoon2019a}. Speakers also take strategies in group-contexts that don't occur as often in dyadic contexts, such as referring to a target with both the name that one person will understand and a elaborated description that will help another person get on the same page \citep{yoon2018}. The ability to track partner's knowledge states presumably would degrade as groups got bigger, but this paradigm has not been used for groups large enough for this to happen. 

\subsection{Convention formation}
Over repetitions with the same partner, dyads in repeated reference games tend to form shared ``conventions'' (also called ``conversational pacts'') about how to refer to the initially ambiguous targets. These conventions tend to be partner- and context-specific: changes in the speaker, audience members, or changes in the context can all license the use of a new description \citep{metzing2003a, ibarra2016, yoon2014}.

What exactly does convention formation refer to? There is ambiguity about what level of specificity convention formation and conceptual pacts refer to. It could be on the lexical level, such as calling a figure ``ballerina''. It could be conceptualizing the figure as a ballet dancer with a tutu (manifesting in descriptions with semantic association, but not lexical overlap, such as ``ballerina'' and ``dancing in a tutu''). It could also be a general paradigm for how to describe figures, such as in terms as humans in different postures.  \cite{horton2002a} distinguishes between ``lexical entrainment'' when the same words are reused, and ``conceptual similarity'' when there is broader similarity that does not repeat the same words. These levels often co-occur, but in order to model the phenomenon, we need to be clear about which is meant in order to operationalize it.  

YOU ARE HERE
While the meaning of a description is not inherently related to its length; these two features tend to correlate in the empirical work around reference games, and thus ``reduction'' or the shortening of utterance is also used as a shorthand and measurement proxy for the semantic changes. It remains an empirical question whether the shortening of utterances and the convention formation are inherently coupled or merely occur together in the paradigms considered in the literature. These phenomena also co-occur and are sometimes conflated with partner-specificity, as in many paradigms, different pairs form different conventions. ADD CITATIONS

This set of empirical results have been characterized in descriptive theories, but we do not have ways to predict them quantitatively (ex. with computational models), nor do we have a grasp on the necessary or sufficient conditions under which they occur to what extent. Even with a number of experiments finding these same results, there has not been a systematic investigation of how these phenomena vary across experimental space. 

What are potential explanations for why convention formation occurs?

While not an explanation, \cite{leung2023} usefully points out that forming a convention can be thought of as preceding in two stages: first some referential expression must succeed in communicating the target, and only then can that expression turn into a more reduced form. Breaking the convention-formation process into these two steps may make it more tractable. 


One wrinkle is that many features of initial descriptions can become conventions. Typically holistic or analogic descriptions win out \cite{clark1986}, but this isn't absolute. Groups may use something strange and even something that is on a lower-level or on a meta-level as their referring name, and for them, this can be effective. This suggests a strong path dependency for how reduced utterances evolve, potentially influenced by factors such as relationships and humor value. 

Another question is whether convention formation requires a "special" mechanism and theory, or whether the results can be sufficiently explained under broader theories of efficiency or communication (as discussed below). 

How might convention formation change with group size? 
One angle on larger groups is network structures, where convention formation has been studied on networks of up to 50 people \citep{guilbeault2021}
A different paradigm that does look at much larger groups in networks is 	Groups can be complicated \cite{guilbeault2021} looks at how different sizes of groups interacting over a network structure result in different category boundaries, where large groups end up more the same than small groups. Brings up questions about network structure and how we should think about networks even within groups where multiple people are interacting synchronously. Some of the other try to only allow lines between points -- either bidirectional is dialog or single-directional in monolog but there's still the development of shared stuff from the co-presence of listening to someone else even without direct interaction? TODO NEEDS WORK


\subsection{Takeaways:} The communication and reference game literature provides descriptive theories that identify some phenomena of interest and raise questions around whether these phenomena occur intentionally or emerge as a by-product of other processes. These serve as a list of results that models could hope to explain. 

However, as the frequently ambiguous terms make clear, the descriptive work has not nailed down the phenomena to the degree of precision necessary. How do we measure these constructs across experiments? Fuller characterization of these phenomena will also require testing them in more circumstances, in order to define their extent. Alternatively, the verbal theories could be specific about the domain in which they claim to apply.  

[de-snark??]




\section{Efficiency}
One unifying framework gaining traction in psycholinguistics is efficiency, the idea that language and language use is under pressure to support efficient communication by maximizing the ratio of relevant information transmitted to effort. Efficiency is thought to arise from trade-offs between communicative expressivity and some combination of learnability and easy of production \cite{piantadosi2012, kirby2015}. 

Evidence for efficiency comes from the argument that features of language are distributed much closer to the Pareto frontier than would be expected by chance. A historically well-known example is that word frequencies follow a power-law distribution, which \cite{zipf1949} explains in terms of a ``principle of least effort'', although note that power-law distributes are common across domains and generated by a variety of processes \cite{piantadosi2014}. Stronger evidence comes from the lexical partitioning of subdomains such as color, number, and kinship terms, where the distribution of systems falls on the frontier between complexity (number of terms) and informativity (how many bits each term provides) \cite{keysar2000, gibson2019}. Syntactic features of language such as harmonic word order or dependency length also appear to be optimizing for increased expressivity with minimized processing effort \cite{gibson2019, hawkins1995}. 
	
Efficiency arguments are based on the language artifacts of grammars and transcripts, but efficiency pressures act on language use as a process, not language as a static code \cite{gibson2019}. Thus efficiency can be seen as imposing a joint constraint on the entire communicative process to minimize the total time and effort involved in going from an idea in one person's head to a sufficiently close idea in another person's head. One corollary of this framing is that shorter utterances (as measured in syllables or clock-time) are not always efficient if they take longer to produce or parse. 

\subsection{reference expressions and redundancy}
Interlocuter behavior in iterated reference games is informally referred to as efficient (in particular, the formation of reduced conversational pacts) CITE ME , but it isn't formally analyzed in terms of efficiency. Explicit tests of efficiency are used in the study of so-called  ``redundant'' color adjective use and other forms of so-called ``over-informative'' language use. As shown by the names, it seems like people's propensity to label something as a ``blue cup'' when there are not other cups around goes against the idea of efficient language use. 

Several issues arise here. Claims of redundancy or over-informativity require defining what is minimally informative. Defining what is minimally informative depends on a commitment to a fully specified semantic-pragmatic system. For instance, if specificity implicatures are within the option space, are those calculated before or after informativeness is measured \cite{bergen}? One could sidestep the theory by empirically measuring the information content of different utterances by how they shift the entropy of the distribution of inferred meanings \cite{degen20200406}, but this does not scale up well. 

Additionally, determining what is efficient requires not just analyzing phrases and their alternatives, but also production and comprehension time, which may be highly contingent on contextual factors and conversational history. 

The flip side of ''redundancy'' is ambiguity: many, many utterances are ambiguous. In general, strong contextual factors render the ambiguity a non-issue \cite{piantadosi2012}, but this means we can't judge language out of the physical and social context it is used in. 

These ideas that utterances should have ``just enough'' information has inspired a lot of empirical research into what utterances people produce and what utterances people comprehend. As an empirical matter, each of these halves can be empirically measured: by comparing them, we could determine how calibrated productions are to what other people will understand. 



\subsection{Takeaways:}
Efficiency is very hard to cache out in specific predictions because of the many time scales the pressures operate on: what's efficient for an utterance in isolation may not be efficient when considered over an entire life of language use. Thus, the efficiency framework is dependent on linking assumptions, and an efficiency approach could be seen as determining what link assumptions are needed to bring different phenomena under this umbrella, and then assessing the parsimony of those links.

With regard to iterated reference games, I believe it is an open question whether speakers produce utterances are correctly calibrated for what listeners will understand. Testing the interpretation of utterances and potential alternatives, along with how long they take to process, and how confident listeners are in their interpretations is a way of empirically determining if the utterances are calibrated for the listener. If utterances are not calibrated, it calls into question some claims about what reduction and partner-specific utterances represent. The miscalibration could still link to efficiency either via claims that the bottleneck is on the search and production side or that speakers are mistaken in their mental model of the listener. 


\section{RSA}

Rational Speech Acts (RSA) is an information-theoretic, computational framework for making quantitative predictions about pragmatic inferences in context \cite{goodman2016, frank2012a}. The basic idea of the RSA family of models is to picture two interlocuters recursively reasoning about how the other would produce or interpret utterances, grounding out in a listener (or speaker) who behaves in a pre-specified ``literal'' way. Computational frameworks such as RSA provide a way to factor together different trade offs and determine their relative weights in a model. A softmax is taken over the scores of the options to produce a distribution of interpretations and utterances, with some parameters such as the degree of optimality fit based on data.  
This framework is usually run with one or two levels of recursion, where it tends to produce a reasonable fit to human experimental judgments, consistent with work finding that most people reason pragmatically at a low recursion depth TODO CITE FRANKE \& DEGEN. 

This set of models has been used to model some instances of ad hoc pragmatics as well as conventionalized pragmatic implicatures. CITATIONS
Different models in the RSA tradition incorporate different sets of components in the models. Models generally include a utility or informativity term that relates to how well an utterance resolves uncertainty in favor of the target referent.  It is common to also include factors such as the prior likelihood of referring to each target (salience prior) and some cost on utterances where longer or more complex utterances are penalized \cite{goodman2016}. Some models also go beyond informativity, incorporating options to infer the question-under-discussion CITATION or for speakers to balance informativity with politeness. CITATIONS

A full RSA model would incorporate all of these components and infer their weights. However, for tractability, usually only those features that are considered relevant to the domain of interest are included. Because of the flexible framework, it is possible to model many sources and levels of uncertainty, and then integrate out that uncertainty to make predictions, but also update on the sources of uncertainty in response to input. 

\subsection{the challenge of semantics}
Perhaps the largest challenge to RSA models is the question of how to ground out the models in a ``literal'' listener or speaker. For the most part, RSA is tested in toy domains where the set of possible utterances are small and it is possible to enumerate a set of meanings. For instance, in some domains, a soft or continuous semantics is used to represent that some dimensions of meaning might be more strongly informative than others \cite{degen20200406}. This semantics supports the prediction of patterns of ``redundant'' color adjectives in referring expressions. However, soft semantics can run into conflict with compositionality: either every possible utterance must independently receive a degree of match with every possible object in the prior, or the prior needs to include rules for how to determine the match of a whole utterance on the basis of the match with each component. In a later experiment of \cite{degen20200406}, typicality effects made compositional semantics not work, but the utterance space was small enough that each utterance could be treated individually. 

 In less toy domains, there is not a satisfactory answer: some situations can be handled by empirically measuring likelihoods in an exhaustive ways, but this holistic approach is not compatible with incremental RSA or larger sets of utterances that require compositionality to be defined. In order to extend this model towards more realistic and open-ended scenarios, an important question to grapple with is what form of meaning (even at a computational level) will appropriately support pragmatic reasoning. 

\subsection{RSA approaches to reduction}
Scaling up RSA to handle reference games requires solving at least two problems. One is specifying a semantics system that can handle the abstract, metaphoric, and parts-based descriptions that are used -- this could be seen as the problem of accounting for initial reference. 

Secondly, one must explain how to go from one successful utterance to a different (often shorter) utterance. One RSA-style model that attempts to explain why multi-part descriptions are produced initially, but shorter descriptions are produced later is CHAI,  a framework to bridge different levels of convention formation \cite{hawkins2021}. TODO SAY MORE ABOUT CHAI In toy models of interlocuters playing a reference game with soft semantics, initial utterances use multiple properties to collectively increase the degree of certainty in the target. However, this successful reference then shapes the priors about the meanings of the words, until the degree of certainty afforded by only one word is sufficient. 

While CHAI can predict the qualitative pattern, there's still a question of how to predict the slope of reduction and the content of words that stay versus drop. 


\subsection{Takeaways}
RSA seems like the closest theoretical frameworks that could be made to fit a sequential model of iterated reference games. The big caveats are the problems of scaling up to an open vocabulary and the question of whether there will be too much flexibility from free parameters. The open vocabulary problem is a hard one; rather than wait for a fully realized semantic system, I think one criteria for judging the adequacy of semantic systems is whether they can serve as a linking hypothesis to allow RSA models to predict the patterns of pragmatic language use that are observed experimentally. 
CHAI, while not a full explanation for the full patterns of real-world data, is a big step forward in at least providing a framework that actually explains why reduction would be optimal. 

\section{Psycholinguistic considerations}

The prior sections have all operated at a pretty high level of analysis, but the language and behaviors observed in reference games and real-world descriptions come from lower-level, incremental processes. Psycholinguistics imposes constraints on the algorithmic level of linguistic communication; to the extent we can infer these constraints from fine-grained behavior or transfer these constraints from other areas of psycho- and neuro-linguistics, these constraints may provide bounds for the computational models. 

TODO MAKE THE ABOVE SUCK LESS

\subsection{Top-down or bottom-up?}
One large question in language processing and production broadly is what the relative balance of bottom-up and top-down influences are CITATIONS NEEDED. 

In the psycholinguistics of reference games, a hotly debated question is whether the early moments of production and processing are ``ego-centric'' or can be influenced by non-linguistic information, such as the perspective of the interlocuter. On the production side, TODO cite Horton \& Keysar attempt to test this, but acknowledge that monitoring and fixing of the utterance, including pre-initiation of the utterance, may take into account the listener's perspective. %TODO say more about the egocentrism thing

On the comprehension side, \cite{keysar2000} argues for an initial egocentric perspective on the basis that people often intially look at objects that are good matches to a description that are not mutually visible with their interlocuter. This interpretation rests on a couple dubious linking hypotheses: that if people consider an interlocuters perspective, their prior should be that the interlocuter only refers to mutually known things and separately that looking at an object is a sign that it is considered a potential referent (eye-tracking data is widely interpreted this way, but there is evidence that this proxy is only approximate CITE DEGEN).

The counterpoint to initial ego-centrism presented by \cite{hanna2003} is a constraint-based theory where many factors can play into comprehension, including working memory limitations. Many factors may influence language production and comprehension, to varying extents, and on differing time courses. Determining the relative timings and weights is an important endeavor; however, as these experiments show, it's empirically difficult to do so when the measurements are far from the constructs and there are nuisance experimental parameters as well. 

\subsection{Bounds on rational approaches}
In additional to possible information-integration timing limitations on optimality, the retrieval and generation of utterances may be another source of deviation from optimal models. Utterance planning is difficult, and production biases such as easy first, plan reuse, and reduce interference that make production easier may deviate from what information-theoretic approaches would predict as efficient \cite{macdonald2013}.
Another limitation is the search problem of production. RSA and other computational theories assume that alternatives are readily available, and then provide ways of choosing from among the options. Especially with low-codability targets, the initial mental generation of any option may be a bottleneck. This is difficult to study, obviously, but trying to get traction on initial utterance planning would answer important questions. 
There are empirical challenges with determining what is difficult for speakers to produce, although analyses of disfluencies \cite{yoon2014} is one approach. 

\subsection{Takeaways}

Some of the questions raised from a psycholinguistic angle are about the fine-grained time course of reference games: how utterances are generated and interpreted and what information is integrated when. Nonetheless, the big picture is that this instance of language use, in common with other instances of language use, is constrained by the general processes of language cognition.

Studying reference games on this level needs a different type of data (eye-tracking, timing details of utterances and responses) than the previous that can rely on transcripts of games. 

TODO WORK

It's possible that some misfit of optimal approaches may be due to something something bounded rationality
Pushing down levels of analysis, resource-rational models should embody some of the constraints from feasible memory retrieval, production, and processing. Some of these will be from domain general processes (memory retrieval) and others may be about the language system in particular. 
	\section{So, what now?}

What would we want from formal theories and computational models?

Any theory also needs to be compatible with what we know at different levels of analysis and related phenomena. A theory of linguistic iterated reference to novel objects need not cover how named objects are referred to, or how conventions form in drawing, or how language evolves, or how language is processed in the brain. But it is important the theory be compatible with all of these; it should not make untrue assumptions about these other areas. Ideally, the boundaries of a theory would be continuous with adjacent results and theories. 

Related, there are questions of how to scope a theory of iterated reference games; for instance, it may make sense to have a model that only covers dyadic interactions or a certain modality of interaction or a certain type of stimuli. This limited scope is fine if it is clear and the assumptions of the models don't lead to wild (false) predictions. 
	
	A key part of formal theories and computational models is they need to make clear quantitative predictions that can account for the existing data regarding the phenomena of interest. 
	
	
	Before we can do that, we need is a better definition of the phenomena and when they occur. I believe the phenomena of central interest here are a) how people describe images/objects/things where there is not a canonical or conventional name and b) the dynamics of how this process, over repetition, results in nicknames. Some components include explaining why the process goes through the intermediate steps it does, why it is partner specific, and how understandable the descriptions are to non-participants. 
	
There are a few options for making progress. The gap between data and theory can be narrowed from both the data and theory sides. 

\subsection{Data side}
	
	One necessity is a better empirical and descriptive understanding of the phenomena of interest. How do circumstantial knobs (group size, communication modality, stimuli, etc) push around the extend to which we see the phenomena of reduction, convention formation, and partner specificity? We don't have to finely map the entire landscape, but some sense of the geography of experimental space is necessary. Secondly, with these related phenomena, there's a question of how closely they are tied. Does reduction only occur via convention formation? Is one possible without the other? A greater range of experimental situations could tell how well these separate versus correlate in different situations, which will in turn clarify what theory should explain. CITE 20 QUESTIONS PAPER
	
	Another empirical avenue is to fill in descriptive details on the process of reduction. This will require finding useful joints to carve the rich language data into. Quantitatively, what types of utterances tend to occur after what other utterances? One could imagine trying to map the probabilistic FSA and transition probabilities. TODO NEEDS WORK 
	
	Another avenue is to push down a level of analysis and do empirical work looking at how utterances are produced rather than just recording what descriptions are produced. This might be especially useful for initial descriptions where the search problem is the hardest. 
	
	\subsection{Theory side}
	
	From the theory side, I think the most approachable way is to model the increment of what to say or how to interpret given a certain communication history: one can usefully compare options and condition on the prior. The big questions here are how to handle open-ended semantics and how to construction the option set. There's questions of whether predicting utterances is right thing, or whether a more abstracted version (perhaps predicting how many clauses to use, or whether to use description and/or name) is better. 	It'll also a question of threading a needle between aiming to incorporate too many factors (being too ambitious) and too few (overfitting to too specific a scenario). What's a minimal viable non-toy example? 
	
	Another theory component is how to build a non-dyadic RSA that can represent uncertain knowledge states or jointly optimize for the responses of multiple interlocuters. Further work in general on non-toy models of RSA CITE EXAMPLES would be useful. 
	
	Efficiency makes fairly vague predictions, and may be hard to crystallize out. One approach would be to treat the transcripts as some sort of artifact and try to determine potential counterfactuals, to see where the attested patterns fall on some larger space. Defining the space of possibilities could be difficult, and determining the information value of counterfactuals may require empirical testing. But one could address the open question of whether on a comprehension side, the observed patterns are efficient. This leaves out the potential that production side is the bottleneck on efficiency.  
	
	
	\section{How will the rest of this thesis move us in that direction?}
	
	TODO WHAT'S THE CAUSAL MODEL
	Overall, it seems that despite much research, there are still questions about what exactly are the phenomena to be characterized and how far they extend. Over this thesis, we provide data in various direction that could be useful for theory building. 
	
	many of the pieces could use more data
	
	a) a broader look at when reduction and semantic convergence patterns occur: how extensive is this phenomena by looking at larger groups and different modalities. This evidence contradicts many of the verbal theories that privilege dyadic communication and other things. 
	
	b) we dig into the data from a in an attempt to look at the stage to stage evolution of descriptions (TODO gotta do this research)
	
	c) developmental trajectory
	
	d) what's the processing look like? 
	
	? e) ? do we include any AA or game-theory? 
	
	\section{to be reincorporated}
	REREAD piantodosi2012 
	TODO dig into more: \cite{piantadosi2012} has me wondering whether conversational pacts are even real, or whether they are actually just contextual reduction is ambiguity and them peaking of the distributions in a slightly recursive way plus some recency effects and habit. This approach requires that speakers and listeners have similar models of language and the world at least in the relevant domain so that they can use contextual information to constrain the situation 
	\cite{piantadosi2012} in line with RSA assumes that inference is cheap and that context and speaker goals are constantly taken into account 
	
	

	
	
	\cite{hawkins2020b} How do you break symmetries in initial descriptions: there's prior variability across speaker preferences (they may each have a preferred label, but be unsure if others will accept it) and/or speakers may also not have labels and need to do some sampling. This doesn't account for production time course factors. 
	
	\cite{hawkins2021} says there are 3 core cognitive abilities: the ability to represent that there is variability in other's lexicons; to coordinate via online learning; and to generalize across interactions ("partial pooling" model where updates both to partner and population) 

Efficiency also predicts that a changing conversational history will change the context and thus different descriptions may be efficient. This could operate both by increasing beliefs that a certain utterance will be understood (and this is contextually low ambiguity) or more generally by shaping the syntactic expectations, perhaps making it easier to produce and comprehend odder descriptions. 

\cite{hawkins2021} separating the inference problem about what the other person's lexicon is (which is how they will interpret things in the moment, b/c you may have temporarily changed their lexicon) with decisions about what to say given that 

\cite{hawkins2021} points out that our models for communication and modeling the world and others need to be able to account for different people having different knowledge (including some tied to community membership or social role) and that vocabularies need to accomodate change over time and new things to refer to as the world changes. 

%TODO FIX REFERENCES!!!
\printbibliography

\end{document}