\documentclass[]{article}
\usepackage{biblatex}
%opening
\title{ARRR: Why most theory is this area is weak and wrong}
\author{Veronica Boyce, local cynic}
\addbibresource{sources.bib}
\begin{document}

\maketitle






\section{Useful approach: What I think is true}
Theories should be clear about what level of analysis and scope of explanation they are trying to provide. Theories that are compatible with other theories operating at different levels of analysis and that are compatible with the theories and evidence from adjacent fields are preferable. With that position, here's my distillation of what theories are most promising to me. 

At a broad-strokes computational level, abstracting out language-specific constraints and the details of production and processing, I think that RSA-style models are promising. These theories allow for probabilistic integration of the many linguistic and non-linguistic sources of information that are at play in conversation. It can accommodate different goal states as well as varying levels of certainty about anything.

% Many versions have successfully matched behavior in limited domains, but there are many factors that are in play in some situations and ideally they would exist in the background of models the rest of the time. Computational tractability becomes a problem if there are actually included, but it most cases, it seems like considering these other factors and then neglecting them is reasonable. 




Another source of constraints for implementational levels is how the language production and processing system works -- what possible utterances are and how they are produced and how things can be structured are constrained by language. 

Broadly think that efficiency is a driving factor and seems to have broad explanatory power, although we have to think about how it plays out in any particular situation. 

For communication, we could see efficiency as manifesting in trying to optimize bits of (goal-relevant) information conveyal per unit time. Conversation is a complex process so there's a lot going on: there's a mapping of goal to relevant information (which might be lossy), the speaker then has the access words to produce (which may not be easy for descriping low-nameability referents), and produce them. The comprehender then has to parse the string, interpret it (along with whatevever pragmatic integration is required) and then take an action. Often efficiency is established on the basis of how long the words are, but in some cases saying more words may be efficient if it reduces production costs or comprehension costs (making the task easier, or making it easier to understand by being nice to the parser). 

We don't have computation models for how to cost all these pieces against each other, so for now it's hard to verify these things. 

Different situations (experimental and otherwise) will induce different goals and provide different affordances; good models will have the ability to make predictions over a range of situations. 


When considering repeated reference especially for difficult-to-name targets, I think there's a productive split between what is needed for 'first contact' -- establishing an initial successful reference -- and what drives subsequent references, where reduction and changes need to be accounted for. One key distinction that doesn't get explicitly highlighted much (but is brought up in some recent work, such as \cite{leung2023}) is that the process of `first contact' -- establishing initial reference -- is at least somewhat separable from the repeated reference / reduction phenomenon. They're probably not totally separate as the same systems will need to work for both, but there are probably peculiarities to the reduction part. 

Listeners and speakers are (usually) engaged in a cooperative activity, and it is possible for them to do some load-balancing between them depending on the situation. 

From audience design: speakers take into account the whole set of listeners who are present -- tend to tailor so that all could understand, but use meanings/shorthands that knowledgeable ones will recognize (=> many possible ways to accomodate multiple listeners, perspectives, also consistent with a name \& describe that's good for future) 





A few directions that seem useful:
* start at RSA and attempt to scale up to accomodate conversations (tackle the open ended things)
* try to figure out what the bounds from memory / processing / production are and push a model down to a more resource rational / sampling based implementation
* something something extend theories to how groups work?



\section{Open questions that aren't satisfactorily answered}

Why the reduction curves we see? why not flat? or much sharper? 

how to bridge information theory/efficiency with syntactic/habitual expectation of language form 

whats the memory component over time? like if you asked people who had played the game to then later name all the figures? would they use the names their group had even months later? 

What are processing/production ways to get at cost and truthness of descriptions and also how are they sampled? 





%TODO look at kronmuller and barr MA (again?)


%TODO consider adding some cites from yoon2014 to the list, especially around constraint based 

%TODO zaslavsky -- confused on the details, but something about what efficiency is from an information-theoretic perspective 


%TODO consider constraint based models 



%TODO What's the SOTA in language production modelling? Utterance planning? 

%TODO Constraint based accounts of production (and comprehension) see \cite{hanna2003} highlights for suggested readings


%TODO forward search \cite{heller2012} since they're pretty reasonable about the idea of name versus what properties to include 

\subsection{Good: Unsatisfying ?: Explaining reduction phenomena}

For an efficiency standpoint it makes sense that the more something is referred to the shorter and easier it will be to refer to. However, this does not explain the process by which is occurs nor the partner-specificity that is observed. 

Many of the theories related to partner-specificity can explain how people succeed at establishing reference with each other and separately, why they persist in using shared terms. This too cannot explain how reduction occurs, since the reduction necessarily involves a change in how something is referred to (if only by dropping words). 

One approach to explaining how interlocuters might go from descriptions involving multiple components to fewer components is sketched in \cite{hawkins2021}. In a toy world with a limited number of utterances and targets, positing lexical uncertainty and TODO what the compositionality function is then applying RSA qualitatively results in the reduction pattern. Initially as each word has very uncertain meaning, using two that each slightly favor the target object makes sense because both is a much stronger indicator than either alone. However, each time they both are used together in this way, that causes a vocabulary update increasing the link between word and target. Once the link is strong enough, one of the words on its own is sufficiently clear that the cost of two words outweighs the now marginal additional clarification value. 

To the best of my knowledge, this is the only model that posits a computational mechanism that explains the reduction phenomena. As a toy model, it simplifies many aspects, and a line of modeling word could be gradually adding in real-world sources of complexity. For instance, what sort of semantics, both for the meanings of words and chunks, and for their compositionality, could support either the initial interpretation of long multi-part descriptions, and the updating required to eventually lead to reduction? 

Another piece is that reduction isn't just about shortening in the number of words or concepts used; it also tends to follow a stereotyped pattern, where more abstract, holistic "names" stick, while descriptions that may be more concrete or describe the image piece-mail tend to drop out. Why is this what happens?  Is there a way to model the initial semantics of these pieces and of the updating such that this pattern of what sticks is predicted? 

An additional complexity here is that the end point can vary. Usually holistic or analogic descriptions win out \cite{clark1986}, but this isn't absolute. Sometimes groups may use something strange and even something that is on a lower-level or on a meta-level as their referring name, and for them, this can be effective. So to fully explain this, we need to take into account the path dependency for how reduced utterances evolve, and potentially also account for issues such as people's relationships or humor value. 

Another desiderata from a computational model would be accurate predictions for the rate of reduction, although this too can vary greatly depending on groups. 

Overall, the high variability of reduction depending on images and group members and their interactions will make it hard to fully explain. However, even for a canonical instance of reduction, we have been limited to hand-wavy verbal theories. Now a promising model that can explain the pattern in a toy word, but incorporating semantics may prove challenging. (As it has elsewhere in RSA.) 



\subsection{Unsatisfying open ?: Groups}

Much of the literature is concerned with dyadic interactions, so theories do not often clearly predict what happens in multi-party settings. 
\cite{yoon2019} how much do you think of the group as a unit, versus as a set of individuals (obviously this is going to change some as group size changes, but what are the patterns) 

\cite{clark1996} focuses very much on dyadic interaction, and is in the vein that multi-person is serial dialog (verify this last part). 

how to extend ideas of joint action to accomodate multiple people? (re clark1996). 

One question is how you extend RSA up to multiple people -- how to do an utterance designed for multiple people? I guess you could represent separately and fit whatever joint function for optimizing that you want? 

groups allow for more complex structures. \cite{fay2000} tries to look at whether 5 and 10 person groups behave more like dialog or serial monolog (to the group) -- I think it's unclear that this is useful -- how do you define interactions / how do you usefully measure commonalities. There is a suggestion that there may be a transition point in how groups behave, possibly around 10 people, although context and goals seem very likely to push this around 

how to account for side conversations or parallel tracks which are available in some modalities (and not others) also other mediums such as fora / discord / slack have different affordances for allowing branching and parallel things that might be better for groups 

Groups can be complicated \cite{guilbeault2021} looks at how different sizes of groups interacting over a network structure result in different category boundaries, where large groups end up more the same than small groups. Brings up questions about network structure and how we should think about networks even within groups where multiple people are interacting synchronously. Some of the other try to only allow lines between points -- either bidirectional is dialog or single-directional in monolog but there's still the development of shared stuff from the co-presence of listening to someone else even without direct interaction? 

There should be some gradients in terms of these forms of more indirect interaction that aren't explained by dyadic models because the mechanisms that are claimed to support the partner specificity don't cover it (for in part being too low level?)

\cite{hawkins2021} for groups, how should we think about the pooling and updating based on the group -- have a different type of somewhat indirect evidence about the group members, although how indirect it is may depend on group size and structure and dynamics 

it's really unclear how \cite{pickering2004} would accomodate three people in their priming approach. can three people act as two people? 


One question is about the partner specificity of representations and how they may bleed together

This also interacts with other things such as ToM all of social cognition and the nature of memory representations 



\section{meta}

Maybe this should just be an interlude? 

What we need to make progress -- / why this was very frustrating 
coda on meta commentary which is maybe that we need more data and that it's all a mess 
* explanatory value
* levels of analysis
* experimental evidence

general meta-theory: when something is a new area, easy to make over-simplifiying models of “here are the two or three ways it could work” this is useful, but as a field matures, important to accept nuances.

useful sketch of some options versus reality / full messy space of options

Stronger if you have gradients (ideal if you have math model and can do something quantitative)

\subsection{ Levels of analysis and implicit versus explicit knowledge}
many theories are loose on what level of analysis they are addressing things out, and if there posit representations whether they mean that those are actually in the mind somewhere or whether it's a model that might not be actually possesed by people in that form. Also how much there may be a layer of approximation over everything. 

\subsection{experimental space and messiness}
20 	questions with nature. 
the experimental space here is quite huge and many of the experiments lack in generality and rigor (it's hard not to, especially by the standards of the day). Thus, a lot of the theoretical claims, while possibly useful and true, are not well supported by the evidence presented. 

In the start of an area of inquiry, it makes sense to use blunt tools and try to categorize things and limit the "messiness" in order to get any sort of traction and be able to start a theory (at least, this is a common approach, unclear if I actually think that it makes sense to have as much early theory). As evidence accumulates and a landscape of results starts to take shape, this stops cutting it. It becomes clear that there obviously is complexity and ignoring that complexity no longer suggests the right next experiments. Over-simplifying assumptions are common in the theory here, which may have been useful and necessary, but increasing maturity of an area comes with expectation that more be explained, and more quantitatively. 

\subsection{Constraints from other disciplines}
We're not making a theory of everything here, but if there are going to be appeals to parsimony, they need to take into account all the other stuff that will perforce be going on outside of this. Thus, if some things already are needed or well-explained that's to be  taken into account, especially with regard to domain general processes. 

In particular, reference contacts other disciplines in the forms of social cognition, since this is a social interaction and involves tracking other's understanding and knowledge states, and memory, since it involves remembering things. What we know and belief from these disciplines will need to match. Thus, if something is common and considered a solved problem, we can't appeal to it being hard. On the other hand, memory is decently understood and so we should reject models that posit implausible memory systems or memory retrieval operations. 

Models may be skimpy on these fronts if they are high level, but that should be explicit. 

Other evidence from language use and perception/ categorization boundaries may also come into play. 

\section{to incorporate}





need some sort of structured heirarchical representation of word meaning (on the part of the other person) -- how do we represent word meaning and in particular the sorts of word meaning profiles that another person could have 

what's the ability to compound utterances? how do we do informativity measures? and how does this play out with more real world stuff? there's a toy model that I think is broadly correct, but you also start running into syntactic expectations for natural language which in the individual instance run counter to pure efficiency and informativity (what if there isn't a noun) 




points to an open question about what realistic priors would look like here

partial pooling approach to generalizing across populations (but this is not when all were in a group together) 

a direction we're not really considering here, but this generalization should be expected not just across partners, but also across contexts (which will tie back into usage -> structure and non-arbitrariness and efficiency arguments )


another piece that isn't super relevant here, but context matters for what conventions will form since what level or levels will be informative (again ties in with communicative utility and thus efficiency )

should expect lateral inhibition from successful matches -- similar to pragmatic reasoning but we think about each choice being also a choice against the other options 


need to fill in the gap for what is happening in the conversation level synchronic interaction that repeated many many times across the community then drives the observed diachronic change 

\cite{hawkins2021} points out that our models for communication and modeling the world and others need to be able to account for different people having different knowledge (including some tied to community membership or social role) and that vocabularies need to accomodate change over time and new things to refer to as the world changes. 

This is at group / modality intersection \cite{foxtree2013} looking at different remote communication methods; brings up the possibility of having different modalities at once with different people. In terms of backchannel -- expectations about usage should very based on ease, but also usage should be based on level of *need* to communicate / inverse level of understanding 


\cite{yoon2014} posits a pretty high level of reasoning in that disfluencies (fairly low level linguistic signal) are explained away by the presence of a co-listener. How far does this go in terms of what sorts of knowledge about the other listeners position will or won't do explaining away? Also at some point we expect to allow that the speaker might be using imprecise heuristics and we can't form strong expectations b/c they might just be messing up. 
above could also be related to recursion depth

\cite{hawkins2020b} one question here is how are people so flexible in how they describe things. There's some ad hoc pragmatic reasoning going on, also people have learning mechanisms and can adapt to their partners. In the world, there's new things to experience, so we need ways of using language in new ones (that's just part of the necessary language capacity). There's also going to be new people and contexts, so we have to operate under uncertainty -- we don't know exactly what is shared. Also there's person to person variation in semantics / how they use words. And we can use feedback (verbal and not) to adjust. 

Pragmatics isn't some special thing, these are actually pretty universal. We're closer to living in tangram world than we think. (Except that we usually don't even have such a nice closed class of alternatives) 

Arbitrariness and stability on the semantic side 

note that the GD of \cite{hawkins2021} has reasonable things to say about children and how they might have weaker priors and be less attuned to how much content is needed to communicate 

\cite{heller2012} on claiming that overinformativity is a thing, but this is deeply problematic. Also mild overinformativity is unlikely to throw the listener?, also questions of how to interpret things like name + descriptions that aren't efficient in the moment but may make things more efficient later (by linking to a name) 



\end{document}
