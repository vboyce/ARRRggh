\documentclass[]{article}
\usepackage{biblatex}
%opening
\title{ARRR: Why most theory is this area is weak and wrong}
\author{Veronica Boyce, local cynic}
\addbibresource{sources.bib}
\begin{document}

\maketitle



	


	
TARGET LENGTH: 25 pages
	


\section{Introduction}

TODO
	



\section{Efficiency}
%STATUS: mostly solid, needs some rereading and polish!
One large-scale framework in psycholinguistics is the idea that language use and thus languages are under pressure to support efficient communication, that is, that languages and language use are close to optimal at maximizing the throughput of relevant information from mind to mind while minimizing the time and effort required. 

\subsection{Examples of efficiency}
Efficiency is a principle that unites varied phenomena observed in different aspects of language. 

Perhaps the most well-known piece of evidence in favor of efficiency is that across many languages, the distribution of word frequencies roughly follow a power-law distribution, where the $n^{th}$ most frequent word occurs with frequency proportional to $\frac{1}{n}$. \cite{zipf1949} observed this distribution and was an early proponent of language being shaped by efficiency, or as he called it the ``principle of least effort''. \cite{zipf1949} also cites other distributions in language, including his finding that more frequent words have more meanings. However, his theories about how these distributions could have arisen are ahistorical and do not provide processes to drive the observed equilibria nor do they account for historic changes in word meanings. 

\cite{piantadosi2014} rightly points out that power-law distributions are very common in many domains and can be generated by many processes, so finding a power-law distribution is extremely weak evidence for efficiency pressures. Additionally, the evidence for power-law distributions in language is more complicated than \cite{zipf1949} acknowledges. There are consistent small deviations from the power-law distribution for the most frequent words \cite{piantadosi2014}, and the roughly power-law distribution shows up for specific domains of words sharing the same denotational meaning, but varying in their connotations. \cite{zipf1949}'s theory of ``least effort'' cannot explain this fuller set of evidence. 


Another property of languages is that they tend to have highly combinatorial structures at multiple levels, which allows language users to express new concepts which is necessary to cope with the non-stationarity of the human world \cite{kirby2015}. In artificial language learning and communication experiments, \cite{kirby2015} found that structure emerged only when the language had to both be used to communicate and learned by new individuals. 

The word-order syntax of many languages places words that are syntactically near each other close to each other in linear order. \cite{gibson2019} argues that syntactic principles such as dependency locality and information locality  may make sentences easier to parse and thus more efficient to process and comprehend. \cite{hawkins1995} argues that syntactic phenomena such as argument order and heavy-NP shift could all arise from limiting the number of words that need to be in a parsing buffer before attachment ambiguities are resolved. 
 
Areas of lexical semantics, such as color words or kinship terms, are often taken as evidence for efficiency. Across languages, kinship terms seem to fall on a frontier of tradeoffs between complexity (number of kinship terms) and informativity (how many bits each term provides) \cite{kemp2018}. Under this theory, different systems arise from different cultural pressures on how much information tends to be relevant, for instance, whether it is usually important to specify the gender and relative age of a sibling, or merely that they are a sibling. More socially relevant, and thus, more commonly communicated distinctions are lexicalized, while rarely used ones are not. The distributions of color and number systems also fall on Pareto frontiers of complexity and informativity \cite{gibson2019}.

\subsection{Efficiency framework}
Theories of efficiency seem to be trying to answer the question: given the artifact of languages, what processes of language usage could have led to this system. Thus, it tends to be a high level account. 

As an overall framework, efficiency is fairly parsimonious and has substantial explanatory power across a wide-range of linguistic and psycholinguistic phenomenon. It's not a falsifiable theory since it relies on many linking hypotheses to connect the overall framework with actual observational and experimental data. 

Efficiency is often frames as arising from two competing pressures -- one trying to increase information conveyed and one trying to minimize effort or make language easier. \cite{piantadosi2012} describes the competing presses as clarity, which pushes for low ambiguity and a highly recoverable signal, versus ease, where a smaller set of lexical items will be easier for both production and comprehension. \cite{kirby2015} views efficiency as arising from a compressibility bias from the need to acquire language and an expressivity bias from language use. 

%describes that the expressivity of a fully combinatorial system is in tension with speed of communication because a fully regular system would make everything take a long time to communicate; irregularities allow for shorter forms for common meanings. Thus, there are competing pressures between compressibility which is important for learning and expressivity which is important for communication. 
%language learning which introduces a bias for compressibility and communicative use pushing for expressivity \cite{kirby2015}
%
%
%\cite{gibson2019} argues that efficiency, complexity, and learnability are collectively probably shaping things.

%TODO also here include the types of evidence/experiments that are used

%TODO and the limitations

\subsection{Efficient usage}

Efficiency isn't just about having an efficient code, it's about language use being efficient \cite{gibson2019}. This is a joint constraint on the entire communicative process to minimize the total time and effort involved in going from an idea in one person's head to a sufficiently close idea in another person's head. This time include the production time to construct the utterance, the time spent uttering the utterance, and the time spent parsing and interpreting the utterance. How efficient is possible will be a function both of the language and the language systems for production and processing (not to mention audition and articulation). As languages are likely the faster evolving compared to the mind, it makes sense that languages have adapted to be easier to produce and process. 

Under this framing of efficiency, shorter utterances (measured in clock time or syllable length) are not necessarily the most efficient as if they take sufficiently longer to produce or parse, they may not be the most efficient in terms of total mind-to-mind time. 

Thus, the goal of efficiency could be seen as maximizing relevant information transfer per unit time, subject to the (mental and biological) constraints of the human mind and the amount of effort/glucose humans are willing to put into communicating. 

\subsection{Informativity, redundancy, ambiguity, and efficiency}
%TODO needs work
One seeming counter-example to efficient language use is the common use of so-called ``redundant'' referring expressions, such as the phrase ``the blue cup'' when there is only one cup visible.  

While ``redundant'' and ''over-informative'' are useful pre-theoretic terms, defining what a minimally-adequate description would be requires a fully-fledged theory of semantics and pragmatics. The naive use of these terms and the idea that utterances should have ``just enough'' information has inspired empirical research into what utterances people use. 

Claims of informativity are generally made relative to a truth-value semantics, disregarding salience or pragmatic enhancement of meaning. 

 Problems also arise with for instance, specificity implicatures: does one calculate the informativeness of an utterance before or after the implicature \cite{bergen}?


As suggested by the name, informativity may be a useful route, as the information content of an utterance can be measured, either in a specified computational framework, or by looking at how it shifts the entropy of the distribution of inferred meanings \cite{degen20200406}. There's still a time course issue, in that excess informativity might be efficient if the additional early information is easier to produce or makes the search problem easier, both of which could be true if color is salient. 

On the other hand, in some situations, phrases that would be considered ``under'' informative, may still be highly effective at communicating the target, because of conventionalized pragmatics. However, whether or not speakers use these pragmatically-licensed short forms may depend on how costly it is to calculate the implicatures:  \cite{baumann2014} argues that in RSA-style environments, speakers often produce ``over'' informative expressions because calculating the implicatures is costly. As long as listeners rarely delay or misinfer because of this, these longer utterances may be efficient because the reduced time to produce them may outweigh the increased articulation time. 


The flip side of ''redundancy'' is ambiguity: many, many utterances are ambiguous. In general, strong contextual factors render the ambiguity a non-issue \cite{piantadosi2012}, but this means we can't judge language out of the physical and social context it is used in. 

An implicit set of constraints in the redundancy literature are those of semantic or syntactic well-formedness: why not say ``blue'' instead of either ``blue one'' or ``blue cup''? Perhaps it's because that's less natural to produce or comprehend, but if we have to appeal to those factors, then it's not just about information content, it's also about expectations about form or production and processing constraints. It's also likely about context: in a speeded matching game, ``blue'' might be much more felicitous because the expectations of well-formedness are decreased by context. 

There are layers here: languages are plastic and syntactic properties can be shaped over long time scales by usage \cite{hawkins1995}. At some point, that ordering becomes grammaticized, and then, even if it would be efficient to break it on an information-theoretic level, it would be effortful and surprising to do so. Different languages have different grammaticized orderings, and so different efficient usages \cite{rubio-fernandez2021}. 

In sum, determining what is an efficient usage may be difficult because it requires not just analyses the words said and their alternatives, but also production and comprehension time, which may be highly contingent on contextual factors and conversational history. 

\subsection{What does efficiency have to say about reference and pragmatics?}

My primary interest here is in pragmatic language use in the domain of reference, so what expectations does an efficiency framework impose on reference and pragmatics? 

This is a context over short time scales, so the wider meanings of language can be treated as static. 

What types of communication utterances are efficient should depend significantly on the context and communication channels. In particular, if interlocuters can interrupt with questions, or cut off a speaker by selecting a referent, then incrementally efficient utterances make sense \cite{gibson2019}. In other contexts, with lower feedback, it might make sense to more evenly distribute information content or rely on surer, but longer descriptions, if there isn't an option to add elaborations contingent on interlocuter behavior. 

The stakes of an interchange should also matter, by specifying where along the effort-informativity frontier interlocuters should be. This may not always cache out as the effort to determine how precise is necessary may exceed the cost of being heuristic levels of precise. 

It's very hard to cache out specific predictions because of the many time scales: what's efficient for an utterance or conversation in isolation may not be efficient when considered over an entire life of language use. We would have to measure how much people adapt to different conversational situations and stakes. 

Efficiency also predicts that a changing conversational history will change the context and thus different descriptions may be efficient. This could operate both by increasing beliefs that a certain utterance will be understood (and this is contextually low ambiguity) or more generally by shaping the syntactic expectations, perhaps making it easier to produce and comprehend odder descriptions. 


\subsection{Summary}
Here language use is being framed in terms of information transfer, so it's easy to consider primarily the content of an utterance. However, language is used in many ways, including for conveying relational or attitudinal information. This is still information and information-theory still applies. It's still part of the exercise in cooperative mindreading. 

Efficiency is particularly dependent on linking assumptions to join up very different sources of evidence. Thus the program could be seen as determining which linking assumptions work or don't work, and then assessing how reasonable and parsimonious the linking assumptions are. 

What actual processes and bottlenecks could be resulting in approximate efficiency? What are the processes of diachronic change? Tends not to get too into the weeds

\cite{bybee2006} argues that it is possible that encoding linguistic events into memory and then retrieving them could be an efficiency-inducing mechanism. While they frame this in terms of frequency effects, it would also be compatible with predictability effects to fit into a more information-theoretic framework. 

This is very much a question of looking at an ``end'' result and theorizing about how it came to be, which means that theories are hard to test. The goal is to determine what functional constraints could have shaped language in this way \cite{futrell2022}. However, there is some historical linguistics evidence that can be brought to bear, as well as possibilities to compare to hypothetical baselines. When high level theories cache out in behavioral predictions for how people use language, these can be tested in communicative environments or language-learning and transmitting games. 

Many of these examples rely on comparing extant languages and language systems to some theoretical languages and observing that observed languages are much closer to the efficiency frontier than would be expected by chance \cite{futrell2022}. 


\section{Communicating}

There is an extensive literature on communication and conversation, including a number of studies and theories focusing primarily on establishing reference and referring expressions. This literature has provided useful descriptions characterizing how interlocuters often interact in various natural and experimental situations. However, the theories that in this area are generally verbal theories that hypothesize ``mechanisms'' or principles, which either contradict the data or do not make risky predictions. Many of these theories take a deterministic approach, not directly dealing with the inherent uncertainty and probabilistic nature of interacting with other minds. Despite these shortfallings, I will briefly touch on this literature and try to extract some interesting questions that could be explored further. 


\subsection{Is this just about language?}
%TODO this section might belong elsewhere


One key question that comes up is whether the studies of dialog are studying spoken, face-to-face use of natural languages used by humans who intent to communicate, or whether this is about some larger domain, of communication more broadly. 

This question of whether we are studying communication or language is also tied to an (empirical) question about how modular language production and processing are. Language and the language facility is highly specialized, but how much domain general cognitive processes are used in creating and interpreting language? To what extent do non-linguistic signals influence linguistic production and interpretation? 

TODO CITE YOON ABOUT DISFLUENCY INTERPRETATION

Prior work on communication has varied in whether it frames itself as being about language per se or language as an instance of communication. 


Even within language use, some traditions privilege in-person oral communication \cite{clark1996}. 

TODO state positions of various works
\cite{clark1996} at least brings up for me what delimits language from other forms of signalling

\cite{pickering2004} seems to at least implicitly think that language is modular in that their theory is built around aligning on levels of language; some of the commentators (such as krauss \& pardo) point out that language is not this modular or automatic in that it can be influenced by non-linguistic cues and background. They also point out that language can be used strategically. 



My take is that language should be considered as an instance of communication, and thus, the general things should also hold for other forms of communication (drawing, gesture, etc). But, there's a lot a lot of conventionalized stuff around language in particular that makes it a) an interesting area to study and b) have some complexities that may not exist as much for other modalities. Determining what qualities are more communication general and which are specific to language (perhaps due to the high level of conventional language) and how habits from different modalities influence each other are all interesting. 

Comparing across different communication modalities and communication channels with different affordances can offer insights into communication. \cite{foxtree2013} examines different remote communication methods, including where different channels are used for different people. 

\cite{hawkinsa} studies convention formation over repetition with drawing as the medium, and finds many similar patterns to how language changes over repeated reference. This suggests processes such as reduction and alignment with partners are modality-general, although they play out differently depending on the affordances of the medium. For both drawing and language there are culturally built up habits about how things are typically represented. Drawing, some is still cultural, but more is human universal based on perceptual stuff, rather than language where the conventions are more language specific. 

Even color is a modality that has some conventional meanings and can be used to communicate \cite{murthy2022}. While some theories can be language-specific, they still should not be incompatible with results from other domains. 



\subsection{how much do people explicitly model others knowledge?}

A big question that comes up with conversation, and interactions between agents more generally, is whether and how agents are tracking other agents internal states of knowledge and how this factors into their interaction. 

\subsection{Mentalizing/CG approach}
One broad approach is the say that humans develop some sort of mental representation of other humans as agents who can have different mental states. Basically, that there is some tracking of someone else's representation, and that this develops fairly early around ages WHATEVER. 

This still leaves a lot of scope for how these representations are implemented, how information gets added or modified, what exactly is tracked, and what processes refer to these representations, rather than use heuristics. 

A frequently used term in discussing shared knowledge states is "common ground". This term arises from logical traditions of speaking of information being private or mutual, or common, where "common" means that it is shared by both and each person knows the other knows it etc for infinite recursion. This is to contrast with the possibility that there could be information which is mutually known, but where it is not known to be mutually known. (One observes that carefully distinguishing between recursion depths is not practically needed.) In other reasoning, people only use a couple levels of reasoning, and so a distinction between "I know it, and I know you know it, and I know you know I know it" may be roughly the maximum that people can actually track.) TODO cite Degen

In formal semantics, there's work around this which because it clearly can't explain much language uses, builds up an entire idea of ``accomodation'' (for instance around definite articles). 
CITE horton1996 as an example of this absolutist approach

Since that infinite recursion is clearly not what is going on mentally when we figure out what knowledge is reasonable to treat as background when talking with someone, Clark theorizes some other ways for information to be introduced into the common ground. (One notes here that "the common ground" is not something anyone has access to; instead, each interlocuter may have beliefs about what is "in the common ground" and available to build off of). 

TODO LIST OF WAYS OF INTRODUCING THINGS:Other approaches [TODO CITE CLARK USING LANGUAGE] Some of the trickiness comes from that no interlocuter has access to the veridical common ground. Instead, a person may have beliefs about what is in the common ground between them and their partner, but it is possible for them to be mistaken. It's also possible for them to be unsure. The proxies described by Clark will sometimes lead to the erroneous belief that something is mutually known when it is not (let alone any meta-knowledge). Alice may think that Bob knows about something because he looked like he was looking at, but he might have been daydreaming or he might have forgotten. Additionally, Alice might think that all doctors know XYZ and so that if Bob is also a doctor, then XYZ is mutually known. People are frequently mistaken on these points. Thus, what we care about for understanding conversation is not some platonic ideal of common ground, but instead what each person thinks the other shares in a sufficiently public way. 

have tried to list circumstances in which people can assume that something is common ground, such as various forms of co-presence, or if something is common knowledge within a community. However, this approach still considers common ground to be a discrete thing. 

 these are generally reasonable, but none of them are foolproof. There isn't generally a way of knowing what another person knows in these absolute terms. Rather, there are heuristics that we can rely on to make good guesses about what someone else will understand, but this requires abandoning any of the attempts to salvage of technical definition of common ground. 

%TODO hanna2003 has a sane definition of CG
A pre-theoretic notion of "things you think another person will understand and won't be surprised if you reference" is a useful one and is sometimes what is functionally meant when people write "common ground" \cite{leung2023}. However, this is an unfortunate use of the term when many people use common ground in some theoretically loaded way. However, imposing a softened, probabilistic frame onto this idea of expected-to-be-shared information is a useful description where determining the bounds is a useful research program. 

In other areas, the roughly same set of content is said to be "given" to cover both background knowledge and information that is presented to both participants at once \cite{fay2010}. 

%TODO other terms like "conversational pact" also seem to be used both theoretically and descriptively

%TODO difficult to infer intent and representation from just behavior


\subsection{Aside for the non-mentalizing alternatives} 

TODO good, but should probably be shorter and less ranty

Despite evidence that suggests that mental modelling is an easy and common thing people do, an alternative theory to mentalizing approaches called the interactive alignment theory attempts to explain how people can successfully collaborate and use the same referential descriptions as their partner without reasoning about each other's mental states. They acknowledge that it is possible to reason explicitly about others minds, but think that is a taxing option only utilized under rare circumstances. As they use it, this strikes as a motte and bailey argument: their motte is that conversations generally proceed by their automatic priming mechanism, while when challenged, they retreat to the safety of the uncontroversial bailey that explicit mental modeling is not the only factor at play in conversation (i.e. there may be caching and heuristics).  

%It is not clear why \cite{pickering2004} assume that mental modeling is costly. Much research in social cognition and theory of mind points to people having pretty good heuristics for keeping track of what others know. This seems contra to many things, including that people are readily able to learn new words (which somehow involves mapping someone's intent to the words) (CITE SCHOBER COMMENTARY)

I find many of their claims hard to understand, and wonder if some of this might be a levels of analysis thing, a difference in definitions, or a preference for different questions of interest. 

On a levels of analysis question, it seems like \cite{pickering2004} are presenting a high-level verbal descriptive theory when they use terms like "priming", but they in their title and throughout the text seem to think they are providing a "mechanistic" theory. \cite{pickering2004} claims to be providing a "mechanistic" explanation, but no mechanisms are to be found. They claim that the alignment process works by "priming", but priming is not a mechanism: it's an umbrella term for a phenomenon whereby the presence of one stimuli has an effect on someone's future behavior processing speed, due somehow to the relation between the stimuli and the later action or stimuli. Mechanisms in terms of memory activation, or other processes are implicated for some types of priming, but calling something priming is a description, not an explanation or mechanism. In particular, their claim that the priming on one level somehow spreads to other levels, including outside of language, was criticized by many of their commentators. They also claim that this "priming" is "resource-free and automatic", without providing a further explanation of what this means or how this is working on the level of processing, memory, and production. 

However, to the best of my understanding, their account really is about how interaction is "priming" coupled with some mechanism for overlap on one level (ex. lexical) to lead to overlap on others (ex. syntactic). These papers tend to focus on somewhat different experiments such as their maze task, where people are cooperating with the same role, and thus may be more likely to both talk in the same way, compared to work from more mentalizing traditions that tend to use asymmetric matcher/director tasks. In the matcher/director tasks, it is clear (dating back to \cite{krauss1966}) that speaker's behavior is influenced both by listeners utterances describing the image, but also by their non-aligned responses such as saying "mhm" or making correct or incorrect selections. The interactive alignment account crucially cannot explain the effects of these other backchannels, and so is forced to explain them away as insufficiently "basic". 


The ideas of \cite{pickering2004} are (distantly) related to some much softer claims that are more likely to be actually true. One kernel of reason is that usage increases the accessibility of a representation (\cite{macdonald1994}), or that the joint association between target, word, and interlocuter are encoded in memory. These processes are non-mentalizing operations that may lead to convergence in the use of words or constructions. A weaker (and more reasonable) interpretation is that production and comprehension share some things like the same memory and track usage statistics including is ways that are dependent on time and perhaps also activated by the context of conversational partner.  Could even be framed that expectations are shaped by the local context, including the conversation partner. 

One big point of conflict between \cite{pickering2004} and many of the commentaries, is that \cite{pickering2004} claims that the priming process goes all the way up to the (non-linguistic) situation model. This is an espeical weakpoint in their theory, as it is leaving the domain of language, where some forms of lexical and structural priming are studied, and where domain-specificity could be invoked (TODO CITE BRANIGAN AND MARKMAN COMMENTARY). 

Reread gandolfi and add to interactive alignment
Newest iteration is from \cite{gandolfi2022} brings up a lot of "control" and monitoring and comparing 

unsure how one is predicting the others utterance without ToM -- is this is behaviorist thing? is the other person not being represented as an agent? or is this just a levels of analysis claim? (representation in general are weird and hard to work with)

I'm confused about this -- and what meta-representing is doing ; feels like a high level description that doesn't have a lot of specific explanatory power

focuses here a lot more on repair and meta stuff 
* "representation" which is a mine field -- what level of heurstic, conscious etc I'm going to be agnostic to, but others may not
* possible to have heuristics around interactions and be a lot less sure about things

TODO really I'm mad that I had to read and know about this nonsense

\subsection{partner specificity per-se and how to get that}
Within reference games, there are claims about partner specificity. Sometimes things are called partner specificity even when there is only one partner because pairs evolve in their language use over time, and different pairs evolve differently. In other cases, there is comparison between how people act with different partners or in situations where the knowledge states of partners is experimentally manipulated. 

The empirical evidence seems to point to people doing ``partial pooling'' over partners \cite{hawkins2021}. That is, there is some variation in how people interact that is specific to the partner, but people are also doing some generalization over partners \cite{yoon2014}. 

How does a speaker decide how to address multiple addresses at once? \cite{yoon2018} lays out discrete possibilities such as targeting the most knowledgeable or the least knowledgeable. These are useful baselines to compare to in trying to understand what speakers do, but the actual evidence points to some gradient that depends on how many knowledgeable and naive listeners there are.  Really one would expect some sort of more complicated functional landscape that depends on how many listeners there are, how discrepant their knowledge is, and whether knowledge states are not nested (that is if an overall less knowledgeable listener has relevant knowledge that a more knowledgeable listener does not). The verbal theories were useful for initial experiments, but they aren't enough to make clear-cut predictions. 

While fitting the at least 3 dimensional functional model may be hard, there are more preliminary questions about what happens for various boundary cases. Other work by Yoon shows that people seem to track people and context interactions at least with groups of size N TODO. It seems likely that this would degrade a groups get bigger and it's harder to track individual identity, but it's an empirical matter how large groups have to be to degrade performance (and presumably also depends on other load factors). 

There are also linguistic options for talking to a group of different knowledge backgrounds, such as using both the name that one person will understand and a elaborated description that will help another person get on the same page \cite{yoon2018}.


in general partner specificity seems like it will be constrained by factors such as working memory, task switching and bottom-up attention (might need to inhibit responses) 


\cite{yoon2019} there may be task demand issues in terms of what the function is for how much to include everyone (based on task and incentive might be better or worse to slow down and include everyone versus not) even if these aren't explicit, might be transfer from other situations. 

sort of relates to the ibarra, but \cite{yoon2019a} points out that there's knowledge-scene integration where interlocuters take into account the physical perspectives and contexts of their listeners and how that interacts with the knowledge states. This is probably a think that takes working memory, so might see declines if the people-context stuff gets too complicated, but it points to a lot of this being pragmatic and shaped by top-down non-linguistic factors about what to do. 


\subsection{Audience design}

%TODO consider combining audience design and partner specificity 

\cite{horton2002a} Here they make the assumption that audience design is only sometimes needed and is osmething that is uniformly an increased in the verbosity. So what's the default. You're always talking to someone, except/even if talking to oneself right? 

\cite{horton2002a} usefully points out that partner specificity should occur mostly in cases of low codability, which I'd elaborate as being low codability in context since context will matter here!

Two possible components could be  responding to interlocuters cues about their understanding (if they express confusion say more), and making good guesses about what they will need to understand based on shared history and inferring from their demographic features (these are different!) 

\cite{horton2002a} useful distinction between lexical entrainment where it's the exact word used again versus conceptual similarity which doesn't need the same exact words, and can generalize (double check if this is in there are my thoughts) 

is incorporating things initially contributed by listeners a component of audience design? 

\cite{horton2005} makes the (reasonable) claim that conversation partners act as cnotextual cues for retrieval of associated information (shared history stuff, not demographics) presumably via episodic memory 

\cite{horton2005} how well you can design utterances from your audience depends on how well you can know what the other person knows

\cite{macdonald2013} talks about audience design in the form that things may be beneficial to comprehenders, but still be driven by the producers needs, in that they produce what they can produce with fliency and without difficulty (rather than let the conversation get slow or repetitive) 

\cite{rogers2013} raises the point that it may be difficult to tell what is strategic and what arises as a result of incremental social interaction (although it's really unlikely to be fully bottom up) It's also possible to have a strategic incremental approach (this is what's probably happening) where there is integration and monitoring of the other people. This like everything else fails to explain reduction. 




Reference game interactions often seem like speakers are being sensitive to the knowledge state of their listener and trying to make the task easier for their listener in what they say and in what order. This apparent phenomenon gets called audience design, but confusingly, it is sometimes meant to imply intention on the part of the speaker and sometimes used even when it is unintentional, and the utterance was likely shaped by speaker ease, with a side effect of listener benefit \cite{horton1996, rogers2013}. 

The problem is that usually speakers and listeners have the same recent context, find the same things salient, and linguistically what is easier to produce is often easier to process. 

There is an important question buried here which is ``how do interlocuters split the communicative load with one another?''

From an efficiency perspective, one would say that we should work to equalize effort, by reducing whatever the largest bottleneck is, which might set a general standard for how the load is usually split. But depending on the interlocuters relative abilities in the moment, different splits might make sense. For instance, when talking with children, the adult might take on more of the load in either role. Or when there is a limited channel and one person cannot communicate as well, the other might take on more load. 

\cite{yoon2019} when there's feedback there's option space for speaker / listener effort splits how does this work 

\cite{clark1986} when there is room for feedback, speakers can do less planning knowing that a listener can interrupt or offer suggestions that the speaker can then accept or reject. 

\cite{fay2010} "minimized collaborative effort" (will need to go back and check but notes on: what sorts of interaction define something as being communicative intent, what sort of feedback) use of "givenness" as probably slang for some sort of cultural CG. getting to be more adjacent to some of the network-y stuff that Robert does (but see notes if needed) 


TODO there might be more that goes here 

\subsection{convention formation}
One specific phenomena where a lot of this plays out is in partner-specific convention formation where over repeated reference people will develop short-hand nicknames for objects they are talking about TODO CITE A BUNCH. 

This is a key phenomena to try to explain. 

\cite{leung2023} points out that forming a convention can be thought of as preceding in two stages: first some referential expression must succeed in communicating the target, and only then can that expression turn into a more reduced form. Thus, there's both the question of how people initially decide what to say to communicate, and also, how people decide future utterances based on the shared history of a successful utterance. 

The idea of convention formation or a ``conceptual pact'' is ambiguous between different levels of analysis: it could be a pact to refer to a figure as ``ballerina''; it could be thinking of the figure as a ballet dancer with a tutu (manifesting in descriptions that may not overlap lexically, such as ``ballerina'' and ``dancing in a tutu''); or it could be a general principle to think of the figures as people as describe them in terms of postures. Expectations on multiple levels can coexist. 


One observation is that they seem to be people specific. In referring to things, there is a general expectation for a person to be consistent, and to not suddenly to a different description, whereas this may be accepted from a new speaker \cite{metzing2003a}. It's unclear whether this expectation is purely for the lexical items to remain the same, or a broader expectation for the conceptualization to stay the same, or some of both. \cite{ibarra2016} shows that the conventions are also context-specific, new context can reshape how people perceive the objects and result in the use of new labels. 


\cite{piantadosi2012} has me wondering whether conversational pacts are even real, or whether they are actually just contextual reduction is ambiguity and them peaking of the distributions in a slightly recursive way plus some recency effects and habit. This approach requires that speakers and listeners have similar models of language and the world at least in the relevant domain so that they can use contextual information to constrain the situation 

\cite{piantadosi2012} in line with RSA assumes that inference is cheap and that context and speaker goals are constantly taken into account 

\subsection{summary}

The communication and convention literature has characterized what happens pretty well, but doesn't make theories that make predictions over a variety of situations. 

TODO

\section{Probabilistic models of pragmatics}
%STATUS: also pretty solid, needs some more lit search

Another vein of research for thinking about communicative utterances is modeling interlocuters as (approximately) rational agents who recursively model one another. There are multiple versions of probabilistic models in this stream, but I focus here on the Rational Speech Acts framework and family of models. This set of models has been used to model some instances of ad hoc pragmatics as well as conventionalized pragmatic implicatures. 

\subsection{Basic framework of RSA}

RSA is an information-theoretic, computational framework for making quantitative predictions about pragmatic inferences in context \cite{goodman2016, frank2012a}. The basic idea of the Rational Speech Acts (RSA) family of models is to picture two interlocuters recursively reasoning about how the other would produce or interpret utterances, grounding out in a listener (or speaker) who behaves in a pre-specified ``literal'' way. This framework is usually run with one or two levels of recursion, where it tends to produce a reasonable fit to human experimental judgments, consistent with work finding that most people reason pragmatically at a low recursion depth CITE DEGEN. 

The basic idea of RSA is to specify some level-0 listener whose lexicon is specified in some way. From there, the speaker reasons about the listeners lexicon, and samples an utterance that softmaxes their utility function. Then, a pragmatic listener reasons about how to interpret an utterance by softmaxing a meaning given their model of the speaker and literal listener. This is a fairly basic framework, but many of the chunks here can get quite complicated when necessary. 

Different models in the RSA tradition incorporate different sets of components in the models. Models generally include a utility or informativity term that relates to how well an utterance resolves uncertainty in favor of the target referent.  It is common to also include factors such as the prior likelihood of referring to each target (salience prior) and some cost on utterances where longer or more complex utterances are penalized \cite{goodman2016}. Some models also go beyond informativity, incorporating options to infer the question-under-discussion CITATION or for speakers to balance informativity with politeness.

In some sense, a fully RSA model would incorporate all of these components and also infer their weights. However, for tractability, usually only those features that are considered relevant to the domain of interest are included.

Because of the flexible framework, it is possible to model many sources and levels of uncertainty, and then integrate out that uncertainty to make predictions, but also update on the sources of uncertainty in response to input. 

\subsection{advantages of a computational framework}

Verbal theories seem to suffer either from being too dogmatic and thus lack explanatory power when their predictions aren't met, or if they do consider trade-offs between multiple influences, they don't make risk predictions, and then lack explanatory power because they could have just as well explained many other things. 

Computational frameworks such as RSA provide a way forward because trade-offs can be factored together and weighed in the models. One could imagine trying to write models for constraint theory that specify all the constraints and try to determine their relative weights. Actually writing these models may be impractical, but it at least provides a mental framework for thinking about relative weights for different trade-offs, and whether the same set of weights could apply cross-situationally, or whether there would need to be hyperparameters. 

Similarly, while Gricean maxims are a useful descriptive starting point, they're underspecified and usually in conflict with one another %TODO cite grice 
Some of the terms in RSA models could be seen as analogs that weight information against utterance cost %TODO what even are the maxims

One additional benefit to RSA and similar models is that it's very easy to incorporate variability and uncertainty and to output graded quantitative predictions (in theory, computational tractability may put a damper on this). 

\subsection{What about semantics?}

Perhaps the largest challenge to RSA models is the question of how to ground out the models in a ``literal'' listener or speaker. For the most part, RSA is tested in toy domains where the set of possible utterances are small and it is possible to enumerate a set of meanings.

One option is truth value lexical semantics where each object-label pair is either true or false CITE, which works well for objects that straightforwardly either have or do not have certain properties (color, shape). This ceases to work as targets decrease in nameability or if prototypicality effects occur. 

An alternative is some sort of soft or continuous semantics where each object-label pair has a value between 0 and 1 \cite{degen20200406}. These semantics can be used to indicate that some properties are stronger than others, by using higher values for color than for size. This soft semantics that reflects informativity is used to achieve a computational model of ``redundant'' referring expressions. %TODO look up exactly how this worked
However, soft semantics still run into the issue of compositionality: either every possible utterance must independently receive a degree of match with every possible object in the prior, or the prior needs to include rules for how to determine the match of a whole utterance on the basis of the match with each component. 
In a later experiment of \cite{degen20200406}, typicality effects made compositional semantics not work, but the utterance space was small enough that each utterance could be treated individually. 

Treating utterances holistically sidesteps the compositionality concern, but this is not scaleable and conflicts with incremental RSA. Incrementality-based accounts are necessary to explain informativity-based ordering preferences CITE. 

To account for more real-world situations, we would like to be able to handle both a large range of possible utterances and situations in which the ordering of information matters. One strategy in communication might be to keep describing an object until the listener chooses an object, but this would require an incremental system that iterates the process each time chunk.

One could see this as saying that we first need to solve semantics in order to do pragmatics. I think a more productive framing is to try to figure out what a model of semantics is that could support RSA models of the pragmatic language use that we observe used behaviorally. 


Some big questions are how to scale this up to accommodate a larger space of possible utterances and meanings, which crucially requires figuring out how to do compositionality. What happens when targets do not have straightforward sets of properties? 

%TODO goodman2013 also for what the right literal meaning is 

%TODO re-look at bergen for what semantics is required to get costly utterance -- rare meaning correspondence 

In order to extend this model towards more realistic and open-ended scenarios, an important question to grapple with is what form of meaning (even at a computational level) will appropriately support pragmatic reasoning. 





\subsection{attempts to grow it bigger}


For now, some of how RSA family models can explain different phenomena is that the literal semantics are customized to each situation. In thinking about what a more general RSA system could look like, this is the point of incompatibility that needs to be solved. 

Some form of soft semantics is likely to be needed to handle metaphoric descriptions of hard to describe images (such as tangrams). It's also unclear how to scale up 
%TODO
% idea of soft semantics is necessary for dealing with tangrams where truth value semantics is unlikely to cut it -- then the specificity and truthiness of the description bits is what's competing 
%TODO will need to read more about what the scaling up attempts have been

One attempt to more directly connect RSA models with convention formation is  CHAI \cite{hawkins2021}. CHAI is a framework that tries to bridge the levels of conventions from partners to networks and societies. 


%how to do alternatives

%computational intractability


\section{Psycholinguistic considerations}

\subsection{Case of disagreement: what influences the time course of production / comprehension }

Many of the theories have implicit assumptions about what the timeline for production or processing of language looks like. These theories vary in their testability, but it is worth thinking about what assumptions they make and how that fits or does not fit with our current understanding of language production and processing. 

This has not stopped people from making these claims. One argument is whether initial utterance planning is ego-centric or whether interlocuter's perspectives and knowledge states are available for initial language planning. TODO cite Horton \& Keysar attempt to test this, but acknowledge that monitoring and fixing of the utterance, including pre-initiation of the utterance, may take into account the listener's perspective. %TODO say more about the egocentrism thing

Parallel to the egocentrism debate in production is an egocentrism debate in comprehension. Basically, the question is whether an intial stage of comprehension is egocentric, that is, not taking into account non-linguistic input about other's knowledge state or intent. This was primarily studied using eye-tracking as a proxy for interpretation, which is problematic as we don't understand fully what eye-movements mean TODO CITE JUDITH. 

It is unclear to me what an egocentric perspective would even really mean, as language primarily comes from individual other speakers, so receiving input from a `generic' speaker is not the norm. From a developmental perspective, children figure this out %TODO cite

In any case, \cite{keysar2000} argues for an initial egocentric perspective on the basis that people often intially look at objects that are good matches to a description that are not mutually visible with their interlocuter. They seem to be assuming that if people weren't egocentric, people should have very strong priors that interlocuters only refer to things that are mutually know, which is clearly false (why ask where something is if you can see it?). 

The counterpoint presented by \cite{hanna2003} is a constraint-based theory where many factors can play into comprehension, including working memory limitations. 

Underneath the poor experiments and strong positions are a number of interesting and complicated questions. It seems clear that many factors can sway comprehension, including both "top-down" and "bottom-up" processes, and understanding the relative mix of these factors could be very interesting. However, it's a difficult empirical matter to disentangle all these factors and a number of nuisance experiment parameters especially when the measures we have are far removed from the constructs of interest. 



\subsection{How does production even work}
* what even is a model of production that we can work with / how do search problems and other ~algorithmic constraints constrain higher-level theory

It's easy to get evidence of what utterances people produce under various circumstances, but much harder to figure out how those utterances were planned. As a result, there are many vague models of how language is produced and flimsy linking assumptions about how these models predict speakers will behave. 

One assumption is that introducing time pressure by telling someone to respond faster will change the production process in a way that limits later steps more than earlier steps. Clearly, time pressure and other resource constraints do affect production as can be seen by differential responses in constrained versus less constrained circumstances. However, given that we do not have a good production model, claims about the mechanism by which time pressure and other constraints influence production are weak.

Production processes can cause deviations from the ideal utterance because of the need to generate potential utterances, including search problems related to retrieving the necessary words in time to construct the utterance. As CITE LEUNG points out, when referring to something, we need to do at least three things as a speaker: generate any description at all, have a description that is good enough for the target, and have a description that doesn't overly match competitors. RSA discusses how to choose between utterances, but in some cases generating any description or a good enough description is non-trivial, and not well studied. How do people produce candidate descriptions in the first place? 



These implementation constraints are where the bounded part of bounded rationality comes in -- we expect RSA-style to be a good high level model, but it's not an implementation and is agnostic about what parts are cached and at what level things are cached or short-cutted. 

Everything is probably more continuous than these things posit. It's a probabilistic world of bounded rationality and heuristics to fill in gaps. 

The big take-away here is that we can't fully deal with these theories without testable computational models of production. %TODO whats SOTA on production modelling

There's interplay between production, comprehension, and what the typology of the language is, that constrain the options for a bounded rational approach like RSA. \cite{macdonald2013} provides a functionalist account claiming that utterance planning is difficult, so speakers have biases in their production. These biases are easy first, plan reuse, and reduce interference. Taking into account both word-level and context-dependent factors, easy first seems to accord with memory retrieval theories. %TODO say more about other parts 
Under this model, these speaker patterns drive typology and the statistics of language, so comprehenders rely on these statistics of input to make predictions and do pragmatic interpretation. 

\cite{heller2012} disagrees and says that speakers have a harder time than listeners b/c they need to model the listener (at least approximately) %TODO re-read heller

One issue with any `which came first and is the driver' arguments is that language is a cultural artifact and doesn't ground out in something external. There isn't an external set of statistics for the language system to be adapted to -- the statistics are also generated by the language system. Thus, as an empirical matter it is difficult to figure out which of comprehension and production is `driving' statistics, as both are under pressure to be calibrated to the another. This calibration is similar to the difficulty determining the division of labor in audience design, just on a different granularity of analysis. 

To avoid circularity, \cite{macdonald2013} claims that some of the production pressures are related to specific mechanistic aspects of memory and domanin general features such as saliency. %TODO reread macdonald and check 

One way to disentangle may be to look at situations where what is easy to produce and what is easy to comprehend are different (CITE Ferreira commentary on \cite{pickering2004}). 

\subsection{Interim summary}

Going from the computational level of bounded rationality to the implementational concerns of psycholinguistics allows for the exploration of what the bounds and heuristics may be. Humans have huge amounts of linguistic experience, which could lead to a lot of cached heuristics. In many cases, these heuristics may be incredibly useful for being able to communicate rapidly, but they may also be suboptimal in some cases. 

Production and comprehension are the processes that pragmatics and also efficiency in language flow through. However, it is difficult to know what mechanisms are going on when the main sources of information are what happens under load and what the time course is. 

For comprehension at least, there's a history of parsers and so some models (TODO CITE), but what is there for production. 

%TODO at risk of scope creep is there a review article on comprehension or production 




%\cite{hanna2003} Looking at the time course of using the speaker's context in processing. Bug questions around whether people are initially egocentric in their interpretations. Makes some weird assumptions about what's required to take other's perspective, on a more mechanistic level, without paying attention to the possibility for some cached heuristics. 
%
%What would an egocentric perspective really be? Language only exists in relation to others (mostly), so how do we think about word meanings in the absence of considering the speaker (clearly there is some way of doing this, "generic speaker", whatever, but I don't know if it's well understood) there's probably also an interesting developmental component -- what's the interplay between language development and ToM development? 
%
%
%For the whole egocentricity timeline stuff, there's a big question of what things factor in how much when and how much that gets pushed around by other constraints such as working memory etc. There's multiple dimensions here (not to mention the many nuisance ones), and we don't have many points of experimental evidence. 
%
%\cite{keysar2000} makes assumptions that we know a lot more about processing and how to interpret eye-movements than we in fact do. Seems to assume that people should have absolute assumptions that what is communicated about will be mutually know via being in mutual view. This is dumb and in real life is never going to be that strict -- it is possible for people to refer to things that are out of their sight at the moment and even when you don't know that the know about it. That needs to be within the considered distribution. Seems to be that the questions are about the relative mix of top-down and bottom-up processes when searching for a visual referent. 
%






\section{Useful approach: What I think is true}
Theories should be clear about what level of analysis and scope of explanation they are trying to provide. Theories that are compatible with other theories operating at different levels of analysis and that are compatible with the theories and evidence from adjacent fields are preferable. With that position, here's my distillation of what theories are most promising to me. 

At a broad-strokes computational level, abstracting out language-specific constraints and the details of production and processing, I think that RSA-style models are promising. These theories allow for probabilistic integration of the many linguistic and non-linguistic sources of information that are at play in conversation. It can accommodate different goal states as well as varying levels of certainty about anything.

% Many versions have successfully matched behavior in limited domains, but there are many factors that are in play in some situations and ideally they would exist in the background of models the rest of the time. Computational tractability becomes a problem if there are actually included, but it most cases, it seems like considering these other factors and then neglecting them is reasonable. 

Some particular challenges for using RSA in practice are the various ways that communication is open ended: it has open vocabulary, open issues of compositionality, open number of turns, and (with spoken language) is highly incremental with options to take actions or interrupt mid sentence. As it becomes more open-ended, issues of how to consider alternatives and the psychological implausibility of actually considering all of them may come into play. A resource-rational approach that uses sampling instead of exhaustivity may provide a way of pushing this computational theory down into being slightly more concrete. 

In terms of theories of interactions, I favor partial-pooling models that treat people as keeping some track of the individuals and situations they interact in while also showing some transfer-learning and generalization across people and contexts. How these two factors balance against each other is an interesting empirical question. 

I believe that people are fairly sophisticated at modeling the knowledge states of their interlocuters, probably through some combination of explicitly modelling knowledge the use of good heuristics. Many of these beliefs may be graded, and many be on the basis of a heirarchical framework of what knowledge tends to be known by what categories of people.  Cultural norms around givenness are something that must be learned jointly with other norms about symbolic communication (primarily language). 

Pushing down levels of analysis, resource-rational models should embody some of the constraints from feasible memory retrieval, production, and processing. Some of these will be from domain general processes (memory retrieval) and others may be about the language system in particular. 


Another source of constraints for implementational levels is how the language production and processing system works -- what possible utterances are and how they are produced and how things can be structured are constrained by language. 

Broadly think that efficiency is a driving factor and seems to have broad explanatory power, although we have to think about how it plays out in any particular situation. 

For communication, we could see efficiency as manifesting in trying to optimize bits of (goal-relevant) information conveyal per unit time. Conversation is a complex process so there's a lot going on: there's a mapping of goal to relevant information (which might be lossy), the speaker then has the access words to produce (which may not be easy for descriping low-nameability referents), and produce them. The comprehender then has to parse the string, interpret it (along with whatevever pragmatic integration is required) and then take an action. Often efficiency is established on the basis of how long the words are, but in some cases saying more words may be efficient if it reduces production costs or comprehension costs (making the task easier, or making it easier to understand by being nice to the parser). 

We don't have computation models for how to cost all these pieces against each other, so for now it's hard to verify these things. 

Different situations (experimental and otherwise) will induce different goals and provide different affordances; good models will have the ability to make predictions over a range of situations. 


When considering repeated reference especially for difficult-to-name targets, I think there's a productive split between what is needed for 'first contact' -- establishing an initial successful reference -- and what drives subsequent references, where reduction and changes need to be accounted for. One key distinction that doesn't get explicitly highlighted much (but is brought up in some recent work, such as \cite{leung2023}) is that the process of `first contact' -- establishing initial reference -- is at least somewhat separable from the repeated reference / reduction phenomenon. They're probably not totally separate as the same systems will need to work for both, but there are probably peculiarities to the reduction part. 

Listeners and speakers are (usually) engaged in a cooperative activity, and it is possible for them to do some load-balancing between them depending on the situation. 

From audience design: speakers take into account the whole set of listeners who are present -- tend to tailor so that all could understand, but use meanings/shorthands that knowledgeable ones will recognize (=> many possible ways to accomodate multiple listeners, perspectives, also consistent with a name \& describe that's good for future) 





A few directions that seem useful:
* start at RSA and attempt to scale up to accomodate conversations (tackle the open ended things)
* try to figure out what the bounds from memory / processing / production are and push a model down to a more resource rational / sampling based implementation
* something something extend theories to how groups work?



\section{Open questions that aren't satisfactorily answered}

Why the reduction curves we see? why not flat? or much sharper? 

how to bridge information theory/efficiency with syntactic/habitual expectation of language form 

whats the memory component over time? like if you asked people who had played the game to then later name all the figures? would they use the names their group had even months later? 

What are processing/production ways to get at cost and truthness of descriptions and also how are they sampled? 





%TODO look at kronmuller and barr MA (again?)


%TODO consider adding some cites from yoon2014 to the list, especially around constraint based 

%TODO zaslavsky -- confused on the details, but something about what efficiency is from an information-theoretic perspective 


%TODO consider constraint based models 



%TODO What's the SOTA in language production modelling? Utterance planning? 

%TODO Constraint based accounts of production (and comprehension) see \cite{hanna2003} highlights for suggested readings


%TODO forward search \cite{heller2012} since they're pretty reasonable about the idea of name versus what properties to include 

\subsection{Good: Unsatisfying ?: Explaining reduction phenomena}

For an efficiency standpoint it makes sense that the more something is referred to the shorter and easier it will be to refer to. However, this does not explain the process by which is occurs nor the partner-specificity that is observed. 

Many of the theories related to partner-specificity can explain how people succeed at establishing reference with each other and separately, why they persist in using shared terms. This too cannot explain how reduction occurs, since the reduction necessarily involves a change in how something is referred to (if only by dropping words). 

One approach to explaining how interlocuters might go from descriptions involving multiple components to fewer components is sketched in \cite{hawkins2021}. In a toy world with a limited number of utterances and targets, positing lexical uncertainty and TODO what the compositionality function is then applying RSA qualitatively results in the reduction pattern. Initially as each word has very uncertain meaning, using two that each slightly favor the target object makes sense because both is a much stronger indicator than either alone. However, each time they both are used together in this way, that causes a vocabulary update increasing the link between word and target. Once the link is strong enough, one of the words on its own is sufficiently clear that the cost of two words outweighs the now marginal additional clarification value. 

To the best of my knowledge, this is the only model that posits a computational mechanism that explains the reduction phenomena. As a toy model, it simplifies many aspects, and a line of modeling word could be gradually adding in real-world sources of complexity. For instance, what sort of semantics, both for the meanings of words and chunks, and for their compositionality, could support either the initial interpretation of long multi-part descriptions, and the updating required to eventually lead to reduction? 

Another piece is that reduction isn't just about shortening in the number of words or concepts used; it also tends to follow a stereotyped pattern, where more abstract, holistic "names" stick, while descriptions that may be more concrete or describe the image piece-mail tend to drop out. Why is this what happens?  Is there a way to model the initial semantics of these pieces and of the updating such that this pattern of what sticks is predicted? 

An additional complexity here is that the end point can vary. Usually holistic or analogic descriptions win out \cite{clark1986}, but this isn't absolute. Sometimes groups may use something strange and even something that is on a lower-level or on a meta-level as their referring name, and for them, this can be effective. So to fully explain this, we need to take into account the path dependency for how reduced utterances evolve, and potentially also account for issues such as people's relationships or humor value. 

Another desiderata from a computational model would be accurate predictions for the rate of reduction, although this too can vary greatly depending on groups. 

Overall, the high variability of reduction depending on images and group members and their interactions will make it hard to fully explain. However, even for a canonical instance of reduction, we have been limited to hand-wavy verbal theories. Now a promising model that can explain the pattern in a toy word, but incorporating semantics may prove challenging. (As it has elsewhere in RSA.) 



\subsection{Unsatisfying open ?: Groups}

Much of the literature is concerned with dyadic interactions, so theories do not often clearly predict what happens in multi-party settings. 
\cite{yoon2019} how much do you think of the group as a unit, versus as a set of individuals (obviously this is going to change some as group size changes, but what are the patterns) 

\cite{clark1996} focuses very much on dyadic interaction, and is in the vein that multi-person is serial dialog (verify this last part). 

how to extend ideas of joint action to accomodate multiple people? (re clark1996). 

One question is how you extend RSA up to multiple people -- how to do an utterance designed for multiple people? I guess you could represent separately and fit whatever joint function for optimizing that you want? 

groups allow for more complex structures. \cite{fay2000} tries to look at whether 5 and 10 person groups behave more like dialog or serial monolog (to the group) -- I think it's unclear that this is useful -- how do you define interactions / how do you usefully measure commonalities. There is a suggestion that there may be a transition point in how groups behave, possibly around 10 people, although context and goals seem very likely to push this around 

how to account for side conversations or parallel tracks which are available in some modalities (and not others) also other mediums such as fora / discord / slack have different affordances for allowing branching and parallel things that might be better for groups 

Groups can be complicated \cite{guilbeault2021} looks at how different sizes of groups interacting over a network structure result in different category boundaries, where large groups end up more the same than small groups. Brings up questions about network structure and how we should think about networks even within groups where multiple people are interacting synchronously. Some of the other try to only allow lines between points -- either bidirectional is dialog or single-directional in monolog but there's still the development of shared stuff from the co-presence of listening to someone else even without direct interaction? 

There should be some gradients in terms of these forms of more indirect interaction that aren't explained by dyadic models because the mechanisms that are claimed to support the partner specificity don't cover it (for in part being too low level?)

\cite{hawkins2021} for groups, how should we think about the pooling and updating based on the group -- have a different type of somewhat indirect evidence about the group members, although how indirect it is may depend on group size and structure and dynamics 

it's really unclear how \cite{pickering2004} would accomodate three people in their priming approach. can three people act as two people? 


One question is about the partner specificity of representations and how they may bleed together

This also interacts with other things such as ToM all of social cognition and the nature of memory representations 



\section{meta}

Maybe this should just be an interlude? 

What we need to make progress -- / why this was very frustrating 
coda on meta commentary which is maybe that we need more data and that it's all a mess 
* explanatory value
* levels of analysis
* experimental evidence

general meta-theory: when something is a new area, easy to make over-simplifiying models of here are the two or three ways it could work this is useful, but as a field matures, important to accept nuances.

useful sketch of some options versus reality / full messy space of options

Stronger if you have gradients (ideal if you have math model and can do something quantitative)

\subsection{ Levels of analysis and implicit versus explicit knowledge}
many theories are loose on what level of analysis they are addressing things out, and if there posit representations whether they mean that those are actually in the mind somewhere or whether it's a model that might not be actually possesed by people in that form. Also how much there may be a layer of approximation over everything. 

\subsection{experimental space and messiness}
20 	questions with nature. 
the experimental space here is quite huge and many of the experiments lack in generality and rigor (it's hard not to, especially by the standards of the day). Thus, a lot of the theoretical claims, while possibly useful and true, are not well supported by the evidence presented. 

In the start of an area of inquiry, it makes sense to use blunt tools and try to categorize things and limit the "messiness" in order to get any sort of traction and be able to start a theory (at least, this is a common approach, unclear if I actually think that it makes sense to have as much early theory). As evidence accumulates and a landscape of results starts to take shape, this stops cutting it. It becomes clear that there obviously is complexity and ignoring that complexity no longer suggests the right next experiments. Over-simplifying assumptions are common in the theory here, which may have been useful and necessary, but increasing maturity of an area comes with expectation that more be explained, and more quantitatively. 

\subsection{Constraints from other disciplines}
We're not making a theory of everything here, but if there are going to be appeals to parsimony, they need to take into account all the other stuff that will perforce be going on outside of this. Thus, if some things already are needed or well-explained that's to be  taken into account, especially with regard to domain general processes. 

In particular, reference contacts other disciplines in the forms of social cognition, since this is a social interaction and involves tracking other's understanding and knowledge states, and memory, since it involves remembering things. What we know and belief from these disciplines will need to match. Thus, if something is common and considered a solved problem, we can't appeal to it being hard. On the other hand, memory is decently understood and so we should reject models that posit implausible memory systems or memory retrieval operations. 

Models may be skimpy on these fronts if they are high level, but that should be explicit. 

Other evidence from language use and perception/ categorization boundaries may also come into play. 

\section{to incorporate}

\cite{hawkins2020b} How do you break symmetries in initial descriptions: there's prior variability across speaker preferences (they may each have a preferred label, but be unsure if others will accept it) and/or speakers may also not have labels and need to do some sampling. This doesn't account for production time course factors. 

this is a domain general model about abstracting over instances and forming conventions -- it is not particular to language, although peculiarities of language will also occur (and may have more levels to conventionalize on) 
\cite{hawkins2021} says there are 3 core cognitive abilities: the ability to represent that there is variability in other's lexicons; to coordinate via online learning; and to generalize across interactions ("partial pooling" model where updates both to partner and population) 



need some sort of structured heirarchical representation of word meaning (on the part of the other person) -- how do we represent word meaning and in particular the sorts of word meaning profiles that another person could have 

what's the ability to compound utterances? how do we do informativity measures? and how does this play out with more real world stuff? there's a toy model that I think is broadly correct, but you also start running into syntactic expectations for natural language which in the individual instance run counter to pure efficiency and informativity (what if there isn't a noun) 

\cite{hawkins2021} separating the inference problem about what the other person's lexicon is (which is how they will interpret things in the moment, b/c you may have temporarily changed their lexicon) with decisions about what to say given that 


points to an open question about what realistic priors would look like here

partial pooling approach to generalizing across populations (but this is not when all were in a group together) 

a direction we're not really considering here, but this generalization should be expected not just across partners, but also across contexts (which will tie back into usage -> structure and non-arbitrariness and efficiency arguments )


another piece that isn't super relevant here, but context matters for what conventions will form since what level or levels will be informative (again ties in with communicative utility and thus efficiency )

should expect lateral inhibition from successful matches -- similar to pragmatic reasoning but we think about each choice being also a choice against the other options 


need to fill in the gap for what is happening in the conversation level synchronic interaction that repeated many many times across the community then drives the observed diachronic change 

\cite{hawkins2021} points out that our models for communication and modeling the world and others need to be able to account for different people having different knowledge (including some tied to community membership or social role) and that vocabularies need to accomodate change over time and new things to refer to as the world changes. 

This is at group / modality intersection \cite{foxtree2013} looking at different remote communication methods; brings up the possibility of having different modalities at once with different people. In terms of backchannel -- expectations about usage should very based on ease, but also usage should be based on level of *need* to communicate / inverse level of understanding 


\cite{yoon2014} posits a pretty high level of reasoning in that disfluencies (fairly low level linguistic signal) are explained away by the presence of a co-listener. How far does this go in terms of what sorts of knowledge about the other listeners position will or won't do explaining away? Also at some point we expect to allow that the speaker might be using imprecise heuristics and we can't form strong expectations b/c they might just be messing up. 
above could also be related to recursion depth

\cite{hawkins2020b} one question here is how are people so flexible in how they describe things. There's some ad hoc pragmatic reasoning going on, also people have learning mechanisms and can adapt to their partners. In the world, there's new things to experience, so we need ways of using language in new ones (that's just part of the necessary language capacity). There's also going to be new people and contexts, so we have to operate under uncertainty -- we don't know exactly what is shared. Also there's person to person variation in semantics / how they use words. And we can use feedback (verbal and not) to adjust. 

Pragmatics isn't some special thing, these are actually pretty universal. We're closer to living in tangram world than we think. (Except that we usually don't even have such a nice closed class of alternatives) 

Arbitrariness and stability on the semantic side 

note that the GD of \cite{hawkins2021} has reasonable things to say about children and how they might have weaker priors and be less attuned to how much content is needed to communicate 

\cite{heller2012} on claiming that overinformativity is a thing, but this is deeply problematic. Also mild overinformativity is unlikely to throw the listener?, also questions of how to interpret things like name + descriptions that aren't efficient in the moment but may make things more efficient later (by linking to a name) 



\end{document}
