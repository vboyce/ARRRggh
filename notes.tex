\documentclass[]{article}

%opening
\title{ARRR: Why most theory is this area is weak and wrong}
\author{Veronica Boyce, local cynic}

\begin{document}

\maketitle

\section{Point of disagreement: modularity of language}
different approaches make different claims and assumptions about whether what the thing that's interesting to study is language specifically or communication, with language being the specific case study that comes with a lot of conventions. 

We're coming down on that language should be considered as an instance of communication, and thus, the general things should also hold for other forms of communication (drawing, gesture, etc). But, there's a lot a lot of conventionalized stuff around language in particular that makes it a) an interesting area to study and b) have some complexities that may not exist as much for other modalities. 

\subsection{lack of supremacy of certain form of language}
Some of the language studiers also make claims about certain forms of language (oral, face-to-face) being the more correct ones to study, with implications that being the easier, truer medium. 

I disagree -- different modalities and channel set-ups have different affordances. Implications will vary from different set-ups, but even for "naturalistic" there's a whole lot of not face-to-face these days. 

\section{Semantics}
One central issue that comes up when discussing linguistic communication is the semantics-pragmatics divide (if you believe in that) or how word meanings are represented. Words certainly have conventionalized meanings (that's how we can talk to people who we haven't talked to before), but there's questions about what the representations are and separately, what an appropriate way to model them is. 

Is literal semantics a useful model? Clearly lots of formal semantics isn't psychologically plausible, but some of the approaches could be useful simplifications for plugging in to RSA. 

What literal semantics will support RSA to explain different things? Like, what if we treated semantics as another Marr Level 1 component of RSA. 

\section{Common ground}
Common ground is frequently alluded to, but inconsistency in how the term is used poses problems. It is also usually framed within a non-probabilistic framework. Here I attempt to lay out what sort of common knowledge system is useful. 

As a first gloss, common ground is things that person A expects person B to share and expects B to not be surprised that A thinks it's shared. 

Much ink has been spilled distinguishing common ground with the infinite recursion of knowledge from some spy game. People are pretty bad at holding onto several level recursion. For this theory, it seems worthwhile to think about what forms of private knowledge are common and which are the really hard to keep track of kind. 

It seems reasonable to model people as being able to have up to a couple levels of recursion (with increasing difficulty as recursion increases) or as "many" as that the information is shared and known to be shared. (Aka, most people aren't spies and aren't playing Clue) Whether or not these things are actually shared this way does not matter, the question is a) what the psychological reality is and b) what's reasonable for models. 

Common ground doesn't actually exist (no platonism here) so it always needs to be considered from the viewpoint of a person who can have (implicit) beliefs about others that are used in producing or interpreting utterances. 

This common ground thing is used both at the level of lexicon / interpretation of symbols and also about the specific knowledge about the world and the current state. And also about the temporary ad hoc conventions being built up! 

Whatever this is, it needs to be flexible -- people don't need to be sure that someone else knows. In fact depending on alternatives, backchannel options, stakes, etc, it may sometimes make sense to use descriptions that you don't expect someone else to get, followed by elaborations, because if they do get it, it's the most efficient and this isn't one shot, it's repeated/incremental/interactive. 


\section{Embrace uncertainty}
One point of distinction for a lot of theories is how they handle uncertainty on the part of interlocuters. Many do not and instead contort themselves to accomodate the fact that people make (in these models) assumptions about what others know based on appearance/etc (assuming member of speech community, assuming general knowledge ). But then they also have to specify accomodation and repair mechanisms to deal with when things that were treated as being commonly known where not known by the interlocuter. Especially in reference to hard to describe objects, people may not always describe things in ways that they "know" the other person will understand, which is harder to explain under these stricter models. 

Probabilistic models allow for uncertainty over what other people know, and what others think words mean, etc etc, and thus some of the accomodation is more built in. 

\section{RSA}

I'm coming out in favor of RSA-style systems -- there are questions about what the right sorts of models and levels of recursion are for the model and there's separately a question of how these get implemented. 

Some key questions here are: what are the alternatives to an utterances? What the literal semantics being used? What's the belief/likelihood representations? 

\section{Psycholinguistic considerations}
Unsure how these few things fit together, but a few things to consider.

Where the bounded part of bounded rationality comes in -- we expect RSA-style to be a good high level model, but it's not an implementation and is agnostic about what parts are cached and at what level things are cached or short-cutted. 

Another issue is production (in terms of alternative generation, if we think RSA): (leung has a good list for this) As a speaker, one has to come up with a description at all, that description needs to be a good enough fit for the target, and then it also needs to not overly fit competitors. But generating these good enough for target descriptions is non-trivial in some circumstances, and this isn't well-modelled that I know of. How do people generate descriptions in the first place? 

Because this is language, there also seem to be strong habits or expectations about form. Like, there's a level of syntactic well-formedness that's expected, even if it's in some sense inefficient. What's the psycholinguistics here? Is this actually what's fastest to produce because of the habits of mapping to speech? Fastest to interpret? 

\section{Efficiency}
Lots of questions about efficiency (see also the notes taken below already)
What are processes that shape efficiency (especially in real-time production)? How does efficiency shape interpretations? There's the long-form for rare bias, but that requires pretty well-formed alternative sets. 

What do we really mean with efficiency? How does it play out on different time scales? What expectations does the overall efficiency framework impose on communication and reference? 

This also gets to ideas of informativeness. And if you get into informativeness and the interaction with relevance. 


\section{informativity}
This is not a well-defined area -- we talk about descriptions being sufficiently informative, but not overly informative, but to make those calculations, you need to have already posited full on semantics and a lack of noise in the interpretation channel. Whatever level of pragmatics you allow, then screws this because now your just barely informative are in expectation overly informative since others can be pragmatically enhanced. Better to explain all of this in terms of RSA where you can deal with it flexibly and not need to specify what the baseline is. 

\section{theory of mind and social representations}
One question is about the partner specificity of representations and how they may bleed together

This also interacts with other things such as ToM all of social cognition and the nature of memory representations 

\section{experimental space and messiness}
20 	questions with nature. 
the experimental space here is quite huge and many of the experiments lack in generality and rigor (it's hard not to, especially by the standards of the day). Thus, a lot of the theoretical claims, while possibly useful and true, are not well supported by the evidence presented. 

In the start of an area of inquiry, it makes sense to use blunt tools and try to categorize things and limit the "messiness" in order to get any sort of traction and be able to start a theory (at least, this is a common approach, unclear if I actually think that it makes sense to have as much early theory). As evidence accumulates and a landscape of results starts to take shape, this stops cutting it. It becomes clear that there obviously is complexity and ignoring that complexity no longer suggests the right next experiments. Over-simplifying assumptions are common in the theory here, which may have been useful and necessary, but increasing maturity of an area comes with expectation that more be explained, and more quantitatively. 

\section{Explaining reduction phenomena}
This is one of the big puzzles -- it makes sense from an efficiency standpoint, but most theories are better at explaining why you should form and maintain a pact and less good at how it should crystallize into something shorter (in this sense, changing). 

Robert's point about having multi-symbol things and how usage then refines the meaning us one approach. Still a question of modelling the rate of drop-off. 

\section{General approach of what I think is right}
Boundedly rational approach to communication. Can be modeled on a Marr level 1 by some sort of RSA approach that probabilistic and admits to malleability by non and extra-linguistic factors. A full account would need many chunks, since the back and forth and incremental isn't well developed in that system. 

At other levels, there's questions about how production works here and that may be a constraining factor that contributed to the approximateness if not everything is easy to produce quickly. 

May resemble constraint-based in terms of optimizing with a bunch of soft constraints over what will or won't work well. 

\section{Constraints from other disciplines}
We're not making a theory of everything here, but if there are going to be appeals to parsimony, they need to take into account all the other stuff that will perforce be going on outside of this. Thus, if some things already are needed or well-explained that's to be  taken into account, especially with regard to domain general processes. 

In particular, reference contacts other disciplines in the forms of social cognition, since this is a social interaction and involves tracking other's understanding and knowledge states, and memory, since it involves remembering things. What we know and belief from these disciplines will need to match. Thus, if something is common and considered a solved problem, we can't appeal to it being hard. On the other hand, memory is decently understood and so we should reject models that posit implausible memory systems or memory retrieval operations. 

Models may be skimpy on these fronts if they are high level, but that should be explicit. 

Other evidence from language use and perception/ categorization boundaries may also come into play. 

\section{List of sources of disagreement}

Memory format 

Ease of social reasoning (note that social cognition says that people are pretty good at a bunch of this and that it appears early in development and is quite advanced and may be a major factor in being human, so theories that posit that this is super hard and requires tool-level thinking are probably confused, or at least not getting parsimony points from this)

Explanation for reduction

Ego-centrism / time course of listeners restricting to CG (if that even makes sense)

Monolog / dialog /etc 

Is language privileged and if so, what specific instances of it

Rules v probabilistic

Is pragmatic inference an always thing? Role of context in linguistic interpretation (yeah, probably always there, any restrictions would have to show up in processing and would be hard to measure? could throw around surprisal with non-linguistic context, but idk if that's been studied) 




\section{Extending to multiple people}
One question is how you extend RSA up to multiple people -- how to do an utterance designed for multiple people? I guess you could represent separately and fit whatever joint function for optimizing that you want? 



\section{old stuff below here}


\section{Summary of efficiency}

There's a growing consensus that various aspects of language over varied timescales, from evolution of specific language systems to language use, display properties that are parsimoniously explained by efficiency. What does efficiency mean? Something like close to optimal in the trade off between informativity and processing/production. We could see this as a trade-off between different pressures (and that's probably how it developed?), but it could also be close to optimal for how quickly the information content (thought/idea) that a speaker wishes to communicate is conveyed to the listener's thoughts, taking into account that this includes mapping from thoughts to language, producing the language, time to transmit the sound (how fast the speech production is), parsing the signal back into linguistic units, and inferring meaning from that. There's all these (somewhat overlapping) steps, and especially for common messages and key information content, language is far above chance. This could be seen as trade-offs in various things, or as trying to minimize the process subject to some standard of close-enough on the meaning front. 

Zipf is an early proponent of language (the system / artefact) being shaped by some efficiency pressure ("principle of least effort"). He points out that if you're maximizing something, you need to get it all into one equation, you can't optomize two things at once (unless you specify how they trade off with each other, but that's jamming them into one equation). His evidence for this is ... lackluster, and there isn't an attempt at looking at other possible explanations for the data, but his work did inspire others to do a better job at looking at this. 

On a language level, both semantic categories and syntax (and potentially things like phonology as well) seem to be closer to what optimal would be than would be expected by chance. While we can look at this and it looks optimized for efficiency (in different parts of the communication sequence, so addressing different potential bottleneck points). Some of this is that commonly conveyed meanings have short ways of saying them (they have words aligned with those meaning levels) instead of either requiring additional modification (increasing speech time and processing time) or unecessarily overspecifying (increasing processing time). Another component is that syntactic properties such as harmonic word order seem to be good for allowing listeners to generally parse things reasonably. 

There's a question of what the microlevel processes are the drive efficiency, and this is where thinking of things in terms of trade-offs comes in. If something is too hard at any point and causes that to bottleneck it's bad, but things that ease whatever the bottlenecky step are will be more successful and those more widely adopted. There's also the possibility that sources of flexibility become grammaticized as they are reinterpreted (cf. Hawkins), that is soft processing constraints that lead to things like heavy-NP shift may then become seen as part of the grammar by frequent use and then the less frequent parts don't get used even in the specific (rare) situations where they (in isolation) are processing-optimal. There's pressure to grammaticize either from learning or from making parsing easier because fewer options? 

On a more relevant level to present interests, speakers and listeners converse in situations where the language is approximately set in stone. There are expectations about what words mean and how syntax works. Given those inventories, speakers and listeners get to make choices about how to interlocute to efficiently do cooperative mindreading. There's a lot of possible levers here: 

* what wants to be communicated comes with a certain level of precision (or lack thereof). in reference, you just need to get the right target given context. when describing an event, there's parts of it that you want to convey, but it's not recreating everything
* depending on syntax and word order constraints (that is, expectations), different languages lend themselves to pointing out different things. We might imagine that in some circumstances one might want to say isolated words out of order, but this would be pretty unnatural and so incur processing costs on the listener end. Possible also on the speaker end producing it, if planning takes longer. If the channel is artificially limited in a game (or telegram) maybe it's worth this trade off, but in everyday speech, the speech length may not be the limiting part. 
* in most conversational environments, there's the option for the listener to respond or otherwise for feedback to be given. thus, there's the possibility for stopping early if an utterance is sufficient or continuing if it is not (because sufficiency is ascertainable from the listener response either verbally or behaviorally -- i.e. reaching towards the wrong thing). How much this feedback is possible varies, but when it is, it makes sense that utterances can use this. Thus, the most efficient path may be to try something and add more only if needed. (This goes well with not necessarily having absolute knowledge of the interlocuters mental state. )

* over the course of a relationship (or conversation) the conversation history shapes expectations which will allow for different descriptions to become efficient -- either increasing belief that something is enough to try, or making less syntactically normal / highly reduced things seem okay (and thus not incur processing cost?) in context. 

How to deal with that a lot of the time people are joking or whatever? Still trying to convey meaning (even if complex, or meta-linguistic meaning)

As an overarching thing, efficiency is hard to prove or disprove in part because it relies on a lot of linking hypotheses for how it should play out in different domains. But it has parsimony and explanatory value across a lot of levels. It's a good fit to the data, even if the realms for experimental tests are somewhat limited. 

\section{Why common ground is dumb}

The idea of common ground assumes that it's a thing that exists. That isn't true but also isn't relevant -- what matters is what one person thinks is sufficiently mutual between them and their interlocuter. The depth effect of common ground is rarely relevant, but people can be mistaken about what is in common (ex. you think it's in common ground because you told it to them, but actually they forgot). Also, as will be discussed extensively, this isn't all or nothing -- I can have uncertainty over who knows what, or think something will be understood because it's generally known by people without specific reason for the individual. 

The question of what are your priors or their priors and how tailored are they to the current context and in particular how much theory of mind and perspective taking (aka recursion) there is, is relevant. And that's vaguely what's being said, but with the mechanisms probably mostly wrong. 

One issue with distinguishing what shapes utterance production is that we primarily have access to the outcome at the end, which mostly isn't what anyone is arguing about. The questions are about what the process is for generating that utterance and what sorts of things are how prominent in the process when. This leads to lots of hand-wavy models about how language is produced (again, hard to model well since we don't have access) and flimsy linking assumptions with behavior. 

One assumption is that telling someone to respond faster (time pressure) will change the production pathway/process in a way that limits later steps more than earlier steps. Clearly, time pressure (and other resource constraints) do affect production, but how is going to be a lot more complicated, especially given the lack of good production model. 

Horton \& Keysar are trying to adjudicate between: initial planning takes into account common ground, and initial planning does not taken into account common ground, but monitor \& fix does (and does so pre utterance initiation sometimes) 

Everything is probably more continuous than these things posit. It's a probabilistic world of bounded rationality and heuristics to fill in gaps. 

egocentrism: what is seen as egocentric behavior could be either a) not caring whether the other person understands / could be referring to a thing, b) mistaken beliefs about what the other person knows , or c) satisficing under limited resources producing either (which isn't really a third option) 

the people who call it egocentrism don't call it that when people make mistakes about what is in common ground. But as \cite{hanna2003} point out, you can never actually know what another person knows 

the ways things are said to get into common ground aren't consistent with various general assumptions that people know things (like default assumption of sharing the same language, or knowing basic facts, etc) or inferences (went to same college, is a local, etc). 

common ground is mostly useful when discussing spying -- something like expected to be comprehensible to listener based on some set of things makes more sense 

\section{name versus description}

how descriptions become names

using names with descriptions as a teaching thing (to make future things faster) 

overinformativity -- what's wrong with it? 

\section{Points of disagreement}

general tension between people who want a set of absolutes, versus gradients

how difficult doing theory of mind is (and under what circumstances)

time course of incorporation of interlocuter specific information 

interpretation of eye movements

what appropriate levels of naturalism are

what work is on the speaker v listener

"""reference diaries"""

terms I don't like: common ground, entrain, aim low v aim high v aim average

Who adjusts how much: do speakers design and/or do listeners accomodate


\section{general points of agreement}

under some circumstances, people will do conscious reasoning like they're playing clue and use very explicit theory of mind 

some of the time, people will not fully map everything and will instead need to rely on short-circuits and proxies 

the question is when these times are and what happens in "normal" situations in the middle ... 


\section{Vaguely plausible}

One key distinction that doesn't get explicitly highlighted much (but is brought up in some recent work, such as \cite{leung2023}) is that the process of `first contact' -- establishing initial reference -- is at least somewhat separable from the repeated reference / reduction phenomenon. They're probably not totally separate as the same systems will need to work for both, but there are probably peculiarities to the reduction part. 

Factors affecting how utterances are produced and interpreted are going to be varied and probabilistic. For instance, we could treat this as some sort of salience prior, where you expect the interlocuter to *probably* refer to the thing that is mutually seen (see "common ground") but the chance of them referring to something you can see and then can't isn't 0 (and thus can be increased in the likelihood). 

Considerations from audience design literature: generally pretty reasonable, communication is in some high dimensional space and there are a lot of potential influences. 

``partial pooling'' model: some sensitivity to context \& who said what, but source memory is hard. Also, there are recency effects \& some expected transfer/universals (learning language) 

Distinction between elaborations (common with a new listener) \& totally new ideas (rare)

From audience design: speakers take into account the whole set of listeners who are present -- tend to tailor so that all could understand, but use meanings/shorthands that knowledgeable ones will recognize (=> many possible ways to accomodate multiple listeners, perspectives, also consistent with a name \& describe that's good for future) 

performance is constrained by realities of task switching \& memory and interference (so some performance things that don't seem ideal may be from those things) -- bounded rationality 

speakers can also take listener context into account (at least when known) but again probably bounded by working memory

shared social history makes for efficient label sharing 


\section{meta}
general meta-theory: when something is a new area, easy to make over-simplifiying models of “here are the two or three ways it could work” this is useful, but as a field matures, important to accept nuances.

useful sketch of some options versus reality / full messy space of options

Stronger if you have gradients (ideal if you have math model and can do something quantitative)

\section{}

my concerns about whether speakers are calibrated/optimized or not continue (see also alcohol paper) 

\section{zipf}
Could be generously interpreted as an early precedent to bounded rationality / resource rationality 

points out need to be very clear about what is being optomized

Efficiency depends on what the time scale that's being optomized for is -- someitmes more prep / longer will pay off over repetition (and you don't know the future, so probabilistic)

gives an ahistorical account looking at word distributions and word \ meaning distributions 

some sort of utility access model ? 
\section{To explore further}

What's the SOTA in language production modelling? Utterance planning? 

Constraint based accounts of production (and comprehension) see \cite{hanna2003} highlights for suggested readings

maybe grice

forward search \cite{heller2012} since they're pretty reasonable about the idea of name versus what properties to include 

piantadosi on power laws and how they come from everything 

see various yoon and brown schmidt for highlighted citations to read 
\bibliography{sources.bib}
\end{document}
