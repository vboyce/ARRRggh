\documentclass[]{article}

%opening
\title{ARRR: Why most theory is this area is weak and wrong}
\author{Veronica Boyce, local cynic}

\begin{document}

\maketitle
% Next steps are to pick a hunk of this and organize it!
\section{TO explore further }

* how to bridge information theory and syntactic/habitual expectations for language form 

What's the usefulness of hedging in communication? For reference not for politeness -- what purpose does it serve, when does it create better results (is it comprehension or production side)? 

Why don't things reduce extremely sharply after first success / speed of refinement

What are processing/production ways to get at cost and truthness of descriptions and also how are they sampled? 

whats the memory component over time? like if you asked people who had played the game to then later name all the figures? would they use the names their group had even months later? 

%TODO not sure what if anything to say about Eliav

%TODO so I read hockett and hockett and don't think it has usefulness here? 

%TODO look at kronmuller and barr MA (again?)

%TODO not sure there's anything relevant to say about khani et al 

%TODO not sure if there's anything relevant to say about turner

%TODO consider adding some cites from yoon2014 to the list, especially around constraint based 

%TODO zaslavsky -- confused on the details, but something about what efficiency is from an information-theoretic perspective 
%TODO figure out what my not how memory works coment on Clark chapter 4 was about 

%TODO consider constraint based models 

%TODO look at \cite{clark1986} more, both notes and original text


What's the SOTA in language production modelling? Utterance planning? 

Constraint based accounts of production (and comprehension) see \cite{hanna2003} highlights for suggested readings

maybe grice

forward search \cite{heller2012} since they're pretty reasonable about the idea of name versus what properties to include 


see various yoon and brown schmidt for highlighted citations to read 

\section{Goes somewhere but I haven't figured it out yet}

Zipf points out that if you're maximizing something, you need to get it all into one equation, you can't optomize two things at once (unless you specify how they trade off with each other, but that's jamming them into one equation). His evidence for this is ... lackluster, and there isn't an attempt at looking at other possible explanations for the data, but his work did inspire others to do a better job at looking at this. 

\cite{zipf1949} if we're being generous it's an early example of bounded rationality / resource rationality in terms of trying to find tradeoffs 

even without specific relevant knowledge, \cite{garrison2022} brings up that when there's shared social history (even not about this topic) that makes for more efficient label sharing ; alcohol also gets better labels for strangers, but unclear on mechanism. 

\cite{clark1996}
discussion of the difference between natural signs and signals -- which isn't a distinction I especially buy, but does raise questions over how we determine whether something was an intentional signal from an agent or not 

raises lots of philosophy questions about whether intent is required for something to have meaning and questions about the developmental trajectory of all of this 

\cite{murthy2022} on color chip associations with words. This uses a strongly uncertain framing where we have priors over word-color associations. How does this map up to words where there's more structure to the prior in some complicated way. Also evidence that one can learn a lot from feedback, including things that may have had really shallow priors. 

Connection to CG: but how deep does recursion go? Could look at the Franke \& Degen for some of this, but generally seems to be only a couple stages on this recursion, so maybe recursion for CG is also only a couple stages -- not sure how strong the connection is here
\cite{bergen} on how to get matching between costly utterances and rare meanings which is needed for efficiency


\cite{fay2010} "minimized collaborative effort" (will need to go back and check but notes on: what sorts of interaction define something as being communicative intent, what sort of feedback) use of "givenness" as probably slang for some sort of cultural CG. getting to be more adjacent to some of the network-y stuff that Robert does (but see notes if needed) 

\cite{horton1996} is interested in the processing timeline incorporation of CG -- raises a lot of questions about what the current production literature is, assumes that social context is complicated and costly to put online, really bizarre discrete time step assumptions; doesn't clearly specify what the alternatives to using CG are; there's also issues where some of what looks like audience design/CG might actually be various heuristics or speaker-dependent functions and it's hard to do that (caching, yknow) 

\subsection{Processing egocentrism} 

One issue with distinguishing what shapes utterance production is that we primarily have access to the outcome at the end, which mostly isn't what anyone is arguing about. The questions are about what the process is for generating that utterance and what sorts of things are how prominent in the process when. This leads to lots of hand-wavy models about how language is produced (again, hard to model well since we don't have access) and flimsy linking assumptions with behavior. 

One assumption is that telling someone to respond faster (time pressure) will change the production pathway/process in a way that limits later steps more than earlier steps. Clearly, time pressure (and other resource constraints) do affect production, but how is going to be a lot more complicated, especially given the lack of good production model. 

Horton \& Keysar are trying to adjudicate between: initial planning takes into account common ground, and initial planning does not taken into account common ground, but monitor \& fix does (and does so pre utterance initiation sometimes) 

Everything is probably more continuous than these things posit. It's a probabilistic world of bounded rationality and heuristics to fill in gaps. 

egocentrism: what is seen as egocentric behavior could be either a) not caring whether the other person understands / could be referring to a thing, b) mistaken beliefs about what the other person knows , or c) satisficing under limited resources producing either (which isn't really a third option) 

the people who call it egocentrism don't call it that when people make mistakes about what is in common ground. But as \cite{hanna2003} point out, you can never actually know what another person knows 
\subsection{functionalism -- probably part of efficiency }

\cite{hawkins1995} not sure where this goes, but a functionalist approach. This is an approach that assumes a pragmatics as a last layer view rather than a it's all pragmatics all the way through view. 

Efficiency means that things that are more common should be faster to process and this is a joint constraint on the processing system and on language (language might be the faster evolving part here, so that may make language adapt to usage and ease of processing constraints)

From an ease of parsing perspective, it's easier to have less in the buffer at once and to avoid ambiguities if the parts that determine the structure of the parse are closer together (assuming free word order). This sometimes gets grammaticized, and then because if the grammaticization based on say the common heaviness pattern, there will then be exceptions. 

Might be conflicts between balancing syntactic weight for ease of I think comprehension and not production (contra Macdonald?) and information theory. 


\subsection{informativity}

This relates to efficiency/ informativity / and RSA: \cite{piantadosi2012} discussing the role of ambiguity with is relevant to the question of what sort of utterances to make in reference in games or conversation. Descriptions are not going to be unambiguous without context and they might not even be very good descriptions so one is going to need context and a shared history to disambiguate or shift the probability weights more strongly for conventions

\cite{piantadosi2012} gives a useful contextualizing of zipf and cites up more recent work that is more empirically rigorous for power-low patterns. 

Various opposed forces that are supposed to yield efficiency: \cite{piantadosi2012} says it's clarity (low ambiguity and high recovery of signal) that is opposed with ease (of production / processing prefers a smaller set of items) 

the communicative context should play a large role is determining how much signal is needed for clarification and thus shape usage 

This is not a well-defined area -- we talk about descriptions being sufficiently informative, but not overly informative, but to make those calculations, you need to have already posited full on semantics and a lack of noise in the interpretation channel. Whatever level of pragmatics you allow, then screws this because now your just barely informative are in expectation overly informative since others can be pragmatically enhanced. Better to explain all of this in terms of RSA where you can deal with it flexibly and not need to specify what the baseline is. 

\cite{baumann2014} argues that in RSA-style environments, speakers often produce "over" informative expressions, and they make the claim that it's because calculating the implicatures is costly.  do listeners ever misinfer b/c of overinformativeness? what's the downside of being "over" informative except from an efficiency stand-point? how do we even define "over" specification, since this is always going to be in regard to a level of inference and a level of probabilistic certainty that we're okay with. 

\cite{bergen} on specificity implicatures will also raise questions here, since do you calculate informativeness before or after the implicature? 

From efficiency if production time speed if a big factor, then it may be overall efficient. 

\cite{degen20200406} on informativity as being the relevant thing *not* some technical definition of overspecification 

idea of "pragmatic surprisal" 

\cite{heller2012} on claiming that overinformativity is a thing, but this is deeply problematic. Also mild overinformativity is unlikely to throw the listener?, also questions of how to interpret things like name + descriptions that aren't efficient in the moment but may make things more efficient later (by linking to a name) 

\subsection{Robert stuff} 

\cite{hawkins2020b} one question here is how are people so flexible in how they describe things. There's some ad hoc pragmatic reasoning going on, also people have learning mechanisms and can adapt to their partners. In the world, there's new things to experience, so we need ways of using language in new ones (that's just part of the necessary language capacity). There's also going to be new people and contexts, so we have to operate under uncertainty -- we don't know exactly what is shared. Also there's person to person variation in semantics / how they use words. And we can use feedback (verbal and not) to adjust. 

Pragmatics isn't some special thing, these are actually pretty universal. We're closer to living in tangram world than we think. (Except that we usually don't even have such a nice closed class of alternatives) 

Arbitrariness and stability on the semantic side 

\cite{hawkins2020b} How do you break symmetries in initial descriptions: there's prior variability across speaker preferences (they may each have a preferred label, but be unsure if others will accept it) and/or speakers may also not have labels and need to do some sampling. This doesn't account for production time course factors. 

\cite{hawkins2021} introduces CHAI, a framework that tries to bridge the levels of conventions from partners to networks and societies. seems generally right; need models that can explain both partner specificity and community scale conventions

this is a domain general model about abstracting over instances and forming conventions -- it is not particular to language, although peculiarities of language will also occur (and may have more levels to conventionalize on) 
\cite{hawkins2021} says there are 3 core cognitive abilities: the ability to represent that there is variability in other's lexicons; to coordinate via online learning; and to generalize across interactions ("partial pooling" model where updates both to partner and population) 

need to fill in the gap for what is happening in the conversation level synchronic interaction that repeated many many times across the community then drives the observed diachronic change 

\cite{hawkins2021} points out that our models for communication and modeling the world and others need to be able to account for different people having different knowledge (including some tied to community membership or social role) and that vocabularies need to accomodate change over time and new things to refer to as the world changes. 


need some sort of structured heirarchical representation of word meaning (on the part of the other person) -- how do we represent word meaning and in particular the sorts of word meaning profiles that another person could have 

what's the ability to compound utterances? how do we do informativity measures? and how does this play out with more real world stuff? there's a toy model that I think is broadly correct, but you also start running into syntactic expectations for natural language which in the individual instance run counter to pure efficiency and informativity (what if there isn't a noun) 

\cite{hawkins2021} separating the inference problem about what the other person's lexicon is (which is how they will interpret things in the moment, b/c you may have temporarily changed their lexicon) with decisions about what to say given that 

points to an open question about what realistic priors would look like here

partial pooling approach to generalizing across populations (but this is not when all were in a group together) 

a direction we're not really considering here, but this generalization should be expected not just across partners, but also across contexts (which will tie back into usage -> structure and non-arbitrariness and efficiency arguments )

another piece that isn't super relevant here, but context matters for what conventions will form since what level or levels will be informative (again ties in with communicative utility and thus efficiency )

should expect lateral inhibition from successful matches -- similar to pragmatic reasoning but we think about each choice being also a choice against the other options 

note that the GD of \cite{hawkins2021} has reasonable things to say about children and how they might have weaker priors and be less attuned to how much content is needed to communicate 

\subsection{List of sources of disagreement}

Memory format 

Ease of social reasoning (note that social cognition says that people are pretty good at a bunch of this and that it appears early in development and is quite advanced and may be a major factor in being human, so theories that posit that this is super hard and requires tool-level thinking are probably confused, or at least not getting parsimony points from this)

Explanation for reduction

Ego-centrism / time course of listeners restricting to CG (if that even makes sense)

Monolog / dialog /etc 

Is language privileged and if so, what specific instances of it

Rules v probabilistic

Is pragmatic inference an always thing? Role of context in linguistic interpretation (yeah, probably always there, any restrictions would have to show up in processing and would be hard to measure? could throw around surprisal with non-linguistic context, but idk if that's been studied) 

general tension between people who want a set of absolutes, versus gradients

how difficult doing theory of mind is (and under what circumstances)

time course of incorporation of interlocuter specific information 

interpretation of eye movements

what appropriate levels of naturalism are

what work is on the speaker v listener

"""reference diaries"""

terms I don't like: common ground, entrain, aim low v aim high v aim average

Who adjusts how much: do speakers design and/or do listeners accomodate




\subsection{mush about audience design that I don't know how to classify}

\cite{horton2002a} Here they make the assumption that audience design is only sometimes needed and is osmething that is uniformly an increased in the verbosity. So what's the default. You're always talking to someone, except/even if talking to oneself right? 

\cite{horton2002a} usefully points out that partner specificity should occur mostly in cases of low codability, which I'd elaborate as being low codability in context since context will matter here!

Audience design has big definition problems is that different people use it to refer to different things Sigh. 

Two possible components could be  responding to interlocuters cues about their understanding (if they express confusion say more), and making good guesses about what they will need to understand based on shared history and inferring from their demographic features (these are different!) 

\cite{horton2002a} useful distinction between lexical entrainment where it's the exact word used again versus conceptual similarity which doesn't need the same exact words, and can generalize (double check if this is in there are my thoughts) 

is incorporating things initially contributed by listeners a component of audience design? 

\cite{horton2005} makes the (reasonable) claim that conversation partners act as cnotextual cues for retrieval of associated information (shared history stuff, not demographics) presumably via episodic memory 

\cite{horton2005} how well you can design utterances from your audience depends on how well you can know what the other person knows

\cite{horton1996} makes the correct point that a result does not allow us to infer intent -- the appearance of audience design could potentially be arising from something else and its just hard to know

\cite{macdonald2013} talks about audience design in the form that things may be beneficial to comprehenders, but still be driven by the producers needs, in that they produce what they can produce with fliency and without difficulty (rather than let the conversation get slow or repetitive) 

To some extent the idea of audience design is about how the labor of the conversation is split between participants and what the processes of these are -- right we assume it's a join thing, that there's cooperativity in having the conversation at least 

\cite{rogers2013} points out that audience design can be used as a descriptive "it looks like it's tailored for the audience" without actually committing to any intent on the part of the speaker to tailor for the audience 

\cite{rogers2013} raises the point that it may be difficult to tell what is strategic and what arises as a result of incremental social interaction (although it's really unlikely to be fully bottom up) It's also possible to have a strategic incremental approach (this is what's probably happening) where there is integration and monitoring of the other people. This like everything else fails to explain reduction. 

\subsection{Misc: modularity of language}
different approaches make different claims and assumptions about whether what the thing that's interesting to study is language specifically or communication, with language being the specific case study that comes with a lot of conventions. 

We're coming down on that language should be considered as an instance of communication, and thus, the general things should also hold for other forms of communication (drawing, gesture, etc). But, there's a lot a lot of conventionalized stuff around language in particular that makes it a) an interesting area to study and b) have some complexities that may not exist as much for other modalities. 

\cite{clark1996} at least brings up for me what delimits language from other forms of signalling

This is at group / modality intersection \cite{foxtree2013} looking at different remote communication methods; brings up the possibility of having different modalities at once with different people. In terms of backchannel -- expectations about usage should very based on ease, but also usage should be based on level of *need* to communicate / inverse level of understanding 

channels may differ in their richness and efficiency (some of this might also be habit over different channels)

\cite{hawkinsa} Drawing convention formation over repeated drawing shows some similar patterns to language reduction. These similarities point towards the processes of interest such as reduction and alignment with partners being general and agnostic to the medium of communication, although of course they play out in different ways depending on the affordances of the medium. For both drawing and language there are culturally built up habits about how things are typically represented. Drawing, some is still cultural, but more is human universal based on perceptual stuff, rather than language where the conventions are more language specific. 

\cite{murthy2022} on color chip matching -- there's something to learn about convention in domains other than language. Theories should make at least not wildly inconsistent predictions about those areas. 

\cite{pickering2004} seems to at least implicitly think that language is modular in that their theory is built around aligning on levels of language; some of the commentators (such as krauss \& pardo) point out that language is not this modular or automatic in that it can be influenced by non-linguistic cues and background. They also point out that language can be used strategically. 

\subsection{lack of supremacy of certain form of language}
Some of the language studiers also make claims about certain forms of language (oral, face-to-face) being the more correct ones to study, with implications that being the easier, truer medium. 

I disagree -- different modalities and channel set-ups have different affordances. Implications will vary from different set-ups, but even for "naturalistic" there's a whole lot of not face-to-face these days. 

\cite{clark1996} argues that face to face conversation is the more natural (chapter 1) and thus that all other situations of language use will be more challenging. This goes against idea of transfer learning or ability to adapt to other situations. Notably, in the current world, a lot of linguistic communication, even informal communication, takes place not face to face. there's also a strong focus on dyadic interaction in particular, unclear if dyadic is actually a more natural or common situation that others.

\subsection{joint action}
\cite{clark1996} while not the central interest here, theory should be continguous, so we should consider how to consider language when used in conversations with more limited entities. People do talk to their pets and their babies. People also talk with automated system that use language, and now talk with AI chatbots. Are there something totally different? or are there gradients of different actions with some being more prototypically joint and cooperative than others -- at least for conversation with a toddler, it's a conversation, but this suggests that there isn't a clear delimiting between joint actions and not b/c of semi-cooperative situations where one party is not very good at cooperating (pet, baby, AI). 

(generally, insert railing against over splitting approach here)


\subsection{"""Alignment"""}

\cite{eliav2023} (maybe?) brings up the idea that conceptual alignment could be one to one or it could be a wider thing that displays transfer learning (concepts are on different levels) 

not sure where it goes: but there seems to be good explanations for why using multiple chunks might be good b/c uncertain if other person will understand (although see open questions about how true this is) 



\subsection{partner specificity}

\cite{hawkins2021} for explaining treating different partners as different contexts and explaining the partial pooling and gradient into group conventions. partner identity is part of the (episodic memory) and is tied to the usage, but as it gets encoded more generally in non-episodic may be the process by which it becomes convention level 

\cite{yoon2014} also supports a partial-pooling type model, in that there's some sensitivity to context and who said what, but also there are still cross-interlocuter recency effects

\cite{yoon2014} point out that representation and use are key (idk what my notes meant by that) 

\cite{yoon2014} posits a pretty high level of reasoning in that disfluencies (fairly low level linguistic signal) are explained away by the presence of a co-listener. How far does this go in terms of what sorts of knowledge about the other listeners position will or won't do explaining away? Also at some point we expect to allow that the speaker might be using imprecise heuristics and we can't form strong expectations b/c they might just be messing up. 

\cite{yoon2018} sketches some different options -- we expect that this is actually going to be a lot more gradient than that, and it would be cool to have a mathematical model of some of this

\cite{yoon2018} raises question of when speakers are able to track different states of listener knowledge? both in terms of group, but also in terms of other cognitive load and performance/speed pressures 

in general partner specificity seems like it will be constrained by factors such as working memory, task switching and bottom-up attention (might need to inhibit responses) 

task demands and goals could interfere

Seem to be questions both of how much information is provided total and in what order its provided -- see \cite{yoon2018} on the interpretation of elaborations versus replacements -- giving name + more might be a way to accomodate different knowledge levels and get people closer to the same page 

\cite{yoon2019} there may be task demand issues in terms of what the function is for how much to include everyone (based on task and incentive might be better or worse to slow down and include everyone versus not) even if these aren't explicit, might be transfer from other situations. 

\cite{yoon2019} when there's feedback there's option space for speaker / listener effort splits how does this work 

sort of relates to the ibarra, but \cite{yoon2019a} points out that there's knowledge-scene integration where interlocuters take into account the physical perspectives and contexts of their listeners and how that interacts with the knowledge states. This is probably a think that takes working memory, so might see declines if the people-context stuff gets too complicated, but it points to a lot of this being pragmatic and shaped by top-down non-linguistic factors about what to do. 

\subsection{Decent: Interactive alignment goofiness}

 Despite this, the interactive alignment theory attempts to solve the problem of how people can come to use similar words and successfully collaborate without having to actually reason about each other's mental states. They acknowledge that it is possible to reason explicitly about others minds, but think that is a taxing option only utilized under rare circumstances, and is not the norm. As they use it, this strikes as a motte and bailey argument: their motte is that conversations generally proceed by their automatic priming mechanism, while when challenged, they retreat to the safety of the uncontroversial bailey where explicit mental modeling happens but is not the only factor at play in conversation.  

It is not clear why \cite{pickering2004} assume that mental modeling is costly. Much research in social cognition and theory of mind points to people having pretty good heuristics for keeping track of what others know. This seems contra to many things, including that people are readily able to learn new words (which somehow involves mapping someone's intent to the words) (CITE SCHOBER COMMENTARY)

I find many of their claims hard to understand, and wonder if some of this might be a levels of analysis thing, a difference in definitions, or a preference for different questions of interest. 

On a levels of analysis question, it seems like \cite{pickering2004} are presenting a high-level verbal descriptive theory when they use terms like "priming", but they in their title and throughout the text seem to think they are providing a "mechanistic" theory. \cite{pickering2004} claims to be providing a "mechanistic" explanation, but no mechanisms are to be found. They claim that the alignment process works by "priming", but priming is not a mechanism: it's an umbrella term for a phenomenon whereby the presence of one stimuli has an effect on someone's future behavior processing speed, due somehow to the relation between the stimuli and the later action or stimuli. Mechanisms in terms of memory activation, or other processes are implicated for some types of priming, but calling something priming is a description, not an explanation or mechanism. In particular, their claim that the priming on one level somehow spreads to other levels, including outside of language, was criticized by many of their commentators. They also claim that this "priming" is "resource-free and automatic", without providing a further explanation of what this means or how this is working on the level of processing, memory, and production. 

However, to the best of my understanding, their account really is about how interaction is "priming" coupled with some mechanism for overlap on one level (ex. lexical) to lead to overlap on others (ex. syntactic). These papers tend to focus on somewhat different experiments such as their maze task, where people are cooperating with the same role, and thus may be more likely to both talk in the same way, compared to work from more mentalizing traditions that tend to use asymmetric matcher/director tasks. In the matcher/director tasks, it is clear (dating back to \cite{krauss1966}) that speaker's behavior is influenced both by listeners utterances describing the image, but also by their non-aligned responses such as saying "mhm" or making correct or incorrect selections. The interactive alignment account crucially cannot explain the effects of these other backchannels, and so is forced to explain them away as insufficiently "basic". 


The ideas of \cite{pickering2004} are (distantly) related to some much softer claims that are more likely to be actually true. One kernel of reason is that usage increases the accessibility of a representation (\cite{macdonald1994}), or that the joint association between target, word, and interlocuter are encoded in memory. These processes are non-mentalizing operations that may lead to convergence in the use of words or constructions. A weaker (and more reasonable) interpretation is that production and comprehension share some things like the same memory and track usage statistics including is ways that are dependent on time and perhaps also activated by the context of conversational partner.  Could even be framed that expectations are shaped by the local context, including the conversation partner. 

One big point of conflict between \cite{pickering2004} and many of the commentaries, is that \cite{pickering2004} claims that the priming process goes all the way up to the (non-linguistic) situation model. This is an espeical weakpoint in their theory, as it is leaving the domain of language, where some forms of lexical and structural priming are studied, and where domain-specificity could be invoked (TODO CITE BRANIGAN AND MARKMAN COMMENTARY). 

\subsection{Reread gandolfi and add to interactive alignment} 
Newest iteration is from \cite{gandolfi2022} brings up a lot of "control" and monitoring and comparing 

unsure how one is predicting the others utterance without ToM -- is this is behaviorist thing? is the other person not being represented as an agent? or is this just a levels of analysis claim? (representation in general are weird and hard to work with)

I'm confused about this -- and what meta-representing is doing ; feels like a high level description that doesn't have a lot of specific explanatory power

 focuses here a lot more on repair and meta stuff 

\section{Interpersonal / Common ground}

When we communicate, we seem to tailor our interactions based on the person. While this seems obvious, describing the extent of this and theorizing on how it occurs can become complex. 

One central aspect of this is that speakers seem to calibrate what they say to what an interlocuter is likely to understand so that the communicative act can be successful. A non-exhaustive list of factors here are using words and language the interlocuter will understand, making assumptions based on the interlocuter's identity, and basing references and explanations based on prior history between the speaker and the interlocuter. 

In terms of distinguishing what people know, there's a history of word defining different types of knowledge, include private, mutual, and common knowledge. This has led to widespread usage of the term "common ground" to refer to what is (assumed to be) shared knowledge between people. However, deriving this in a reasonable way has proved tricky.

It's a very commonly used term, but it means different things to different authors. It's also hard to tell in many cases what theoretical commitment is there. 

some uses of common ground and conversational pact are used descriptively as a sort of people as contexts claim \cite{leung2023} rather than as a commitment to the theory 

 It's sometimes presented as requiring infinite recursion of A knowing that B knows that etc A knows fact Y, but this is obviously psychologically untenable. (This could be a levels of analysis issue, where common ground is defined recursively on a computational level, but is assumed to be approximated differently; however, common ground is often assumed to be a "thing" without discussion about what exactly the claim is.) CITE CLARK CHAPTER 4 Is common ground just a verbal theory with some useful explanatory power, or is it a cognitively real cultural tool? In the second case, there are questions about what the developmental and learning trajectory for acquiring this tool is. Whatever the real thing is that needs to be acquired; the acquisition trajectory might suggest that it has softer edges and is less discrete. 

Other approaches [TODO CITE CLARK USING LANGUAGE] have tried to list circumstances in which people can assume that something is common ground, such as various forms of co-presence, or if something is common knowledge within a community. However, this approach still considers common ground to be a discrete thing. 

Some of the trickiness comes from that no interlocuter has access to the veridical common ground. Instead, a person may have beliefs about what is in the common ground between them and their partner, but it is possible for them to be mistaken. It's also possible for them to be unsure. The proxies described by Clark will sometimes lead to the erroneous belief that something is mutually known when it is not (let alone any meta-knowledge). Alice may think that Bob knows about something because he looked like he was looking at, but he might have been daydreaming or he might have forgotten. Additionally, Alice might think that all doctors know XYZ and so that if Bob is also a doctor, then XYZ is mutually known. People are frequently mistaken on these points. Thus, what we care about for understanding conversation is not some platonic ideal of common ground, but instead what each person thinks the other shares in a sufficiently public way. 

This history of common ground is written to distinguish it from times when there is covert knowledge, and where parts of people's knowledge states would be unexpected to the other. This does occur, although, usually only at small levels of recursion, such as if Alice spies on Bob and Eve, then Bob and Alice might each know that Alice is visiting, Alice knows (or assumes with good evidence) that Bob knows, but Bob does not know that Alice knows. Here, they both have the factual knowledge, but there is a discrepancy at the first level of recursion. Do situations where deeper levels of recursion actually matter occur much? I'd argue that they don't and that this is consistent with low-depths of recursive reasoning in other related domains (CITE RSA, Franke/Degen). 

A bigger issue is that things are usually treated as being either in or out of common ground and much formal pragmatics has attempted to explain a few of the obvious failure cases via accomodation. As I argue elsewhere, this absolutist approach doesn't work because everything is probabilistic and people can be quite creative in how they use language. CITE horton1996 as an example of this absolutist approach

 Instead, one can be reasonable and admit that people can have graded beliefs. I'll suggest that if we must use the term common ground, we, on a practical level, gloss it as something like "things that person A expects person B to share and expects B to not be surprised that A thinks it's shared". Thus, we could distinguish between "we each know this, but he doesn't know I know it too" and "we both know this" but not between the subtypes of "we both know this". In other areas, the roughly same set of content is said to be "given" to cover both background knowledge and information that is presented to both participants at once \cite{fay2010}. 
 
 TODO hanna2003 has a sane definition of CG
 
 

In a probabilistic framework, we'd replace this idea of "common ground" with instead having priors over what the other person beliefs or knows. This can be useful for separating out different contexts that in some sense all get lumped into CG: the lexical priors having to do with how someone will interpret signals (out of context, such as what words they might know) can be split off from their general world knowledge (perhaps being inferred based on characteristics) and that can also be separated from specific knowledge that has been accumulating during the interaction. This sort of partition may be useful and parts may be cache-able and shared by broad sets of people. 

In this sort of flexible, probabilistic framework, situational constraints such as the available of a backchannel by which a listener might interrupt or ask questions can determine what a speaker says. In some circumstances, one might try an utterance with a different degree of belief that it will be understood, depending on time pressure. This all assumes that the goal is to have the interlocuter understand -- while this is a common goal of communication, it isn't always the goal. It is possible for people to exploit their beliefs about other's knowledge states to do other acts such as show off or communicate private information to one person while another can overhear.  


If we sidestep the definitional issues around having a coherent concept of common ground, there's still the question of where in processing stimuli is knowledge of another's perspective and knowledge-state incorporated? I'll note that this depends on a lot of linking assumptions which are contested (CITATIONS). 



Is common ground required? 

There are cases where people communicate despite a small common ground; for instance when talking to a toddler or another uncooperative agent. In these cases, many of the assumptions we make about cooperative interlocuters may be violated. Is this an exceptional situation where different mental tools are brought to bear, or is this the edge of modeling another person's knowledge state and intentions (including whether they follow community norms about lexica)? 


It's easy to claim that things always work a certain way CITE USING LANGUAGE and that all interactions require common ground (check citation to \cite{clark1996}). While these simplifications may be useful at some stage of theorizing, they're not true and should be replaced by better models as a field matures. 


One other difficulty with the idea of a platonic CG is the observation of a "curse of knowledge" where basically having private information makes people unable to explain things in simple enough terms; or basically assuming more background is shared than actually is. It's unclear whether we should model this as incorrect assumptions about what is in the common ground, or rather whether it is a failure in retrieving and producing the right concepts. 

What are the bounds on common ground? Some conversational infrastructure, such as the meanings of obscure words, are taken to be something that is considered when delineating common ground. Are more fundamental norms of cooperative communication such as joint attention mechanisms also something that's part of common ground? 

One of the big problems is that it collapses over things that are assumed for larger groups with the specific personal history stuff. 



Again from a developmental perspective you can act like you have CG without having it based on heuristics (and this is probably what kids do, see also their common failures on this) 

See also the recent work talking about when we model what the other person knows that isn't shared 

The question of what are your priors or their priors and how tailored are they to the current context and in particular how much theory of mind and perspective taking (aka recursion) there is, is relevant. And that's vaguely what's being said, but with the mechanisms probably mostly wrong. 

the ways things are said to get into common ground aren't consistent with various general assumptions that people know things (like default assumption of sharing the same language, or knowing basic facts, etc) or inferences (went to same college, is a local, etc). 





\section{Communication writ large}
\subsection{Misc: Convention}

May be cultural mores about how to refer to things or how clear to be that run counter to a pure efficiency model. (Especially if there's perceived social cost to asking questions, might not be on equilibrium). 


Another place there isn't a clear line is between conventions and non-conventionalized coordination. 

Can get coordination from game theory, from probabilistic stuff, don't need to resort to common ground

conversational pacts are not just partner specific they are context specific \cite{ibarra2016}. if the context changes in a way that affects task goals or information needs, people will change their descriptions and there isn't a problem. whatever the expectations are about continuing to use the same ones, that's not absolute (and is probably the product of something else) where usefulness is a factor 

\cite{krauss1964} hypothesizes that there will be convergence and frequency-dependent modification where things referred to more times will get more convergence / shortening
 \cite{leung2023} has an implicit pattern that in forming a convention for a low-nameable thing there's two factors, getting some referring expression off the ground, and succeeding at reference and then a pattern of reduction after something has worked. This seems like a really useful high level framework. 
 
 not really sure where this goes: \cite{metzing2003a} for how much conceptual pacts stay, I think there's a question about whether what is being studied here is lexical level or conceptual level. Presumably there's some gradient and there could be entrainment on different levels. 
 
 Whether it's weird when a new speaker uses an existing convention depends on how strange the convention was and on things like evesdropping, their common knowledge background (maybe that's just what all doctors call it...), community membership
 
 Also this whole literature around new speaker / old speaker breaking pacts is a lot less robust than the amount of weight that's put on it. Wonder what the p-curve on the meta-analysis is ... 
 
 \cite{piantadosi2012} has me wondering whether conversational pacts are even real, or whether they are actually just contextual reduction is ambiguity and them peaking of the distributions in a slightly recursive way plus some recency effects and habit. This approach requires that speakers and listeners have similar models of language and the world at least in the relevant domain so that they can use contextual information to constrain the situation 
 
 \cite{piantadosi2012} in line with RSA assumes that inference is cheap and that context and speaker goals are constantly taken into account 

\subsection{Misc: Communication}

\cite{clark1986} proposes a try-repair-accept framework where reference expressions don't have to be certain to succeed and can often be present with hedged language indicating their tentative status. If they don't work, there's room for back and forth repair, before a description is accepted by both parties. Acceptance can be implicit in the form of action, or verbally expressed. 

\cite{clark1986} because communication is a joint activity, there is this possibility for repair. In the production of unrehearsed speech, if planning falls through or doesn't stay ahead of production, there may be fillers, restarts, mistakes, etc. But this may still be an ideal efficient path in expectation because it makes use of the ability of the listener to step in and backchannel. It is possible to have production strategy where you keep saying things until they choose the referent. Wouldn't need to calculate a level of informative/overinformativeness because it'll be empirically determined when they choose the thing. 

\cite{clark1986} idea of mutual acceptance is very formal way of putting it -- often won't need to be explicit and joint attention or assumptions of understanding could also work (possible to adapt to systems that due to affordances have different costs of actions and this will effect thresholds -- do you expect verbal response, or are you on a "it's good unless you hear otherwise") 

\cite{clark1986} Will have to look this up again "how does an appeal to prior acceptance work"



\cite{clark1996} idea that language (use) is a joint action

\cite{clark1996} useful take aways: - some communicative acts require a signal from the other person to close the loop (not necessarily communicative) or else there will be continued follow up (or it’ll get dropped) and the type of things that close them vary (basically people look for feedback signals from others)

- there’s on some level some considerations of who interlocuters are and what they know

- people taking into account current circumstances including prior responses ; in general tends to be some sort of monitoring if interactions for various signals when engaged in interactions / joint activities.






\section{Psycholinguistic considerations}

Limits on working memory and processing constraints often mean that human behavior relies on short-cuts and approximations rather than doing full inference that is implicated in computation models. These same limitations may explain some non-optimality in human behavior around communication and reference. 

When using language to communicate, additional considerations come into play because (regardless of how much language-specific infrastructure there is) language comes with strong habits about what is syntactically or semantically well-formed. These strong expectations about the form of what is produced and the processes by which utterances are constructed and produced and parsed and processed affect communicative output. 

Production:


Processing:

Both: 

Limitations that are not specific to language: Any sort of production process has search problems related to memory retrieval. Compositionality is also maybe not strictly linguistic. 

On a not-language specific perspective, there may be time course pressures where not all information is available immediately. Some of this is l
\subsection{Assorted psycholing}

Unsure how these few things fit together, but a few things to consider.

Where the bounded part of bounded rationality comes in -- we expect RSA-style to be a good high level model, but it's not an implementation and is agnostic about what parts are cached and at what level things are cached or short-cutted. 

Another issue is production (in terms of alternative generation, if we think RSA): (leung has a good list for this) As a speaker, one has to come up with a description at all, that description needs to be a good enough fit for the target, and then it also needs to not overly fit competitors. But generating these good enough for target descriptions is non-trivial in some circumstances, and this isn't well-modelled that I know of. How do people generate descriptions in the first place? 

Because this is language, there also seem to be strong habits or expectations about form. Like, there's a level of syntactic well-formedness that's expected, even if it's in some sense inefficient. What's the psycholinguistics here? Is this actually what's fastest to produce because of the habits of mapping to speech? Fastest to interpret? (Syntactic expections for there being a noun come into play in \cite{degen20200406} --> can't say blue without saying pin as well) 

\cite{hanna2003} Looking at the time course of using the speaker's context in processing. Bug questions around whether people are initially egocentric in their interpretations. Makes some weird assumptions about what's required to take other's perspective, on a more mechanistic level, without paying attention to the possibility for some cached heuristics. 

What would an egocentric perspective really be? Language only exists in relation to others (mostly), so how do we think about word meanings in the absence of considering the speaker (clearly there is some way of doing this, "generic speaker", whatever, but I don't know if it's well understood) there's probably also an interesting developmental component -- what's the interplay between language development and ToM development? 



\cite{heller2012} says that speakers have a harder time than listeners b/c they need to model the listener (at least approximately) 
re production should look into what the current consensus around production is 


\cite{horton1996} is interested in the processing timeline incorporation of CG -- raises a lot of questions about what the current production literature is, assumes that social context is complicated and costly to put online, really bizarre discrete time step assumptions; doesn't clearly specify what the alternatives to using CG are; there's also issues where some of what looks like audience design/CG might actually be various heuristics or speaker-dependent functions and it's hard to do that (caching, yknow) 

For the whole egocentricity timeline stuff, there's a big question of what things factor in how much when and how much that gets pushed around by other constraints such as working memory etc. There's multiple dimensions here (not to mention the many nuisance ones), and we don't have many points of experimental evidence. 

\cite{keysar2000} makes assumptions that we know a lot more about processing and how to interpret eye-movements than we in fact do. Seems to assume that people should have absolute assumptions that what is communicated about will be mutually know via being in mutual view. This is dumb and in real life is never going to be that strict -- it is possible for people to refer to things that are out of their sight at the moment and even when you don't know that the know about it. That needs to be within the considered distribution. Seems to be that the questions are about the relative mix of top-down and bottom-up processes when searching for a visual referent. 

\cite{keysar2000} seems to imply that audience design means that listeners don't have to do work (maybe I missed something) 

\cite{pickering2004} the Ferreira commentary beings up that there are speaker / listener asymmetries and that these may have audience design / work splitting consequences as easy to produce and easy to comprehend are not always the same thing 

\subsection{Production}

\cite{macdonald2013} thinks that production in particular is very important. This gives a functionalist account focused on production as the driving thing that then informs both comprehension and typology. Claims that there are three biases in production: easy first (taking into account word level and context dependent retrieval factors, seems relatively consistent with memory stuff), plan reuse (which is the explanation for structural priming) and reduce interference. The bigger claim is that utterance planning difficulty is the driver here, and that comprehension interpretation is just relying on the statistics of the input from speakers. 

This has got to be cyclic over time, since unlike things with external statistics for humans to learn from, language is a human product and the product and the production and processing and none of them externally determined. Unclear how to adjudicate over which pieces are the driving bottlenecks and what is adapted from there. 

Claims that production is winner take all (\cite{macdonald2013}) not sure how to think about that really 

\cite{macdonald2013} also claims that some of the production stuff is related to pretty specific mechanistic memory stuff (which doesn't seem implausible, but I don't know the memory literature well) basically it hopes to ground things out with appeals to domain general features of saliency to avoid circularity about what is easy to produce 



\section{Efficiency}

Various areas of psycholingustics are tied in with a paradigm of efficiency as a high-level descriptor of a pressure on language and language use that occurs on multiple time scales. 

For most of this, has to work backwards from the observed features of language and language use, although at the small time scales can be experimentally observed as well. 

Question is basically: what pressures could explain the properties that are observed. Efficiency is basically a trade-off and most theory say that it's the result of two somewhat opposed pressures although what exactly the pressures are varies. 


There's a growing consensus that various aspects of language over varied timescales, from evolution of specific language systems to language use, display properties that are parsimoniously explained by efficiency. What does efficiency mean? Something like close to optimal in the trade off between informativity and processing/production. We could see this as a trade-off between different pressures (and that's probably how it developed?), but it could also be close to optimal for how quickly the information content (thought/idea) that a speaker wishes to communicate is conveyed to the listener's thoughts, taking into account that this includes mapping from thoughts to language, producing the language, time to transmit the sound (how fast the speech production is), parsing the signal back into linguistic units, and inferring meaning from that. There's all these (somewhat overlapping) steps, and especially for common messages and key information content, language is far above chance. This could be seen as trade-offs in various things, or as trying to minimize the process subject to some standard of close-enough on the meaning front. 


Lots of questions about efficiency (see also the notes taken below already)
What are processes that shape efficiency (especially in real-time production)? How does efficiency shape interpretations? There's the long-form for rare bias, but that requires pretty well-formed alternative sets. 

What do we really mean with efficiency? How does it play out on different time scales? What expectations does the overall efficiency framework impose on communication and reference? 

This also gets to ideas of informativeness. And if you get into informativeness and the interaction with relevance. 


As an overarching thing, efficiency is hard to prove or disprove in part because it relies on a lot of linking hypotheses for how it should play out in different domains. But it has parsimony and explanatory value across a lot of levels. It's a good fit to the data, even if the realms for experimental tests are somewhat limited. 

As Zipf points out, it's important to be clear about what the imagined optomization function is (when thinking at a high level), or what the pressures are that create the constraints at lower level. Efficiency depends on what the time scale that's being optomized for is -- someitmes more prep / longer will pay off over repetition (and you don't know the future, so probabilistic)

Related to a lot of efficiency work is trying to figure out what the pressures on language are -- like what's the stuff that's being optimized for here, but you have to back it out from behavior. 

The idea is that language and language use appear to be optimizing for efficiency; this is there appears to be a balance between effort and information conveyed. This is posited to be the result of different pressures in opposite directions, with processing/ production or learning pushing for simplicity and the need to communicate pushing to make things more complicated. 

Then the questions are
* what is the right characterization of forces and how do they actually operate (TODO look up cites because some include learning and some production) 
* what can be explained on what time scales by this

\subsection{Time scale: languages}
One observation is that various aspects of language show patterns consistent with efficiency. 

 
\cite{zipf1949} was an early proponent of language being shaped by some efficiency pressure ("principle of least effort"). \cite{zipf1949} makes some observations about the tradeoffs between the number of signs and how much meaning each sign has; although this seems to be an ahistorical account that isn't covering historic changes in word meaning or the processing the drive the equilibria we see. claims about numbers of meaning are presuppose a knowledge of what counts as a separate meaning. Makes the observation of a power law distribution (which led to Zipfian being a synonym) Number of meanings versus usage -- also more to the point there are strong claims here and sloppiness with regard to units of analysis and when there's intent and what level of analysis and plausibility it's going for. 

Railing against zipf stuff: \cite{piantadosi2014} we observe from zipf that the rth most frequenyt word occurs roughly 1/r of the time (inverse proportion to rank) this is a power law distribution 
Zipf claims that this is due to his minimum effort theory (see zipf). But there are many, many processes that could and do produce power law distributions. So the fact that this is power law distributed is very weak evidence since there's many alternatives for generating this pattern. There's actually a richer pattern in language in terms of both small deviations from this pattern and the fact that this pattern shows up in domains where you restrict to words with approximately the same denotation (but strongly varying levels of tabooness/slang/context) -- this isn't explained by Zipf's claims because it's not a mapping of how commonly different meanings need to be expressed and what words are chosen for those meanings. A lot of claims in this area aren't very testable, or aren't very cognitively reasonable, or don't even explain this narrow cut of the data. Rather than focus on this one feature, it makes sense to look at broader patterns that need to be explained, for instance by efficiency based explanations. 

\cite{kirby2015} talks about how language has a combinatorial structure at multiple levels and that this combinatorial structure is key to be able to talk about new things (which is important because of the non-stationarity issues) 

\cite{kirby2015} key idea that combinatorial and efficient are in tension because a fully regular system will make everything very long

\cite{kirby2015} many language systems and subsystems that we see seem to be near the expressive/ compressive trade off space; claim that this is because of tensions between compressibility (important for learning) and expressivity (communication) 

\cite{futrell2022} From an information theory perspective, trying to back out what functional constraints language is operating under / what constraints would explain language. What is language optomizing for and what pressures are driving that optomization? 

On a language level, both semantic categories and syntax (and potentially things like phonology as well) seem to be closer to what optimal would be than would be expected by chance. While we can look at this and it looks optimized for efficiency (in different parts of the communication sequence, so addressing different potential bottleneck points). Some of this is that commonly conveyed meanings have short ways of saying them (they have words aligned with those meaning levels) instead of either requiring additional modification (increasing speech time and processing time) or unecessarily overspecifying (increasing processing time). Another component is that syntactic properties such as harmonic word order seem to be good for allowing listeners to generally parse things reasonably. 


\subsection{Time scale: conversation} 

\cite{kemp2018} on semantic typology. When measuring informativity and what information loss occurs as a result of communication, we need to do this relative to what is important in the situation to communicate. With their kinship examples, the question is how often things like older and younger or gender of siblings are relevant versus just the fact of siblinghood. Over time depending on how often these sorts of factors have to be communicated (which the claim is, may be socially specific) that will determine what distinctions are lexicalized versus not. This is determining where on the frontier different languages end up, but they all tend to be not too far off from the frontier. Depends on how often things are referred to and how specific it needs to be in those cases (basically how close the contrast set is). 

\cite{hawkins2021} points out that increasing efficiency (at the level of interactions) often isn't so much about saying less as about being able to express more and more complex ideas in the same amount of words/time 

\cite{gibson2019} ideas of communicative efficiency, complexity, and learnability- these are all factors that probably shape things. These are going to be context dependent on the usage situations. For in-context efficiency, if there's a lot of uncertainty on what will be an adequate description and there's a strong backchannel or possibility of incremental, then should try things because there's the opportunity for clarification. 

\cite{gibson2019} for various syntactic things, including information locality, these might count as efficiency under the idea of making things maximally easy to understand. This is then going to be how fast can you sufficiently accurately construct the tree from the string, which will be how fast you can convey meaning, but on the comprehenders side? 

seems like what's being minimized is the time to communicate including the production and comprehension processing times (expression length isn't the only thing that's minimized)

Over time an arbitrary form-meaning mapping becomes systematic which then means that the mappings aren't arbitrary because there's embedded in this system and so couldn't change unilaterally. 

\cite{gibson2019} it's hard to measure things like communicative utility which makes it harder to instantiate some of this theory (unclear which things are my thoughts in response and which are brought up in paper) 



There's a question of what the microlevel processes are the drive efficiency, and this is where thinking of things in terms of trade-offs comes in. If something is too hard at any point and causes that to bottleneck it's bad, but things that ease whatever the bottlenecky step are will be more successful and those more widely adopted. There's also the possibility that sources of flexibility become grammaticized as they are reinterpreted (cf. Hawkins), that is soft processing constraints that lead to things like heavy-NP shift may then become seen as part of the grammar by frequent use and then the less frequent parts don't get used even in the specific (rare) situations where they (in isolation) are processing-optimal. There's pressure to grammaticize either from learning or from making parsing easier because fewer options? 


On a more relevant level to present interests, speakers and listeners converse in situations where the language is approximately set in stone. There are expectations about what words mean and how syntax works. Given those inventories, speakers and listeners get to make choices about how to interlocute to efficiently do cooperative mindreading. There's a lot of possible levers here: 

* what wants to be communicated comes with a certain level of precision (or lack thereof). in reference, you just need to get the right target given context. when describing an event, there's parts of it that you want to convey, but it's not recreating everything
* depending on syntax and word order constraints (that is, expectations), different languages lend themselves to pointing out different things. We might imagine that in some circumstances one might want to say isolated words out of order, but this would be pretty unnatural and so incur processing costs on the listener end. Possible also on the speaker end producing it, if planning takes longer. If the channel is artificially limited in a game (or telegram) maybe it's worth this trade off, but in everyday speech, the speech length may not be the limiting part. 
* in most conversational environments, there's the option for the listener to respond or otherwise for feedback to be given. thus, there's the possibility for stopping early if an utterance is sufficient or continuing if it is not (because sufficiency is ascertainable from the listener response either verbally or behaviorally -- i.e. reaching towards the wrong thing). How much this feedback is possible varies, but when it is, it makes sense that utterances can use this. Thus, the most efficient path may be to try something and add more only if needed. (This goes well with not necessarily having absolute knowledge of the interlocuters mental state. )

* over the course of a relationship (or conversation) the conversation history shapes expectations which will allow for different descriptions to become efficient -- either increasing belief that something is enough to try, or making less syntactically normal / highly reduced things seem okay (and thus not incur processing cost?) in context. 

How to deal with that a lot of the time people are joking or whatever? Still trying to convey meaning (even if complex, or meta-linguistic meaning)

\subsection{Time scale: utterance} 
\cite{rubio-fernandez2021} looking at language efficiency and incrementality -- brings up questions of how immediately things are parsed (linear v heirarchical) and suggests a conflict between efficiency and informativity -- although really efficiency is informativity x briefness right? 

\cite{rubio-fernandez2021} when looking at incremental efficiency; from an informativity perspective in the moment you're going to get a clash with well-formedness and syntax some of the time -- how does that resolve and why does it resolve the way it does (is it production / comprehension that means those aren't actually efficient, because there's more to life than phoneme counting) Seems to put the brunt of the weight on the speaker for doing design for the listener 


\cite{bybee2006} possible that encoding linguistic events into memory and then retrieving is a mechanism that results in efficiency on a language over time scale? (look back at text for more) 
refers to frequency effects -- perhaps some of these are actually predictability effects to link to a more information-theoretic approach 





\section{RSA / probabilistic models }

One school of thought around pragmatics (both the ad hoc pragmatics that takes place constantly and conventionalized pragmatic implicatures) is that they can be modeled as a rational recursive mental modeling of the interlocuters state. There are multiple probabilistic models in this stream (CITATIONS), but I focus here on the Rational Speech Acts model. 

Overall, RSA is a computational framework for making quantitative predictions about pragmatic behavior \cite{goodman2016}. The basic idea of the Rational Speech Acts (RSA) family of models is to picture the two interlocuters recursively reasoning about how the other would produce or interpret utterances, grounding out in a listener (or speaker) who behaves in a pre-specified "literal" way. This framework is usually run with one or two levels of recursion, where it tends to produce a reasonable fit to human experimental judgments. 

Different instances of RSA incorporate different sets of components in the models. It is common to consider factors such as the prior likelihood of referring to each object (salience prior) and some cost on utterances where longer or more complex utterances are most costly to produce. 

\cite{frank2012a} This is an information theoretic approach, with the goal as to how to quantitatively predict pragmatic inference in context (that's the big goal). Question here is how to do this with less clear referents like abstract things. Features that matter are the contextual salience (although this is sometimes ignored) and a surprisal-based informativeness measure (how much the utterance reduces uncertainty) which could either be empirically or semantic-system calculated. Lots of work is about how to scale this system up to things that eventually come into contact with interesting interactions. Although also may be able to account for some conventionalized pragmatics too. 

\cite{goodman2016} RSA is a computational framework for making quantitative predictions about pragmatic behavior. Variations on RSA pull out different features could be at play -- in some sense a full model would have to include all of these, but many are particularly relevant in different situations and so get modeled in those cases. 
One approach to explaining both some conventionalized pragmatic implicatures and some features of people's pragmatic language is the Rational Speech Acts approach of modeling pragmatic usage as a speaker and listener recursively reasoning about the other. Variations of the basic model have provided computational model explanations of a number of phenomena (CITATION). 

The basic idea of RSA is to specify some level-0 listener whose lexicon is specified in some way. From there, the speaker reasons about the listeners lexicon, and samples an utterance that softmaxes their utility function. Then, a pragmatic listener reasons about how to interpret an utterance by softmaxing a meaning given their model of the speaker and literal listener. This is a fairly basic framework, but many of the chunks here can get quite complicated when necessary. 

While it is possible to run the recursion farther, in general RSA generates reasonable fit to human behavior with level 1 or level 2 listeners or speakers. (TODO CITE DEGEN). 

Because it's already using a probabilistic framework, it's possible to model uncertainty at various levels and then integrate over the uncertainty but also make updates to it on the basis of more information. 

There's a lot of flexibility, but this means that choosing the right semantics to ground out the literal listener with is important. This poses a challenge, and I suggest that in order to extend this model towards more realistic and open-ended scenarios, an important question to grapple with is what form of meaning (even at a computational level) will appropriately support pragmatic reasoning. 

Some models have used truth value lexical semantics (CITE), but this poses problems as the targets decrease in nameability. Some sort of soft or continuous semantics can be used (CITE) which ameliorates some problems. However, it still raises the question of compositionality. CITE sidesteps this issue by using a closed class of possible utterances and measuring their semantic fits empirically, but treating things as chunks is not scalable to open-class utterances. It also conflicts with the desires for an incremental RSA that could account for informativity-based ordering preferences or manage language use where interruption is possible. 

This could be read as saying that we need to solve semantics in order to have pragmatics, but I'd instead see that a productive way of thinking about what a good semantics system could be is to think what could support the pragmatic language use we see as send through as RSA-type framework. (This still leaves off all the sampling and processing constraints that eventually will also need to be considered.) 

One advantage of RSA and other probabilistic models is that they can make graded quantitative predictions, accommodate variability, and weigh trade-offs between different perceived pressures on communication (such as when different Gricean maxims come into conflict). These advantages all come from having to fully specify the components of the model. 

This probabilistic approach can be seen as a quantitative formalism similar to other graded approaches such as the verbal theory of constraint-based. However, RSA is explicitly a computational-level model that is sometimes agnostic to whether the calculations are happening in the conversation or are a cached process that has been crystallized into conventional usage. 

** Intro to RSA ** 



** Advantages to a probabilistic approach

One point of distinction for a lot of theories is how they handle uncertainty on the part of interlocuters. Many do not and instead contort themselves to accomodate the fact that people make (in these models) assumptions about what others know based on appearance/etc (assuming member of speech community, assuming general knowledge ). But then they also have to specify accomodation and repair mechanisms to deal with when things that were treated as being commonly known where not known by the interlocuter. Especially in reference to hard to describe objects, people may not always describe things in ways that they "know" the other person will understand, which is harder to explain under these stricter models. 

Probabilistic models allow for uncertainty over what other people know, and what others think words mean, etc etc, and thus some of the accomodation is more built in. 

Gricean maxims provide some descriptive coverage, but there's often (perhaps always) conflict between them and none of them are well enough defined to specify what counts as "relevant" etc. 

** One big question is what sorts of semantics are needed to support the model working. 

One central issue that comes up when discussing linguistic communication is the semantics-pragmatics divide (if you believe in that) or how word meanings are represented. Words certainly have conventionalized meanings (that's how we can talk to people who we haven't talked to before), but there's questions about what the representations are and separately, what an appropriate way to model them is. 

Is literal semantics a useful model? Clearly lots of formal semantics isn't psychologically plausible, but some of the approaches could be useful simplifications for plugging in to RSA. What literal semantics will support RSA to explain different things? Like, what if we treated semantics as another Marr Level 1 component of RSA. 


** Some of the uses have been to explain conventional pragmatic implicatures. 

\cite{bergen} is mostly trying to explain a very particular set of implicatures raises questions about what types of semantics are a reasonable substrate for RSA. (see notes for details about options for semantics) 

Things that at one point may have been pragmatics become entrenched by usage (possibly within partner specific ad hoc interactions, but certainly over time for a community) 

** Some have been to explain reference expressions. 

\cite{degen20200406} in choosing a referring expression, some trade offs between cost of utterance and informativeness (also many, many things no where near the frontier, just for the record) 

\cite{degen20200406} uses continuous/soft semantics to explain how redundancy can be useful

could look at \cite{degen20200406} as asking the question: what's a system of semantics and RSA pragmatics that would generate and explain these observed phenomena (what are the constraints or processes that could lead to this output) 

idea of soft semantics is necessary for dealing with tangrams where truth value semantics is unlikely to cut it -- then the specificity and truthiness of the description bits is what's competing 

** All raise questions about how to account for all the sources of variability. 

Some key questions here are: what are the alternatives to an utterances? What the literal semantics being used? What's the belief/likelihood representations? 


there's a conflict between compositionality (which \cite{degen20200406} get around by using whole phrase semantics) and incremental RSA / ordering constraints for cross-linguistic --> points to a tension on how to do both

Again a big question is how to ground the semantics of the literal listener -- what usage is based (and what is pragmatic enhancement), and what sort of semantics even works. Truth value doesn't work all the time, how to introduce uncertainty there? 

Some RSA models incorporate cost terms -- abstraction of various things, which is probably related to efficiency pressures (or is modelling the causes of efficiency pressure) 

Questions of how to model uncertainty over word meanings and other parts of interlocuter states (what do they know if this is not mutual knowledge) or their goals

\cite{goodman2013} this paper again raises the question of what's the right literal meaning to use  -- is it some sort of context free expectation? 

How much do extra-linguistic, domain general factors affect pragmatics? Priors? Seems like there's a fine grained interaction between knowledge and implicature (not really sure what I meant here)

At a broad-strokes computational level, abstracting out language-specific constraints and the details of production and processing, I think that RSA-style models are promising. These theories allow for probabilistic integration of the many linguistic and non-linguistic sources of information that are at play in conversation. It can accommodate different goal states as well as varying levels of certainty about anything. Many versions have successfully matched behavior in limited domains, but there are many factors that are in play in some situations and ideally they would exist in the background of models the rest of the time. Computational tractability becomes a problem if there are actually included, but it most cases, it seems like considering these other factors and then neglecting them is reasonable. 

Some particular challenges for using RSA in practice are the various ways that communication is open ended: it has open vocabulary, open issues of compositionality, open number of turns, and (with spoken language) is highly incremental with options to take actions or interrupt mid sentence. As it becomes more open-ended, issues of how to consider alternatives and the psychological implausibility of actually considering all of them may come into play. A resource-rational approach that uses sampling instead of exhaustivity may provide a way of pushing this computational theory down into being slightly more concrete. 


\section{What I think is true}

Perspective: Theories should be clear about what level of analysis and scope of explanation they are trying to provide. Theories that are compatible with other theories operating at different levels of analysis and that are compatible with the theories and evidence from adjacent fields are preferable. With that position, here's my distillation of what theories are most promising to me. 

At a broad-strokes computational level, abstracting out language-specific constraints and the details of production and processing, I think that RSA-style models are promising. These theories allow for probabilistic integration of the many linguistic and non-linguistic sources of information that are at play in conversation. It can accommodate different goal states as well as varying levels of certainty about anything. Many versions have successfully matched behavior in limited domains, but there are many factors that are in play in some situations and ideally they would exist in the background of models the rest of the time. Computational tractability becomes a problem if there are actually included, but it most cases, it seems like considering these other factors and then neglecting them is reasonable. 

Some particular challenges for using RSA in practice are the various ways that communication is open ended: it has open vocabulary, open issues of compositionality, open number of turns, and (with spoken language) is highly incremental with options to take actions or interrupt mid sentence. As it becomes more open-ended, issues of how to consider alternatives and the psychological implausibility of actually considering all of them may come into play. A resource-rational approach that uses sampling instead of exhaustivity may provide a way of pushing this computational theory down into being slightly more concrete. 

People are fairly sophisticated at modeling the knowledge states of their listeners, both in terms of explicit knowledge and the use of heuristics. These beliefs are graded and some assumed knowledge goes with broader groups of people. There may be ideas of somethings being "general common knowledge" or known among people at the university. Not everything may need to be fully calculated for each person. This is like a partial pooling model on knowledge -- we may also update how commonly known something is upon discovering some people don't know it. Cultural norms around givenness are something that must be learned jointly with other norms about symbolic communication (primarily language). 





There are constraints on the optimality and these are also important to consider -- some of these may be memory constraints or processing constraints that are domain general about how veridical memories are and how much we know about and can track situations and interlocuters. If we start getting to implementational levels, or even just resource-rational levels, will need to start accounting for how many things can be integrated at once. 

Another source of constraints for implementational levels is how the language production and processing system works -- what possible utterances are and how they are produced and how things can be structured are constrained by language. 

Broadly think that efficiency is a driving factor and seems to have broad explanatory power, although we have to think about how it plays out in any particular situation. 

For communication, we could see efficiency as manifesting in trying to optimize bits of (goal-relevant) information conveyal per unit time. Conversation is a complex process so there's a lot going on: there's a mapping of goal to relevant information (which might be lossy), the speaker then has the access words to produce (which may not be easy for descriping low-nameability referents), and produce them. The comprehender then has to parse the string, interpret it (along with whatevever pragmatic integration is required) and then take an action. Often efficiency is established on the basis of how long the words are, but in some cases saying more words may be efficient if it reduces production costs or comprehension costs (making the task easier, or making it easier to understand by being nice to the parser). 

We don't have computation models for how to cost all these pieces against each other, so for now it's hard to verify these things. 

While here I'm following a high level probabilistic approach, it has a lot of similarities to the constraint based approaches in considering trade-offs between a number of soft constraints. In this way, has a lot of properties shared with cognition generally. 

Don't distinguish hard lines between "normal" and abnormal situations -- communicative and linguistic skills can transfer to new contexts and depending on the contexts, relative weighting of different factors will be different, but those are just the extremes of the same distribution we are constantly in. 

When considering repeated reference especially for difficult-to-name targets, I think there's a productive split between what is needed for 'first contact' -- establishing an initial successful reference -- and what drives subsequent references, where reduction and changes need to be accounted for. One key distinction that doesn't get explicitly highlighted much (but is brought up in some recent work, such as \cite{leung2023}) is that the process of `first contact' -- establishing initial reference -- is at least somewhat separable from the repeated reference / reduction phenomenon. They're probably not totally separate as the same systems will need to work for both, but there are probably peculiarities to the reduction part. 

Factors are very unlikely to be all or nothing. A salience prior makes sense, as a priori there may be expectations that an interlocuter will refer to something mutually visible for instance, but the prior space also needs to include that they're referring to something you can't see, or making a joke spouting nonsense. These low-probability outcomes that need to be allowed pose a challenge for absolute system, and also seem to mean that priors need to incorporate everything, albeit at extremely low levels. (Need to remap 0's to something tiny) 

Considerations from audience design literature: generally pretty reasonable, communication is in some high dimensional space and there are a lot of potential influences. 

``partial pooling'' model: some sensitivity to context \& who said what, but source memory is hard. Also, there are recency effects \& some expected transfer/universals (learning language) 

Distinction between elaborations (common with a new listener) \& totally new ideas (rare)

From audience design: speakers take into account the whole set of listeners who are present -- tend to tailor so that all could understand, but use meanings/shorthands that knowledgeable ones will recognize (=> many possible ways to accomodate multiple listeners, perspectives, also consistent with a name \& describe that's good for future) 

performance is constrained by realities of task switching \& memory and interference (so some performance things that don't seem ideal may be from those things) -- bounded rationality 

speakers can also take listener context into account (at least when known) but again probably bounded by working memory

shared social history makes for efficient label sharing 

A few directions that seem useful:
* start at RSA and attempt to scale up to accomodate conversations (tackle the open ended things)
* try to figure out what the bounds from memory / processing / production are and push a model down to a more resource rational / sampling based implementation
* something something extend theories to how groups work?


\section{meta}
general meta-theory: when something is a new area, easy to make over-simplifiying models of “here are the two or three ways it could work” this is useful, but as a field matures, important to accept nuances.

useful sketch of some options versus reality / full messy space of options

Stronger if you have gradients (ideal if you have math model and can do something quantitative)

\subsection{ Levels of analysis and implicit versus explicit knowledge}
many theories are loose on what level of analysis they are addressing things out, and if there posit representations whether they mean that those are actually in the mind somewhere or whether it's a model that might not be actually possesed by people in that form. Also how much there may be a layer of approximation over everything. 

\subsection{experimental space and messiness}
20 	questions with nature. 
the experimental space here is quite huge and many of the experiments lack in generality and rigor (it's hard not to, especially by the standards of the day). Thus, a lot of the theoretical claims, while possibly useful and true, are not well supported by the evidence presented. 

In the start of an area of inquiry, it makes sense to use blunt tools and try to categorize things and limit the "messiness" in order to get any sort of traction and be able to start a theory (at least, this is a common approach, unclear if I actually think that it makes sense to have as much early theory). As evidence accumulates and a landscape of results starts to take shape, this stops cutting it. It becomes clear that there obviously is complexity and ignoring that complexity no longer suggests the right next experiments. Over-simplifying assumptions are common in the theory here, which may have been useful and necessary, but increasing maturity of an area comes with expectation that more be explained, and more quantitatively. 
\subsection{Constraints from other disciplines}
We're not making a theory of everything here, but if there are going to be appeals to parsimony, they need to take into account all the other stuff that will perforce be going on outside of this. Thus, if some things already are needed or well-explained that's to be  taken into account, especially with regard to domain general processes. 

In particular, reference contacts other disciplines in the forms of social cognition, since this is a social interaction and involves tracking other's understanding and knowledge states, and memory, since it involves remembering things. What we know and belief from these disciplines will need to match. Thus, if something is common and considered a solved problem, we can't appeal to it being hard. On the other hand, memory is decently understood and so we should reject models that posit implausible memory systems or memory retrieval operations. 

Models may be skimpy on these fronts if they are high level, but that should be explicit. 

Other evidence from language use and perception/ categorization boundaries may also come into play. 

\section{Open questions that aren't satisfactorily answered}
\subsection{Good: Unsatisfying ?: Explaining reduction phenomena}

For an efficiency standpoint it makes sense that the more something is referred to the shorter and easier it will be to refer to. However, this does not explain the process by which is occurs nor the partner-specificity that is observed. 

Many of the theories related to partner-specificity can explain how people succeed at establishing reference with each other and separately, why they persist in using shared terms. This too cannot explain how reduction occurs, since the reduction necessarily involves a change in how something is referred to (if only by dropping words). 

One approach to explaining how interlocuters might go from descriptions involving multiple components to fewer components is sketched in \cite{hawkins2021}. In a toy world with a limited number of utterances and targets, positing lexical uncertainty and TODO what the compositionality function is then applying RSA qualitatively results in the reduction pattern. Initially as each word has very uncertain meaning, using two that each slightly favor the target object makes sense because both is a much stronger indicator than either alone. However, each time they both are used together in this way, that causes a vocabulary update increasing the link between word and target. Once the link is strong enough, one of the words on its own is sufficiently clear that the cost of two words outweighs the now marginal additional clarification value. 

To the best of my knowledge, this is the only model that posits a computational mechanism that explains the reduction phenomena. As a toy model, it simplifies many aspects, and a line of modeling word could be gradually adding in real-world sources of complexity. For instance, what sort of semantics, both for the meanings of words and chunks, and for their compositionality, could support either the initial interpretation of long multi-part descriptions, and the updating required to eventually lead to reduction? 

Another piece is that reduction isn't just about shortening in the number of words or concepts used; it also tends to follow a stereotyped pattern, where more abstract, holistic "names" stick, while descriptions that may be more concrete or describe the image piece-mail tend to drop out. Why is this what happens?  Is there a way to model the initial semantics of these pieces and of the updating such that this pattern of what sticks is predicted? 

An additional complexity here is that the end point can vary. Usually holistic or analogic descriptions win out \cite{clark1986}, but this isn't absolute. Sometimes groups may use something strange and even something that is on a lower-level or on a meta-level as their referring name, and for them, this can be effective. So to fully explain this, we need to take into account the path dependency for how reduced utterances evolve, and potentially also account for issues such as people's relationships or humor value. 

Another desiderata from a computational model would be accurate predictions for the rate of reduction, although this too can vary greatly depending on groups. 

Overall, the high variability of reduction depending on images and group members and their interactions will make it hard to fully explain. However, even for a canonical instance of reduction, we have been limited to hand-wavy verbal theories. Now a promising model that can explain the pattern in a toy word, but incorporating semantics may prove challenging. (As it has elsewhere in RSA.) 








\subsection{Unsatisfying open ?: Groups}


\cite{yoon2019} how much do you think of the group as a unit, versus as a set of individuals (obviously this is going to change some as group size changes, but what are the patterns) 

\cite{clark1996} focuses very much on dyadic interaction, and is in the vein that multi-person is serial dialog (verify this last part). 

how to extend ideas of joint action to accomodate multiple people? (re clark1996). 

One question is how you extend RSA up to multiple people -- how to do an utterance designed for multiple people? I guess you could represent separately and fit whatever joint function for optimizing that you want? 

groups allow for more complex structures. \cite{fay2000} tries to look at whether 5 and 10 person groups behave more like dialog or serial monolog (to the group) -- I think it's unclear that this is useful -- how do you define interactions / how do you usefully measure commonalities. There is a suggestion that there may be a transition point in how groups behave, possibly around 10 people, although context and goals seem very likely to push this around 

how to account for side conversations or parallel tracks which are available in some modalities (and not others) also other mediums such as fora / discord / slack have different affordances for allowing branching and parallel things that might be better for groups 

Groups can be complicated \cite{guilbeault2021} looks at how different sizes of groups interacting over a network structure result in different category boundaries, where large groups end up more the same than small groups. Brings up questions about network structure and how we should think about networks even within groups where multiple people are interacting synchronously. Some of the other try to only allow lines between points -- either bidirectional is dialog or single-directional in monolog but there's still the development of shared stuff from the co-presence of listening to someone else even without direct interaction? 

There should be some gradients in terms of these forms of more indirect interaction that aren't explained by dyadic models because the mechanisms that are claimed to support the partner specificity don't cover it (for in part being too low level?)

\cite{hawkins2021} for groups, how should we think about the pooling and updating based on the group -- have a different type of somewhat indirect evidence about the group members, although how indirect it is may depend on group size and structure and dynamics 

it's really unclear how \cite{pickering2004} would accomodate three people in their priming approach. can three people act as two people? 


One question is about the partner specificity of representations and how they may bleed together

This also interacts with other things such as ToM all of social cognition and the nature of memory representations 

\bibliography{sources.bib}
\end{document}
