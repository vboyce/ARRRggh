\documentclass[]{article}

%opening
\title{ARRR: Why most theory is this area is weak and wrong}
\author{Veronica Boyce, local cynic}

\begin{document}

\maketitle

\section{Summary of efficiency}

There's a growing consensus that various aspects of language over varied timescales, from evolution of specific language systems to language use, display properties that are parsimoniously explained by efficiency. What does efficiency mean? Something like close to optimal in the trade off between informativity and processing/production. We could see this as a trade-off between different pressures (and that's probably how it developed?), but it could also be close to optimal for how quickly the information content (thought/idea) that a speaker wishes to communicate is conveyed to the listener's thoughts, taking into account that this includes mapping from thoughts to language, producing the language, time to transmit the sound (how fast the speech production is), parsing the signal back into linguistic units, and inferring meaning from that. There's all these (somewhat overlapping) steps, and especially for common messages and key information content, language is far above chance. This could be seen as trade-offs in various things, or as trying to minimize the process subject to some standard of close-enough on the meaning front. 

Zipf is an early proponent of language (the system / artefact) being shaped by some efficiency pressure ("principle of least effort"). He points out that if you're maximizing something, you need to get it all into one equation, you can't optomize two things at once (unless you specify how they trade off with each other, but that's jamming them into one equation). His evidence for this is ... lackluster, and there isn't an attempt at looking at other possible explanations for the data, but his work did inspire others to do a better job at looking at this. 

On a language level, both semantic categories and syntax (and potentially things like phonology as well) seem to be closer to what optimal would be than would be expected by chance. While we can look at this and it looks optimized for efficiency (in different parts of the communication sequence, so addressing different potential bottleneck points). Some of this is that commonly conveyed meanings have short ways of saying them (they have words aligned with those meaning levels) instead of either requiring additional modification (increasing speech time and processing time) or unecessarily overspecifying (increasing processing time). Another component is that syntactic properties such as harmonic word order seem to be good for allowing listeners to generally parse things reasonably. 

There's a question of what the microlevel processes are the drive efficiency, and this is where thinking of things in terms of trade-offs comes in. If something is too hard at any point and causes that to bottleneck it's bad, but things that ease whatever the bottlenecky step are will be more successful and those more widely adopted. There's also the possibility that sources of flexibility become grammaticized as they are reinterpreted (cf. Hawkins), that is soft processing constraints that lead to things like heavy-NP shift may then become seen as part of the grammar by frequent use and then the less frequent parts don't get used even in the specific (rare) situations where they (in isolation) are processing-optimal. There's pressure to grammaticize either from learning or from making parsing easier because fewer options? 

On a more relevant level to present interests, speakers and listeners converse in situations where the language is approximately set in stone. There are expectations about what words mean and how syntax works. Given those inventories, speakers and listeners get to make choices about how to interlocute to efficiently do cooperative mindreading. There's a lot of possible levers here: 

* what wants to be communicated comes with a certain level of precision (or lack thereof). in reference, you just need to get the right target given context. when describing an event, there's parts of it that you want to convey, but it's not recreating everything
* depending on syntax and word order constraints (that is, expectations), different languages lend themselves to pointing out different things. We might imagine that in some circumstances one might want to say isolated words out of order, but this would be pretty unnatural and so incur processing costs on the listener end. Possible also on the speaker end producing it, if planning takes longer. If the channel is artificially limited in a game (or telegram) maybe it's worth this trade off, but in everyday speech, the speech length may not be the limiting part. 
* in most conversational environments, there's the option for the listener to respond or otherwise for feedback to be given. thus, there's the possibility for stopping early if an utterance is sufficient or continuing if it is not (because sufficiency is ascertainable from the listener response either verbally or behaviorally -- i.e. reaching towards the wrong thing). How much this feedback is possible varies, but when it is, it makes sense that utterances can use this. Thus, the most efficient path may be to try something and add more only if needed. (This goes well with not necessarily having absolute knowledge of the interlocuters mental state. )

* over the course of a relationship (or conversation) the conversation history shapes expectations which will allow for different descriptions to become efficient -- either increasing belief that something is enough to try, or making less syntactically normal / highly reduced things seem okay (and thus not incur processing cost?) in context. 

How to deal with that a lot of the time people are joking or whatever? Still trying to convey meaning (even if complex, or meta-linguistic meaning)

As an overarching thing, efficiency is hard to prove or disprove in part because it relies on a lot of linking hypotheses for how it should play out in different domains. But it has parsimony and explanatory value across a lot of levels. It's a good fit to the data, even if the realms for experimental tests are somewhat limited. 

\section{Why common ground is dumb}

The idea of common ground assumes that it's a thing that exists. That isn't true but also isn't relevant -- what matters is what one person thinks is sufficiently mutual between them and their interlocuter. The depth effect of common ground is rarely relevant, but people can be mistaken about what is in common (ex. you think it's in common ground because you told it to them, but actually they forgot). Also, as will be discussed extensively, this isn't all or nothing -- I can have uncertainty over who knows what, or think something will be understood because it's generally known by people without specific reason for the individual. 

The question of what are your priors or their priors and how tailored are they to the current context and in particular how much theory of mind and perspective taking (aka recursion) there is, is relevant. And that's vaguely what's being said, but with the mechanisms probably mostly wrong. 

One issue with distinguishing what shapes utterance production is that we primarily have access to the outcome at the end, which mostly isn't what anyone is arguing about. The questions are about what the process is for generating that utterance and what sorts of things are how prominent in the process when. This leads to lots of hand-wavy models about how language is produced (again, hard to model well since we don't have access) and flimsy linking assumptions with behavior. 

One assumption is that telling someone to respond faster (time pressure) will change the production pathway/process in a way that limits later steps more than earlier steps. Clearly, time pressure (and other resource constraints) do affect production, but how is going to be a lot more complicated, especially given the lack of good production model. 

Horton \& Keysar are trying to adjudicate between: initial planning takes into account common ground, and initial planning does not taken into account common ground, but monitor \& fix does (and does so pre utterance initiation sometimes) 

Everything is probably more continuous than these things posit. It's a probabilistic world of bounded rationality and heuristics to fill in gaps. 

egocentrism: what is seen as egocentric behavior could be either a) not caring whether the other person understands / could be referring to a thing, b) mistaken beliefs about what the other person knows , or c) satisficing under limited resources producing either (which isn't really a third option) 

the people who call it egocentrism don't call it that when people make mistakes about what is in common ground. But as \cite{hanna2003} point out, you can never actually know what another person knows 

the ways things are said to get into common ground aren't consistent with various general assumptions that people know things (like default assumption of sharing the same language, or knowing basic facts, etc) or inferences (went to same college, is a local, etc). 

common ground is mostly useful when discussing spying -- something like expected to be comprehensible to listener based on some set of things makes more sense 

\section{name versus description}

how descriptions become names

using names with descriptions as a teaching thing (to make future things faster) 

overinformativity -- what's wrong with it? 

\section{Points of disagreement}

general tension between people who want a set of absolutes, versus gradients

how difficult doing theory of mind is (and under what circumstances)

time course of incorporation of interlocuter specific information 

interpretation of eye movements

what appropriate levels of naturalism are

what work is on the speaker v listener

"""reference diaries"""

terms I don't like: common ground, entrain, aim low v aim high v aim average

Who adjusts how much: do speakers design and/or do listeners accomodate


\section{general points of agreement}

under some circumstances, people will do conscious reasoning like they're playing clue and use very explicit theory of mind 

some of the time, people will not fully map everything and will instead need to rely on short-circuits and proxies 

the question is when these times are and what happens in "normal" situations in the middle ... 


\section{Vaguely plausible}

One key distinction that doesn't get explicitly highlighted much (but is brought up in some recent work, such as \cite{leung2023}) is that the process of `first contact' -- establishing initial reference -- is at least somewhat separable from the repeated reference / reduction phenomenon. They're probably not totally separate as the same systems will need to work for both, but there are probably peculiarities to the reduction part. 

Factors affecting how utterances are produced and interpreted are going to be varied and probabilistic. For instance, we could treat this as some sort of salience prior, where you expect the interlocuter to *probably* refer to the thing that is mutually seen (see "common ground") but the chance of them referring to something you can see and then can't isn't 0 (and thus can be increased in the likelihood). 

Considerations from audience design literature: generally pretty reasonable, communication is in some high dimensional space and there are a lot of potential influences. 

``partial pooling'' model: some sensitivity to context \& who said what, but source memory is hard. Also, there are recency effects \& some expected transfer/universals (learning language) 

Distinction between elaborations (common with a new listener) \& totally new ideas (rare)

From audience design: speakers take into account the whole set of listeners who are present -- tend to tailor so that all could understand, but use meanings/shorthands that knowledgeable ones will recognize (=> many possible ways to accomodate multiple listeners, perspectives, also consistent with a name \& describe that's good for future) 

performance is constrained by realities of task switching \& memory and interference (so some performance things that don't seem ideal may be from those things) -- bounded rationality 

speakers can also take listener context into account (at least when known) but again probably bounded by working memory

shared social history makes for efficient label sharing 


\section{meta}
general meta-theory: when something is a new area, easy to make over-simplifiying models of “here are the two or three ways it could work” this is useful, but as a field matures, important to accept nuances.

useful sketch of some options versus reality / full messy space of options

Stronger if you have gradients (ideal if you have math model and can do something quantitative)

\section{}

my concerns about whether speakers are calibrated/optimized or not continue (see also alcohol paper) 

\section{zipf}
Could be generously interpreted as an early precedent to bounded rationality / resource rationality 

points out need to be very clear about what is being optomized

Efficiency depends on what the time scale that's being optomized for is -- someitmes more prep / longer will pay off over repetition (and you don't know the future, so probabilistic)

gives an ahistorical account looking at word distributions and word \ meaning distributions 

some sort of utility access model ? 
\section{To explore further}

What's the SOTA in language production modelling? Utterance planning? 

Constraint based accounts of production (and comprehension) see \cite{hanna2003} highlights for suggested readings

maybe grice

forward search \cite{heller2012} since they're pretty reasonable about the idea of name versus what properties to include 

piantadosi on power laws and how they come from everything 

see various yoon and brown schmidt for highlighted citations to read 
\bibliography{sources.bib}
\end{document}
