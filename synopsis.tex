
\documentclass[]{article}
\usepackage[]{geometry}
\usepackage{biblatex}
%opening
\title{Towards formal theories and computational models of evolving referents to unfamiliar targets}
\author{Veronica Boyce}
\addbibresource{sources.bib}
\begin{document}
	
	\maketitle
	
	
	Language is an amazing human technology that supports much of human culture and technology by being an efficient way of conveying many concepts with precision. Humans communicate in a range of situations, with language that ranges from scripted and stereotyped (eg. greetings) to very open ended. It is this potential for open-ended use and extensibility that allows for language to be used in novel contexts to support the transmission of new ideas and communicate with new people. 
	
	Much linguistic creativity is ephemeral -- it occurs at a single time within a single conversation, satisfying that communicative need, but if that communicative need does not persist, the language used to achieve it need not persist either. However, some linguistic needs are recurrent, and the words used to fill these needs may eventually conventionalize and lexicalize within the community, and perhaps even spread to larger communities. At the long time scale, linguistic innovation becomes linguistic evolution. 
	
	Regardless, humans are adept at using language to communicate about unfamiliar targets with each other. This success reveals two somewhat separable skills: a) the ability to refer to new things (that don't have established names) in a way another person can understand and b) the ability to refer to a not-quite-so-new anymore thing in a way that is sensitive to the conversation history and may eventually converge into just being a conventional name. 
	
	How can we explain and predict this phenomena?
	
	\subsection{Levels of explanation}
	One issue with developing formal models of human linguistic behavior is that the data is rich and the possibility space is vast. How does one take messy interaction data and tame it into meaningful features that can modeled? 
	
	One could define the phenomena of interest, and thus the scope of the modeling and prediction problem, at a few different levels:
	
	1. One of the clearest trends that is observed experimentally is that utterance length reduces over repeated reference to the same novel target between the same pair of interlocuters. This has a measurable output metric (utterance length), and given enough data, a functional form could be fit. However, this really only lends itself to statistical models. Even within the same experimental conditions, individual dyads can vary widely on how quickly they reduce their utterances. Determining the relevant input predictors, and operationalizing them would be a challenge, and even then we wouldn't be able to say why or how the reduction phenomena occurs. This also loses the richness of what the words were by focusing on length.
	
	2. Instead of predicting the entire curve of a conversation, we could instead ask, given the environment, and the conversation history thus far (i.e. any previous references to the target), can we predict properties of the next description? While still a high-level model, this at least parallels the presumed generative process of people selecting utterances and actions based on what has occurred thus far. Because the step-size is smaller, some of the variation between groups may be less of an issue, if the dynamics are less variant, but variations compound over time. This approach can also be neatly separated into questions of how to model initial utterances and separately the dynamics of how successful utterances evolve over repetition. 
	
	3. Finally, one may wish to model the actual production and comprehension processes. How does the conversation history and context affect the parsing of new reference expressions? Can we model the process and predict when people will understand an utterance? Conversely, can we model how people decide what words to use to describe a novel target? This could be seen as the algorithmic equivalent to the more computational process in 2. Notably, this even more incremental approach requires a different sort of data to get at the fine grained time course. 
	
	Currently, we have formal models at none of these levels. Personally, I find the 2nd level the most promising, but ideally, we would have mutually compatible formal theories at all levels. In the rest of this introduction, I will discuss the current state of the literature and gesture at what types of work will be needed to bridge towards formal models. 
	
	I will cover approaches from four perspectives. First, the communication and reference game literature, where we will discuss what the phenomena of interest are, although these are only characterized in descriptive theories, and not formal theories. Next, I will in turn discuss two optimization-oriented frameworks of efficiency and the Rational Speech Acts models. Each of these might be able to supply formal theory, although as we will see, there are significant challenges in lining these frameworks up with the rich, open-ended language data we wish to explain. Finally, I will touch on the psycholingistic approach, which reveals some constraints that computational/optimization approaches may need to account for. 
	

\section{Communication}
The communication and conversation literature, especially with regard to referring expressions, has provided useful descriptive work, but is primarily made up of verbal theories that are vague, deterministic, do not make testable risky predictions, and use terms inconsistently. I briefly touch on these approaches, looking for parts that could be formalized and cataloging some of the phenomena that we will wish to explain. 

\subsection{Mentalizing versus Non-mentalizing approaches}

A big question that comes up with conversation, and interactions between agents more generally, is whether and how agents are tracking other agents internal states of knowledge and how this factors into their interaction.

The ``mentalizing'' tradition treats humans as representing other humans as agents with mental states. Within this broad school, there is variation in how these representations are implemented, how information gets added or modified, what exactly is tracked, and when representations (versus heuristics) are used. 

Within this tradition, many use the term ``common ground'' to reference knowledge that two agents share. In some cases, it is used to mean roughly ``things you think another person will understand and won't be surprised if you reference'' which is a useful pre-theoretic idea \cite{leung2023}. However, others use ``common ground'' in a theoretically-loaded way coming from the privileged versus mutual versus common knowledge framework. Under this usage, ``common ground'' involves infinite recursion in knowing that the other person knows that etc.; this is the usage that comes up in formal semantics where many things may be introduced to common ground via accomodation \cite{horton1996}. MORE CITATIONS

In practice, humans don't tend to do more than a couple layers of recursion in their pragmatic reasoning [CITE FRANKE DEGEN]. Thus, it is generally not important to distinguish knowledge types at deeper recursion levels than mutual knowledge that both people know to be mutual. In fact, \cite{hanna2003} defines common ground as the ``mutual knowledge, beliefs, and assumptions'' held by the interlocuters. A useful idea out of this is that what people say may be influenced both by what they know and by what they think is shared knowledge with their interlocuter. In other domains, this is called ``givenness'' \cite{fay2010}.  

How to deterministically populate these presumed knowledge representations has been the subject of much ink spillage (CITATIONS including CLARK USING LANGUAGE HORTON 1996). For our purposes, I merely note that what another person knows or can be expected to understand is something that computational models will want as an input or intermediary, so that it can be used to evaluate utterance options. However, this can clearly be probabilistic and may be inferred from empirical data. 

In contrast to the mentalizing approaches is a different theory called the ``interactive alignment theory'', which attempts to explain how people can successfully collaborate on reference tasks without reasoning about each other's mental states \cite{pickering2004, gandolfi2022}. It's proponents claim that the alignment occurs via ``priming'' and is ``resource-free and automatic'', without providing a further explanation of what this means or how this is working on the level of processing, memory, and production\cite{pickering2004}. This failure to provide an actual mechanism was widely criticized in the commentaries of \cite{pickering2004}. Given that humans reason socially about each other readily and from a young age, it's not clear that there is a prima facie motivation to prefer a non-mentalizing approach. 

As an aside, the ``common ground'' tradition and the ``interactive alignment'' traditions have tended to use different types of experiments, with ``common ground'' generally using asymmetric director/matcher designs (dating back to at least \cite{krauss1966}) and the ``interactive alignment'' traditions using symmetric designs such as the `maze' task. Thus it is possible the two approaches are build around trying to explain differing sets of experimental results. 

\subsection{Partner specificity, audience design, and sharing effort}

One key phenomenon from these director/matcher games is that different pairs use different words, which leads to claims of ``partner specificity''. This term is used when one person talks with multiple others, possibly using different terms with each, but also used in the absence of any partner-switches just to mean that different pairs develop different names for the targets. 

Empirical evidence from experiments where one director talks with multiple partners suggests that people do ``partial pooling'' over their partners \cite{hawkins2021, yoon2014}. That is, a speaker A will show some variation in their expressions when talking to partner B versus partner C, but there will be some generalization between partners as well, so that A talking with B is more like A talking with C than D talking to E. When coupled with a tendency for descriptions to shorten within a pair, this leads to a jagged pattern of reference length: when switching to a new partner, speakers use longer utterances, but not as long as their initial utterance with their first partner.  

A related ambiguous term is ``audience design'', the idea that speakers seem to be sensitive to the knowledge state of their listener and say things that are easy for the listeners to comprehend. Confusingly, ``audience design'' sometimes implies intention on the part of the speaker and sometimes is used when utterances are constructed based on what's easy for the speaker, and listener ease is a side effect \cite{horton1996, rogers2013, macdonald2013, horton2002a, horton2005}.

  Intention versus side-effect are difficult to distinguish between because speakers and listeners often share recent context, find the same things salient, and linguistically what is easier to produce is often easier to process. Thus, disentangling speaker and listener ease may require careful experimental designs where ease of production and ease of comprehension are separated (TODO CITE CITE Ferreira commentary on \cite{pickering2004}). 
  
Questions around audience design are part of a larger topic of inquiry into how interlocuters split the communicative burden with one another.  
Depending on the task and the communication modality, there may be many options for how to balance the communicative load  \cite{clark1996, fay2010, foxtree2013}. For instance, a listener could describe what options they see or otherwise prompt the speaker. We might expect the load splitting to vary based on the capacities of the interlocuters (ex. a speaker might craft their utterances more when talking to a child versus an adult) and the capacities of the channels (ex. speakers may use different approaches if listeners can interrupt). 

Multi-way conversations complicate the verbal theories of audience design and partner specificity by introducing a larger audience of more partners. How do speakers balance competing needs of listeners? There are discrete theories about how speakers could ``aim low'' or ``aim high'', and questions around whether speakers track individual listeners or an aggregate \cite{yoon2014}. The empirical reality is more complicated: speakers are sensitive to the knowledge states of listeners in a gradient way, and at least in small groups, can track the correspondence between individual listener identity to histories and knowledge states, and can incorporate contextual factors that modulate task difficulty into their considerations \cite{yoon2014. yoon2018, yoon2019, yoon2019a}. Speakers also take strategies in group-contexts that don't occur as often in dyadic contexts, such as referring to a target with both the name that one person will understand and a elaborated description that will help another person get on the same page \cite{yoon2018}. 

One expects that the ability to track partner's knowledge states would eventually degrade as groups got bigger, but it's an empirical matter how large groups have to be before speakers weren't able to track individual performance and knowledge. There is neither sufficient data nor theories on how utterance design changes with group size. 


\subsection{Convention formation}
Over repetitions with the same partner, dyads in repeated reference games tend to form shared ``conventions'' about how to refer to the initially ambiguous targets. These conventions tend to be partner- and context-specific: changes in the speaker, audience members, or changes in the context can all license the use of a new description \cite{metzing2003a, ibarra2016, yoon2014}.

The shared description is also referred to a ``conversational pact'' (CITATION), the word ``pact'' implies intentionality, but I don't think that's really discussed. (TODO CONFIRM)

What exactly does convention formation refer to? There is ambiguity about what level of specificity convention formation or conceptual pacts refer to. 
It could be on the lexical level, such as calling a figure ``ballerina''. It could be conceptualizing the figure as a ballet dancer with a tutu (manifesting in descriptions with semantic association, but not lexical overlap, such as ``ballerina'' and ``dancing in a tutu''). It could also be a general paradigm for how to describe figures, such as in terms as humans in different postures.  \cite{horton2002a} distinguishes between ``lexical entrainment'' when the same words are reused, and ``conceptual similarity'' when is a a broader similarity that does not repeat the same words. These levels often co-occur, but in order to model the phenomenon, it needs to be specified precisely, in order to be operationalized. 

While the meaning of a description is not inherently related to its length; these two features tend to correlate in the empirical work around reference games, and thus ``reduction'' or the shortening of utterance is also used as a shorthand and measurement proxy for the semantic changes. It remains an empirical question whether the shortening of utterances and the convention formation are inherently coupled or merely occur together in the paradigms considered in the literature. These phenomena also co-occur and are sometimes conflated with partner-specificity, as in many paradigms, different pairs form different conventions. ADD CITATIONS

This set of empirical results have been characterized in descriptive theories, but we do not have ways to predict them quantitatively (ex. with computational models), nor do we have a grasp on the necessary or sufficient conditions under which they occur to what extent. Even with a number of experiments finding these same results, there has not been a systematic investigation of how these phenomena vary across experimental space. 

What are potential explanations for why convention formation occurs?

While not an explanation, \cite{leung2023} usefully points out that forming a convention can be thought of as preceding in two stages: first some referential expression must succeed in communicating the target, and only then can that expression turn into a more reduced form. Breaking the convention-formation process into these two steps may make it more tractable. 

Another question is whether convention formation requires a "special" mechanism and theory, or whether the results can be sufficiently explained under broader theories of efficiency or communication (as discussed below). 

TODO YOU NEED TO DO MORE WORK WRANGLING HERE!!!! Potentially come back or move stuff below!
REREAD piantodosi2012 

TODO dig into more: \cite{piantadosi2012} has me wondering whether conversational pacts are even real, or whether they are actually just contextual reduction is ambiguity and them peaking of the distributions in a slightly recursive way plus some recency effects and habit. This approach requires that speakers and listeners have similar models of language and the world at least in the relevant domain so that they can use contextual information to constrain the situation 

\cite{piantadosi2012} in line with RSA assumes that inference is cheap and that context and speaker goals are constantly taken into account 

Groups can be complicated \cite{guilbeault2021} looks at how different sizes of groups interacting over a network structure result in different category boundaries, where large groups end up more the same than small groups. Brings up questions about network structure and how we should think about networks even within groups where multiple people are interacting synchronously. Some of the other try to only allow lines between points -- either bidirectional is dialog or single-directional in monolog but there's still the development of shared stuff from the co-presence of listening to someone else even without direct interaction? 


\cite{hawkins2020b} How do you break symmetries in initial descriptions: there's prior variability across speaker preferences (they may each have a preferred label, but be unsure if others will accept it) and/or speakers may also not have labels and need to do some sampling. This doesn't account for production time course factors. 

this is a domain general model about abstracting over instances and forming conventions -- it is not particular to language, although peculiarities of language will also occur (and may have more levels to conventionalize on) 
\cite{hawkins2021} says there are 3 core cognitive abilities: the ability to represent that there is variability in other's lexicons; to coordinate via online learning; and to generalize across interactions ("partial pooling" model where updates both to partner and population) 

\subsection{Takeaways:} The communication and reference game literature provides descriptive theories that identify some phenomena of interest and raise questions around whether these phenomena occur intentionally or emerge as a by-product of other processes. These serve as a list of results that models could hope to explain. 

However, as the frequently ambiguous terms make clear, the descriptive work has not nailed down the phenomena to the degree of precision necessary. How do we measure these constructs across experiments? Fuller characterization of these phenomena will also require testing them in more circumstances, in order to define their extent. Alternatively, the verbal theories could be specific about the domain in which they claim to apply.  

[de-snark??]




\section{Efficiency}
One unifying framework gaining traction in psycholinguistics is efficiency, the idea that language and language use is under pressure to support efficient communication by maximizing the ratio of relevant information transmitted to effort. Efficiency is thought to arise from trade-offs between communicative expressivity and some combination of learnability and easy of production \cite{piantadosi2012, kirby2015}. 

Evidence for efficiency comes from the argument that features of language are distributed much closer to the Pareto frontier than would be expected by chance. A historically well-known example is that word frequencies follow a power-law distribution, which \cite{zipf1949} explains in terms of a ``principle of least effort'', although note that power-law distributes are common across domains and generated by a variety of processes \cite{piantadosi2014}. Stronger evidence comes from the lexical partitioning of subdomains such as color, number, and kinship terms, where the distribution of systems falls on the frontier between complexity (number of terms) and informativity (how many bits each term provides) \cite{keysar2000, gibson2019}. Syntactic features of language such as harmonic word order or dependency length also appear to be optimizing for increased expressivity with minimized processing effort \cite{gibson2019, hawkins1995}. 
	
Efficiency arguments are based on the language artifacts of grammars and transcripts, but efficiency pressures act on language use as a process, not language as a static code \cite{gibson2019}. Thus efficiency can be seen as imposing a joint constraint on the entire communicative process to minimize the total time and effort involved in going from an idea in one person's head to a sufficiently close idea in another person's head. One corollary of this framing is that shorter utterances (as measured in syllables or clock-time) are not always efficient if they take longer to produce or parse. 

\subsection{reference expressions and redundancy}
Interlocuter behavior in iterated reference games is informally referred to as efficient (in particular, the formation of reduced conversational pacts) CITE ME , but it isn't formally analyzed in terms of efficiency. Explicit tests of efficiency are used in the study of so-called  ``redundant'' color adjective use and other forms of so-called ``over-informative'' language use. As shown by the names, it seems like people's propensity to label something as a ``blue cup'' when there are not other cups around goes against the idea of efficient language use. 

Several issues arise here. Claims of redundancy or over-informativity require defining what is minimally informative. Defining what is minimally informative depends on a commitment to a fully specified semantic-pragmatic system. For instance, if specificity implicatures are within the option space, are those calculated before or after informativeness is measured \cite{bergen}? One could sidestep the theory by empirically measuring the information content of different utterances by how they shift the entropy of the distribution of inferred meanings \cite{degen20200406}, but this does not scale up well. 

Additionally, determining what is efficient requires not just analyzing phrases and their alternatives, but also production and comprehension time, which may be highly contingent on contextual factors and conversational history. 

The flip side of ''redundancy'' is ambiguity: many, many utterances are ambiguous. In general, strong contextual factors render the ambiguity a non-issue \cite{piantadosi2012}, but this means we can't judge language out of the physical and social context it is used in. 

These ideas that utterances should have ``just enough'' information has inspired a lot of empirical research into what utterances people produce and what utterances people comprehend. As an empirical matter, each of these halves can be empirically measured: by comparing them, we could determine how calibrated productions are to what other people will understand. 



\subsection{Takeaways:}
Efficiency is very hard to cache out in specific predictions because of the many time scales the pressures operate on: what's efficient for an utterance in isolation may not be efficient when considered over an entire life of language use. Thus, the efficiency framework is dependent on linking assumptions, and an efficiency approach could be seen as determining what link assumptions are needed to bring different phenomena under this umbrella, and then assessing the parsimony of the links.

With regard to iterated reference games, I believe it is an open question whether utterances are correctly calibrated for what listener's will understand. Testing how listener's understand produced utterances and potential alternatives, along with how long they take to process, and how confident they are is a way of empirically determining if the utterances are calibrated for the listener. If they are not, this disproves some claims about what reduction and partner-specific utterances represent, but it could still be linked to efficiency either via claims that the bottleneck is on the search and production side, or that speakers are mistaken in their mental model of the listener. 

YOU ARE HERE


Might be some more theory neutral ways of trying to quantify information here in an empirically derived way. 



This seems like it would lend itself to a formal model: just list all the options and their corresponding levels of effort and informativity and see where reality lands. In practice, determining the options, their levels of effort, and their levels of informativity is a big problem that seems to require solving a bunch of other open quesitons. 


Over the short time scale of one utterance to the next, the wider meaning of language (the prior) can at least be treated as static. There are still issues where What types of communication utterances are efficient should depend significantly on the context and communication channels. In particular, if interlocuters can interrupt with questions, or cut off a speaker by selecting a referent, then incrementally efficient utterances make sense \cite{gibson2019}. In other contexts, with lower feedback, it might make sense to more evenly distribute information content or rely on surer, but longer descriptions, if there isn't an option to add elaborations contingent on interlocuter behavior.

Efficiency also predicts that a changing conversational history will change the context and thus different descriptions may be efficient. This could operate both by increasing beliefs that a certain utterance will be understood (and this is contextually low ambiguity) or more generally by shaping the syntactic expectations, perhaps making it easier to produce and comprehend odder descriptions. 

\section{RSA}

RSA is an information-theoretic, computational framework for making quantitative predictions about pragmatic inferences in context \cite{goodman2016, frank2012a}. The basic idea of the Rational Speech Acts (RSA) family of models is to picture two interlocuters recursively reasoning about how the other would produce or interpret utterances, grounding out in a listener (or speaker) who behaves in a pre-specified ``literal'' way. Computational frameworks such as RSA provide a way to factor together different trade offs and determine their relative weights in a model. This set of models has been used to model some instances of ad hoc pragmatics as well as conventionalized pragmatic implicatures. 

This framework is usually run with one or two levels of recursion, where it tends to produce a reasonable fit to human experimental judgments, consistent with work finding that most people reason pragmatically at a low recursion depth TODO CITE FRANKE \& DEGEN. 

The basic idea of RSA is to specify some level-0 listener whose lexicon is specified in some way. From there, the speaker reasons about the listeners lexicon, and samples an utterance that softmaxes their utility function. Then, a pragmatic listener reasons about how to interpret an utterance by softmaxing a meaning given their model of the speaker and literal listener. This is a fairly basic framework, but many of the chunks here can get quite complicated when necessary. 

Different models in the RSA tradition incorporate different sets of components in the models. Models generally include a utility or informativity term that relates to how well an utterance resolves uncertainty in favor of the target referent.  It is common to also include factors such as the prior likelihood of referring to each target (salience prior) and some cost on utterances where longer or more complex utterances are penalized \cite{goodman2016}. Some models also go beyond informativity, incorporating options to infer the question-under-discussion CITATION or for speakers to balance informativity with politeness.

In some sense, a fully RSA model would incorporate all of these components and also infer their weights. However, for tractability, usually only those features that are considered relevant to the domain of interest are included.

Because of the flexible framework, it is possible to model many sources and levels of uncertainty, and then integrate out that uncertainty to make predictions, but also update on the sources of uncertainty in response to input. 

Perhaps the largest challenge to RSA models is the question of how to ground out the models in a ``literal'' listener or speaker. For the most part, RSA is tested in toy domains where the set of possible utterances are small and it is possible to enumerate a set of meanings. For instance, in some domains, a soft or continuous semantics is used to represent that some dimensions of meaning might be more strongly informative than others \cite{degen20200406}. This semantics supports the prediction of patterns of ``redundant'' color adjectives in referring expressions. However, soft semantics can run into conflict with compositionality: either every possible utterance must independently receive a degree of match with every possible object in the prior, or the prior needs to include rules for how to determine the match of a whole utterance on the basis of the match with each component. In a later experiment of \cite{degen20200406}, typicality effects made compositional semantics not work, but the utterance space was small enough that each utterance could be treated individually. 

 In less toy domains, there is not a satisfactory answer: some situations can be handled by empirically measuring likelihoods in an exhaustive ways, but this holistic approach is not compatible with incremental RSA or larger sets of utterances that require compositionality to be defined. In order to extend this model towards more realistic and open-ended scenarios, an important question to grapple with is what form of meaning (even at a computational level) will appropriately support pragmatic reasoning. 
 
This conundrum could be read as saying that one must define semantics before attempting pragmatics; I do not believe this, but prefer to frame this as a question of finding what model of semantics could be a linking hypothesis to allow RSA models to predict the patterns of pragmatic language use that are observed experimentally. 


\subsection{RSA approaches to reduction}
Scaling up RSA to handle reference games requires solving at least two problems. One is specifying a semantics system that can handle the abstract, metaphoric, and parts-based descriptions that are used -- this could be seen as the problem of accounting for initial reference. 

Secondly, one must explain how to go from one successful utterance to a different (often shorter) utterance. One RSA-style model that attempts to explain why multi-part descriptions are produced initially, but then later reduce to shorter descriptions is CHAI,  a framework to bridge different levels of convention formation \cite{hawkins2021}. TODO SAY MORE ABOUT CHAI In toy models of interlocuters playing a reference game with soft semantics, initial utterances use multiple properties to collectively increase the degree of certainty in the target. However, this successful reference then shapes the priors about the meanings of the words, until the degree of certainty afforded by only one word is sufficient. 

\cite{hawkins2021} separating the inference problem about what the other person's lexicon is (which is how they will interpret things in the moment, b/c you may have temporarily changed their lexicon) with decisions about what to say given that 

\cite{hawkins2021} points out that our models for communication and modeling the world and others need to be able to account for different people having different knowledge (including some tied to community membership or social role) and that vocabularies need to accomodate change over time and new things to refer to as the world changes. 

\subsection{Takeaways}
RSA seems poised as the closest theory that could be made to fit for a sequential model. Has the problem of open vocab, and of free parameter fitting, which reduce risk. At least a useful framework. 
CHAI while not a full explanation for the full patterns of real-world data, at least is a framework that actually explains why reduction would be optimal. 

would need some level of incrementality, or else would need to redefine the step where RSA operates. (this would favor greedy algorithm, but maybe that's okay especially if we take production constraints seriously?)
TODO CITE INCREMENTAL RSA

\section{Psycholinguistics}

Psycholinguistics imposes constraints on the algorithmic level of linguistic communication; however, determining the constraints requires understanding both production and parsing. Understanding the time course of production is particularly difficult to study. 

\subsection{Top-down or bottom-up?}
One major point of disagreement is whether production and comprehension are initially ``ego-centric'' or whether non-linguistic information, such as the perspective of the interlocuter, is exerting an top down influence from the beginning. For example, TODO cite Horton \& Keysar attempt to test this, but acknowledge that monitoring and fixing of the utterance, including pre-initiation of the utterance, may take into account the listener's perspective. %TODO say more about the egocentrism thing

Parallel to the egocentrism debate in production is an egocentrism debate in comprehension. Basically, the question is whether an intial stage of comprehension is egocentric, that is, not taking into account non-linguistic input about other's knowledge state or intent. This was primarily studied using eye-tracking as a proxy for interpretation, which is problematic as we don't understand fully what eye-movements mean TODO CITE JUDITH. 

In any case, \cite{keysar2000} argues for an initial egocentric perspective on the basis that people often intially look at objects that are good matches to a description that are not mutually visible with their interlocuter. They seem to be assuming that if people weren't egocentric, people should have very strong priors that interlocuters only refer to things that are mutually know, which is clearly false (why ask where something is if you can see it?). 

The counterpoint presented by \cite{hanna2003} is a constraint-based theory where many factors can play into comprehension, including working memory limitations. 

 This narrow issue raises larger questions about the relative influences of top-down and bottom-up factors in influencing language processing and production.Underneath the poor experiments and strong positions are a number of interesting and complicated questions. It seems clear that many factors can sway comprehension, including both "top-down" and "bottom-up" processes, and understanding the relative mix of these factors could be very interesting. However, it's a difficult empirical matter to disentangle all these factors and a number of nuisance experiment parameters especially when the measures we have are far removed from the constructs of interest. 

\subsection{Bounds on rational approaches}
Production poses a possible deviation from the idealized RSA models in that production requires the retrieval or generation of a potential good enough utterance in the first place. The difficulties of utterance planning may cause deviations from what information-theory would predict would be efficient, based on production biases such as easy first, plan reuse, and reduce interference \cite{macdonald2013}. 

Understanding the limitations on production is challenging: while it is easy to get examples of what utterances are produced, it is much more difficult to understand how the utterances were planned. One approach is to look at utterance production with and without time pressure and see how utterances differ, but this rests on (uncertain) assumptions about how time pressure changes the production process. 

Many theories such as RSA operate over a set of options, but don't provide answers to how the option space is created in the first place. 

\cite{heller2012} disagrees and says that speakers have a harder time than listeners b/c they need to model the listener (at least approximately) %TODO re-read heller

There's interplay between production, comprehension, and what the typology of the language is, that constrain the options for a bounded rational approach like RSA. \cite{macdonald2013} provides a functionalist account claiming that utterance planning is difficult, so speakers have biases in their production. These biases are easy first, plan reuse, and reduce interference. Taking into account both word-level and context-dependent factors, easy first seems to accord with memory retrieval theories. %TODO say more about other parts 
Under this model, these speaker patterns drive typology and the statistics of language, so comprehenders rely on these statistics of input to make predictions and do pragmatic interpretation. 



One issue with any `which came first and is the driver' arguments is that language is a cultural artifact and doesn't ground out in something external. There isn't an external set of statistics for the language system to be adapted to -- the statistics are also generated by the language system. Thus, as an empirical matter it is difficult to figure out which of comprehension and production is `driving' statistics, as both are under pressure to be calibrated to the another. This calibration is similar to the difficulty determining the division of labor in audience design, just on a different granularity of analysis. 

To avoid circularity, \cite{macdonald2013} claims that some of the production pressures are related to specific mechanistic aspects of memory and domanin general features such as saliency. %TODO reread macdonald and check 

one other angle on production is to look at disfluencies as a symptom of speaker needing to think (ex \cite{yoon2014} et al use this as a measure)

\subsection{Takeaways}
Hard to measure and hard to determine what measurements would adjudicate when it depends on thought. However, given sufficient data, models of utterance generation or incremental processing that tie to data on time course of production or comprehension (perhaps also with eye-tracking), could resolve a lot. There's room for fine-grained models, but we don't have the data. Nor do we understand the relationships between the stimuli or the search space for productions. 

THIS WHOLE SECTION NEEDS WORK!!
some takeaways related to how a different type of data is needed to understand these claims


	\section{What would we want?}
	
	I will not be presenting a formal theory here, because I don't think this topic is ready for one yet. I mean one could posit mathematical relations, but they'd be easily disproved because we don't understand the relationships between things. 
	
	It'll also a question of threading a needle between aiming to incorporate too many factors (being too ambitious) and too few (overfitting to too specific a scenario). 
	
	So, what exactly is the phenomena of interest here? 
	* how people describe images/objects/things where there is not a canonical or conventional name 
	* the dynamics of how this results in "nicknames" 
	--> why does it go through the intermediate steps it does; why is it partner specific; how understandable is it to the outsider? 
	
	(* seems like when there is a canonical / conventional name, one generally just uses that; if that doesn't suffice for contrast, add adjectives/modifiers that do. )
	-- > should be convergent with what happens in nameable places; also with coinages / evo of language and convention over time; should also be non-contradicting what happens in other communication modalities; 
	
	could simplify with given a starting point lexicon and a given history which might be null; what predicts what a person says. 
	
	"Person says" is super open ended and from data we have; there's lots of options; so there's a question of what the right things are to predict -- what is a useful classification scheme in terms of types of utterances or lengths of utterances. 
	
	There are a lot of potential knobs here -- could look at different situations etc. 
	
	Lots we don't know robustly like what are the parameters of the space under which reduction (operationalized somehow) occurs -- what sorts of stims, what sorts and sizes of constrast sets, what types of people, what communication modes? 
	
	While formal theories of iterated reference would not need to cover the larger issue of language evolution, there should be touching between theories of this and the larger scale issues that this can sometimes cause. 
	
	A lot of ways to slice or possible angles: when you don't have or can't produce words how to circumlocute to describe; partner awareness / cooperative communication / feedback; social habits / norms; could be an angle onto efficiency. 
	
	nicknames/ labels/ lexicalized units : not just metaphor: process of going from "bad but good enough" to "good"
	
	issues of calibration around what info is sufficient / per effort 
	
	Here are what I think are some interesting open questions relating to reference. 
	
	Open theory/predictoin question: One hole in the literature is a satisfactory explanation of the phenomenon of reduction that can make predictions about what words drop or are kept and what *rate* of reduction might be expected. Two starting points would be the CHAI model that gives a computational model for how longer initial utterances and later shorter utterances could be optimal \cite{hawkins2021}, and the idea raised in \cite{leung2023} that forming a convention requires two stages: some referential expression must succeed in communicating the target, and then shortening that expression into a more reduced form.
	
	Open empirical q: Related to reduction is the question of whether the reduction phenomena is efficient, or rather, what linking assumptions are needed to argue that it is efficient. Would shorter utterances perhaps be understood faster than the rounds where they are produced? Is the bottleneck on producing the shorter utterances? 
	
	Open empiricial question: One last area that lacks strong theoretic explanations is what happens in groups of more than two people. What would one need to add to RSA to explain multi-person dynamics? There are verbal theories about group interactions from \cite{yoon2018}, but other communication traditions don't cache out in clear predictions about group performance. 
	
	some sort of partial pooling 
	
	Some particular challenges for using RSA in practice are the various ways that communication is open ended: it has open vocabulary, open issues of compositionality, open number of turns, and (with spoken language) is highly incremental with options to take actions or interrupt mid sentence. As it becomes more open-ended, issues of how to consider alternatives and the psychological implausibility of actually considering all of them may come into play. A resource-rational approach that uses sampling instead of exhaustivity may provide a way of pushing this computational theory down into being slightly more concrete. 
	
	In terms of theories of interactions, I favor partial-pooling models that treat people as keeping some track of the individuals and situations they interact in while also showing some transfer-learning and generalization across people and contexts. How these two factors balance against each other is an interesting empirical question. 
	
	I believe that people are fairly sophisticated at modeling the knowledge states of their interlocuters, probably through some combination of explicitly modelling knowledge the use of good heuristics. Many of these beliefs may be graded, and many be on the basis of a heirarchical framework of what knowledge tends to be known by what categories of people.  Cultural norms around givenness are something that must be learned jointly with other norms about symbolic communication (primarily language). 
	
	Pushing down levels of analysis, resource-rational models should embody some of the constraints from feasible memory retrieval, production, and processing. Some of these will be from domain general processes (memory retrieval) and others may be about the language system in particular. 
	When considering repeated reference especially for difficult-to-name targets, I think there's a productive split between what is needed for 'first contact' -- establishing an initial successful reference -- and what drives subsequent references, where reduction and changes need to be accounted for. One key distinction that doesn't get explicitly highlighted much (but is brought up in some recent work, such as \cite{leung2023}) is that the process of `first contact' -- establishing initial reference -- is at least somewhat separable from the repeated reference / reduction phenomenon. They're probably not totally separate as the same systems will need to work for both, but there are probably peculiarities to the reduction part. 
	
	at a high level, want to be able to predict reduction curves! even just in terms of number of words, nothing that currently exists can explain why the rate and shape of drop-off is what it is! There's also claims that it's "efficient" or that partner specificity is "efficient" but the levels of partner specificity and so-called efficiency haven't been tested b/c we don't know how alternatives would have gone over!! could use more data on what the curves are like -- so you have more to fit to. 
	
	at a mid level, want to predict one utterance from the previous -- may be able to do something RSAish where we think about how much info each part gives (could do some empirical derivations). would need to come up with the right set of operations / primitives to get away from the openness
	
	Another piece is that reduction isn't just about shortening in the number of words or concepts used; it also tends to follow a stereotyped pattern, where more abstract, holistic "names" stick, while descriptions that may be more concrete or describe the image piece-mail tend to drop out. Why is this what happens?  Is there a way to model the initial semantics of these pieces and of the updating such that this pattern of what sticks is predicted? 
	
	An additional complexity here is that the end point can vary. Usually holistic or analogic descriptions win out \cite{clark1986}, but this isn't absolute. Sometimes groups may use something strange and even something that is on a lower-level or on a meta-level as their referring name, and for them, this can be effective. So to fully explain this, we need to take into account the path dependency for how reduced utterances evolve, and potentially also account for issues such as people's relationships or humor value. 
	
	A fully satisfying explanation that doesn't card code some preferences may need to refer to production and comprehension factors. 
	
	Groups! Its easy to get lost in studying reference games, but the full phenomena of describing initially non-named things takes place beyond dyads in a variety of situations (CITE ROBERT NETWORK STUFF). There's lot of claims made about how face-to-face dyads are more natural (which tends not to be substantiated), but it's an interesting question how people's capacities for communication are used across a variety of settings and modalities. Good theories will also be able to explain variation based on factors like communication modality and group size. 
	
	CITE 20 questions with nature paper
	
	also question of how to extend RSA to multiparty? 
	
	\section{How will the rest of this thesis move us in that direction?}
	
	TODO WHAT'S THE CAUSAL MODEL
	Overall, it seems that despite much research, there are still questions about what exactly are the phenomena to be characterized and how far they extend. Over this thesis, we provide data in various direction that could be useful for theory building. 
	
	many of the pieces could use more data
	
	a) a broader look at when reduction and semantic convergence patterns occur: how extensive is this phenomena by looking at larger groups and different modalities. This evidence contradicts many of the verbal theories that privilege dyadic communication and other things. 
	
	b) we dig into the data from a in an attempt to look at the stage to stage evolution of descriptions (TODO gotta do this research)
	
	c) developmental trajectory
	
	d) what's the processing look like? 
	
	? e) ? do we include any AA or game-theory? 

\end{document}